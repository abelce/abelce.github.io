{"version":3,"file":"static/chunks/105.25d36fed444378f0.js","mappings":"ACAA,aACA,CAACA,KAAK,gBAAmB,CAAGA,KAAK,gBAAmB,EAAI,EAAE,EAAEC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAElE,MACC,SAASC,CAAmC,CAAEC,CAAmB,CAAEC,CAAmB,CAAE,CAE1EA,EAAoBC,CAAC,CAACF,EAAqB,CACzC,GAAM,UAAW,CAAE,OAAqBG,CAAgB,EACxD,GAAM,UAAW,CAAE,OAAqBC,CAAmB,EAC3D,GAAM,UAAW,CAAE,OAAqBC,CAAU,CACpD,GAEA,ID2YrBC,EAgaAC,EA2NAC,EA5nBAF,EAgaAC,EA2NAC,EArgCyBC,EAA6CR,EAAoB,OAZeS,EAAAT,EAAA,MAOzG,OAAAU,EAEAC,YAEAC,CAAA,CAGAC,CAAA,CAEAC,CAAA,CAMAC,CAAA,CAEAC,CAAA,CAIAC,CAAA,CAKAC,CAAA,CAOAC,CAAA,CAEAC,CAAA,CAEAC,EAAA,EAMAC,CAAA,EACA,KAAAV,CAAA,CAAAA,EACA,KAAAC,KAAA,CAAAA,EACA,KAAAC,KAAA,CAAAA,EACA,KAAAC,SAAA,CAAAA,EACA,KAAAC,GAAA,CAAAA,EACA,KAAAC,KAAA,CAAAA,EACA,KAAAC,MAAA,CAAAA,EACA,KAAAC,UAAA,CAAAA,EACA,KAAAC,UAAA,CAAAA,EACA,KAAAC,SAAA,CAAAA,EACA,KAAAC,MAAA,CAAAA,CACA,CAEAC,UAAA,CACA,eAAAV,KAAA,CAAAW,MAAA,EAAAC,EAAAC,IAAAA,EAAA,MAAAC,MAAA,MAAAb,KAAA,WAAAE,GAAA,QAAAC,KAAA,UAAAA,KAAA,MAIA,OAAAW,MAAAhB,CAAA,CAAAE,CAAA,CAAAE,EAAA,GACA,IAAAa,EAAAjB,EAAAkB,MAAA,CAAAC,OAAA,CACA,WAAArB,EAAAE,EAAA,GAAAE,EAAAE,EAAAA,EAAA,OAAAa,EAAA,IAAAG,EAAAH,EAAAA,EAAAD,KAAA,cACA,CAKA,IAAAG,SAAA,aAAAX,UAAA,MAAAA,UAAA,CAAAW,OAAA,MAIAE,UAAAnB,CAAA,CAAAc,CAAA,EACA,KAAAf,KAAA,CAAAhB,IAAA,MAAAiB,KAAA,CAAAc,EAAA,KAAAT,UAAA,MAAAD,MAAA,CAAAgB,MAAA,EACA,KAAApB,KAAA,CAAAA,CACA,CAGAqB,OAAAC,CAAA,EACA,IAAAC,EAAcD,GAAS,GAAAE,EAAAF,MAAAA,EACvB,CAAAN,OAAAA,CAAA,OAAAlB,CAAA,CACA2B,EAAAT,EAAAU,iBAAA,CAAAF,GAGA,GAFAC,GACA,MAAAtB,KAAA,EAAAsB,CAAA,EACAF,GAAAA,EAAA,CACA,KAAAJ,SAAA,CAAAH,EAAAW,OAAA,MAAA3B,KAAA,CAAAwB,EAAA,SAAAvB,SAAA,EAGAuB,EAAAR,EAAAY,aAAA,EACA,KAAAC,SAAA,CAAAL,EAAA,KAAAvB,SAAA,MAAAA,SAAA,OACA,KAAA6B,aAAA,CAAAN,EAAA,KAAAvB,SAAA,EACA,MACA,KAMA8B,EAAA,KAAAhC,KAAA,CAAAqB,MAAA,EAAAG,EAAA,KAAAD,CAAAA,OAAAA,EAAA,KACAR,EAAA,KAAAf,KAAA,CAAAgC,EAAA,GACA1B,EAAA,KAAAN,KAAA,CAAAgC,EAAA,GAAAC,EAAA,KAAA3B,UAAA,MAAAD,MAAA,CAAAgB,MAAA,CAAAf,EAEA,GAAAmB,EAAAR,EAAAY,aAAA,EAAAN,OAAAA,EAAA,CACA,IAAApB,EAAAc,EAAAiB,SAAA,MAAAjC,KAAA,SAAAE,GAAA,MAAAD,SAAA,CACA,KAAA4B,SAAA,CAAAL,EAAAV,EAAAZ,EAAA8B,EAAA,KACA,IACAV,OAAAA,EACA,KAAAtB,KAAA,MAAAD,KAAA,CAAAgC,EAAA,KAEA,CACA,IAAAG,EAAA,KAAAnC,KAAA,CAAAgC,EAAA,GACA,KAAA/B,KAAA,CAAAgB,EAAAW,OAAA,CAAAO,EAAAV,EAAA,GACA,MACA,KAAAzB,KAAA,CAAAqB,MAAA,CAAAW,GACA,KAAAhC,KAAA,CAAAoC,GAAA,GACA,KAAAL,aAAA,CAAAN,EAAAV,EACA,CAGAe,UAAAO,CAAA,CAAAtB,CAAA,CAAAuB,CAAA,CAAAC,EAAA,EAAAC,EAAA,IACA,GAAAH,GAAAA,GACA,OAAArC,KAAA,CAAAqB,MAAA,OAAArB,KAAA,MAAAA,KAAA,CAAAqB,MAAA,SAAAhB,MAAA,CAAAgB,MAAA,MAAAf,UAAA,GAEA,IAAAmC,EAAA,KAAAC,EAAA,KAAArC,MAAA,CAAAgB,MAAA,CAKA,GAJA,GAAAqB,GAAAD,EAAAhC,MAAA,GACAiC,EAAAD,EAAAnC,UAAA,CAAAmC,EAAAhC,MAAA,CAAAH,UAAA,CACAmC,EAAAA,EAAAhC,MAAA,EAEAiC,EAAA,GAAAD,GAAAA,EAAApC,MAAA,CAAAqC,EAAA,IAAAD,EAAApC,MAAA,CAAAqC,EAAA,OACA,GAAA3B,GAAAuB,EACA,OACA,GAAAG,EAAApC,MAAA,CAAAqC,EAAA,IAAA3B,EAAA,CACA0B,EAAApC,MAAA,CAAAqC,EAAA,GAAAJ,EACA,MACA,EACA,CACA,GACA,QAAAnC,GAAA,EAAAmC,EAGA,CACA,IAAAK,EAAA,KAAAtC,MAAA,CAAAgB,MAAA,CACA,GAAAsB,EAAA,WAAAtC,MAAA,CAAAsC,EAAA,GACA,KAAAA,EAAA,QAAAtC,MAAA,CAAAsC,EAAA,GAAAL,GAEA,KAAAjC,MAAA,CAAAsC,EAAA,MAAAtC,MAAA,CAAAsC,EAAA,GACA,KAAAtC,MAAA,CAAAsC,EAAA,QAAAtC,MAAA,CAAAsC,EAAA,GACA,KAAAtC,MAAA,CAAAsC,EAAA,QAAAtC,MAAA,CAAAsC,EAAA,GACA,KAAAtC,MAAA,CAAAsC,EAAA,QAAAtC,MAAA,CAAAsC,EAAA,GACAA,GAAA,EACAJ,EAAA,GACAA,CAAAA,GAAA,EACA,CACA,KAAAlC,MAAA,CAAAsC,EAAA,CAAAN,EACA,KAAAhC,MAAA,CAAAsC,EAAA,GAAA5B,EACA,KAAAV,MAAA,CAAAsC,EAAA,GAAAL,EACA,KAAAjC,MAAA,CAAAsC,EAAA,GAAAJ,CACA,MAnBA,KAAAlC,MAAA,CAAArB,IAAA,CAAAqD,EAAAtB,EAAAuB,EAAAC,EAmBA,CAIAK,MAAArB,CAAA,CAAAsB,CAAA,CAAAC,CAAA,EACA,IAAA/B,EAAA,KAAAZ,GAAA,CACA,GAAAoB,OAAAA,EACA,KAAAH,SAAA,CAAAG,MAAAA,EAAA,KAAApB,GAAA,OAEA,IAAAoB,OAAAA,CAAA,GAA+C,GAC/C,IAAAN,OAAAA,CAAA,OAAAlB,CAAA,CACA+C,CAAAA,EAAA,KAAA3C,GAAA,EAAA0C,GAAA5B,EAAA8B,OAAA,IACA,KAAA5C,GAAA,CAAA2C,EACA7B,EAAAiB,SAAA,CAHAX,EAGA,IACA,MAAArB,SAAA,CAAA4C,CAAA,GAEA,KAAA1B,SAAA,CANAG,EAMAR,GACA,KAAAiC,YAAA,CAAAH,EAAA9B,GACA8B,GAAA5B,EAAA8B,OAAA,EACA,KAAA1C,MAAA,CAAArB,IAAA,CAAA6D,EAAA9B,EAAA+B,EAAA,EACA,MAEA,KAAA3C,GAAA,CAAA2C,EACA,KAAAE,YAAA,CAAAH,EAAA9B,GACA8B,GAAA,KAAA9C,CAAA,CAAAkB,MAAA,CAAA8B,OAAA,EACA,KAAA1C,MAAA,CAAArB,IAAA,CAAA6D,EAAA9B,EAAA+B,EAAA,EACA,CAIAG,MAAA1B,CAAA,CAAAsB,CAAA,CAAAC,CAAA,EACAvB,MAAAA,EACA,KAAAD,MAAA,CAAAC,GAEA,KAAAqB,KAAA,CAAArB,EAAAsB,EAAAC,EACA,CAGAI,QAAAC,CAAA,CAAAN,CAAA,EACA,IAAAF,EAAA,KAAA5C,CAAA,CAAAqD,MAAA,CAAA/B,MAAA,GACAsB,CAAAA,EAAA,QAAA5C,CAAA,CAAAqD,MAAA,CAAAT,EAAA,EAAAQ,CAAA,IACA,KAAApD,CAAA,CAAAqD,MAAA,CAAApE,IAAA,CAAAmE,GACAR,KAEA,IAAA5B,EAAA,KAAAZ,GAAA,CACA,KAAAD,SAAA,MAAAC,GAAA,CAAAY,EAAAoC,EAAA9B,MAAA,CACA,KAAAD,SAAA,CAAAyB,EAAA9B,GACA,KAAAV,MAAA,CAAArB,IAAA,CAAA2D,EAAA5B,EAAA,KAAAb,SAAA,KACA,KAAAK,UAAA,EACA,KAAA8C,aAAA,MAAA9C,UAAA,CAAA+C,OAAA,CAAAC,KAAA,MAAAhD,UAAA,CAAAW,OAAA,CAAAiC,EAAA,UAAApD,CAAA,CAAAyD,MAAA,CAAAC,KAAA,MAAAtD,GAAA,CAAAgD,EAAA9B,MAAA,GACA,CAKAqC,OAAA,CACA,IAAAjD,EAAA,KACAkD,EAAAlD,EAAAJ,MAAA,CAAAgB,MAAA,CAKA,KAAAsC,EAAA,GAAAlD,EAAAJ,MAAA,CAAAsD,EAAA,GAAAlD,EAAAP,SAAA,EACAyD,GAAA,EACA,IAAAtD,EAAAI,EAAAJ,MAAA,CAAAuD,KAAA,CAAAD,GAAA3B,EAAAvB,EAAAH,UAAA,CAAAqD,EAEA,KAAAlD,GAAAuB,GAAAvB,EAAAH,UAAA,EACAG,EAAAA,EAAAA,MAAA,CACA,WAAAZ,EAAA,KAAAE,CAAA,MAAAC,KAAA,CAAA4D,KAAA,QAAA3D,KAAA,MAAAC,SAAA,MAAAC,GAAA,MAAAC,KAAA,CAAAC,EAAA2B,EAAA,KAAAzB,UAAA,MAAAC,SAAA,CAAAC,EACA,CAGAoD,gBAAAhB,CAAA,CAAAC,CAAA,EACA,IAAAgB,EAAAjB,GAAA,KAAA9C,CAAA,CAAAkB,MAAA,CAAA8B,OAAA,CACAe,GACA,KAAAhC,SAAA,CAAAe,EAAA,KAAA1C,GAAA,CAAA2C,EAAA,GACA,KAAAhB,SAAA,QAAA3B,GAAA,CAAA2C,EAAAgB,EAAA,KACA,KAAA3D,GAAA,MAAAD,SAAA,CAAA4C,EACA,KAAA1C,KAAA,KACA,CAKA2D,SAAA1B,CAAA,EACA,QAAA2B,EAAA,IAAAC,EAAA,SACA,IAAA1C,EAAA,KAAAxB,CAAA,CAAAkB,MAAA,CAAAiD,SAAA,CAAAF,EAAA/D,KAAA,UAAAF,CAAA,CAAAkB,MAAA,CAAAkD,SAAA,CAAAH,EAAA/D,KAAA,CAAAoC,GACA,GAAAd,GAAAA,EACA,SACA,IAAAA,MAAAA,CAAA,KACA,SACAyC,EAAA1C,MAAA,CAAAC,EACA,CACA,CAIA6C,gBAAAvB,CAAA,EACA,QAAA7C,KAAA,CAAAqB,MAAA,MACA,SACA,IAAAgD,EAAA,KAAAtE,CAAA,CAAAkB,MAAA,CAAAoD,UAAA,MAAApE,KAAA,EACA,GAAAoE,EAAAhD,MAAA,SAAArB,KAAA,CAAAqB,MAAA,OACA,IAAAiD,EAAA,GACA,QAAAzD,EAAA,EAAA0D,EAAA1D,EAAAwD,EAAAhD,MAAA,CAAAR,GAAA,EACA0D,CAAAA,EAAAF,CAAA,CAAAxD,EAAA,UAAAZ,KAAA,OAAAF,CAAA,CAAAkB,MAAA,CAAAkD,SAAA,CAAAI,EAAA1B,IACAyB,EAAAtF,IAAA,CAAAqF,CAAA,CAAAxD,EAAA,CAAA0D,GAEA,QAAAvE,KAAA,CAAAqB,MAAgC,KAChC,QAAAR,EAAA,EAAAyD,EAAAjD,MAAA,IAAAR,EAAAwD,EAAAhD,MAAA,CAAAR,GAAA,GACA,IAAA0D,EAAAF,CAAA,CAAAxD,EAAA,GACAyD,EAAAE,IAAA,EAAAC,EAAA5D,IAAA,EAAAA,GAAA4D,GAAAF,IACAD,EAAAtF,IAAA,CAAAqF,CAAA,CAAAxD,EAAA,CAAA0D,EACA,GACAD,CACA,KACAI,EAAA,GACA,QAAA7D,EAAA,EAAAA,EAAAwD,EAAAhD,MAAA,EAAAqD,EAAArD,MAAA,GAAAR,GAAA,GACA,IAAA0D,EAAAF,CAAA,CAAAxD,EAAA,GACA,GAAA0D,GAAA,KAAAtE,KAAA,CACA,SACA,IAAAD,EAAA,KAAA0D,KAAA,GACA1D,EAAAoB,SAAA,CAAAmD,EAAA,KAAApE,GAAA,EACAH,EAAA8B,SAAA,GAAA9B,EAAAG,GAAA,CAAAH,EAAAG,GAAA,OACAH,EAAAgD,YAAA,CAAAqB,CAAA,CAAAxD,EAAA,MAAAV,GAAA,EACAH,EAAAI,KAAA,MACAsE,EAAA1F,IAAA,CAAAgB,EACA,CACA,OAAA0E,CACA,CAIAC,aAAA,CACA,IAAArD,EAAA,KAAAvB,CAAA,CAAAkB,MAAA,CAAAiD,SAAA,MAAAjE,KAAA,IACA,IAAAqB,MAAAA,CAAA,KACA,MAAc,EAAS,CACvB,IAAAL,OAAAA,CAAA,OAAAlB,CAAA,CACA,IAAAkB,EAAA2D,WAAA,MAAA3E,KAAA,CAAAqB,GAAA,CAEA,IAAAuD,EAAA,KAAA7E,KAAA,CAAAqB,MAAA,CAAAG,EADAF,CAAAA,GAAA,IAEA,GAAAuD,EAAA,GAAA5D,EAAAA,EAAAW,OAAA,MAAA5B,KAAA,CAAA6E,EAAA,CAFAvD,MAAAA,EAEA,IACA,SACA,KAAAQ,SAAA,QAAA5B,SAAA,MAAAA,SAAA,OACA,KAAAE,KAAA,KACA,QACA,KAAAF,SAAA,MAAAC,GAAA,CACA,KAAAmB,MAAA,CAAAA,GACA,EACA,CAEAwD,UAAA,CACA,WAAA/E,CAAA,CAAAkB,MAAA,CAAAiB,SAAA,MAAAjC,KAAA,KACA,SAAA0E,WAAA,IACA,KAAA7C,SAAA,QAAA3B,GAAA,MAAAA,GAAA,OACA,MACA,OAEA,KAKA,IAAA4E,SAAA,CACA,WAAA/E,KAAA,CAAAqB,MAAA,CACA,MAAc,EAAS,CACvB,IAAAJ,OAAAA,CAAA,OAAAlB,CAAA,CACA,OAAAkB,OAAAA,EAAA+D,IAAA,CAAA/D,EAAAiD,SAAA,MAAAjE,KAAA,MACA,CAAAgB,EAAAiD,SAAA,MAAAjE,KAAA,GACA,CAIAgF,SAAA,CACA,KAAAhF,KAAA,MAAAD,KAAA,IACA,KAAAA,KAAA,CAAAqB,MAAA,EACA,CAEA6D,UAAAC,CAAA,EACA,QAAAlF,KAAA,EAAAkF,EAAAlF,KAAA,OAAAD,KAAA,CAAAqB,MAAA,EAAA8D,EAAAnF,KAAA,CAAAqB,MAAA,CACA,QAAwB,CACxB,QAAAR,EAAA,EAAAA,EAAA,KAAAb,KAAA,CAAAqB,MAAA,CAAAR,GAAA,EACA,QAAAb,KAAA,CAAAa,EAAA,EAAAsE,EAAAnF,KAAA,CAAAa,EAAA,CACA,SACA,QACA,CAEA,IAAAI,QAAA,aAAAlB,CAAA,CAAAkB,MAAA,CAGAmE,eAAAC,CAAA,cAAAtF,CAAA,CAAAkB,MAAA,CAAAqE,OAAA,CAAAC,KAAA,CAAAF,EAAA,CACArC,aAAAX,CAAA,CAAAtB,CAAA,EACA,KAAAR,UAAA,EACA,KAAA8C,aAAA,MAAA9C,UAAA,CAAA+C,OAAA,CAAAV,KAAA,MAAArC,UAAA,CAAAW,OAAA,CAAAmB,EAAA,UAAAtC,CAAA,CAAAyD,MAAA,CAAAC,KAAA,CAAA1C,IACA,CACAgB,cAAAM,CAAA,CAAAtB,CAAA,EACA,KAAAR,UAAA,EACA,KAAA8C,aAAA,MAAA9C,UAAA,CAAA+C,OAAA,CAAAhC,MAAA,MAAAf,UAAA,CAAAW,OAAA,CAAAmB,EAAA,UAAAtC,CAAA,CAAAyD,MAAA,CAAAC,KAAA,CAAA1C,IACA,CAEAyE,aAAA,CACA,IAAAC,EAAA,KAAApF,MAAA,CAAAgB,MAAA,GACAoE,CAAAA,EAAA,YAAApF,MAAA,CAAAoF,EAAA,GACA,KAAApF,MAAA,CAAArB,IAAA,MAAAuB,UAAA,CAAAmF,IAAA,MAAAxF,SAAA,MAAAA,SAAA,IACA,CAEAyF,eAAA,CACA,IAAAF,EAAA,KAAApF,MAAA,CAAAgB,MAAA,GACAoE,CAAAA,EAAA,YAAApF,MAAA,CAAAoF,EAAA,GACA,KAAApF,MAAA,CAAArB,IAAA,MAAAwB,SAAA,MAAAN,SAAA,MAAAA,SAAA,IACA,CACAmD,cAAAnC,CAAA,EACA,GAAAA,GAAA,KAAAX,UAAA,CAAAW,OAAA,EACA,IAAA0E,EAAA,IAAAzE,EAAA,KAAAZ,UAAA,CAAA+C,OAAA,CAAApC,EACA0E,CAAAA,EAAAF,IAAA,OAAAnF,UAAA,CAAAmF,IAAA,EACA,KAAAF,WAAA,GACA,KAAAjF,UAAA,CAAAqF,CACA,EAGAC,aAAArF,CAAA,EACAA,EAAA,KAAAA,SAAA,GACA,KAAAmF,aAAA,GACA,KAAAnF,SAAA,CAAAA,EAEA,CAEAsF,OAAA,CACA,KAAAvF,UAAA,OAAAA,UAAA,CAAA+C,OAAA,CAAAyC,MAAA,EACA,KAAAP,WAAA,GACA,KAAAhF,SAAA,IACA,KAAAmF,aAAA,EACA,CACA,CACA,MAAAxE,EACArB,YAAAwD,CAAA,CAAApC,CAAA,EACA,KAAAoC,OAAA,CAAAA,EACA,KAAApC,OAAA,CAAAA,EACA,KAAAwE,IAAA,CAAApC,EAAAyC,MAAA,CAAAzC,EAAAoC,IAAA,CAAAxE,GAAA,EAEA,CAGA1B,CADAA,EAOAA,GAAAA,CAAAA,EAAA,IANA,CAAAA,EAAA,qBACAA,CAAA,CAAAA,EAAA,qBACAA,CAAA,CAAAA,EAAA,qBACAA,CAAA,CAAAA,EAAA,qBACAA,CAAA,CAAAA,EAAA,+CACCA,CAAA,CAAAA,EAAA,sBAA0B,8BAI3B,OAAAyE,EACAnE,YAAAiB,CAAA,EACA,KAAAA,KAAA,CAAAA,EACA,KAAAd,KAAA,CAAAc,EAAAd,KAAA,CACA,KAAAD,KAAA,CAAAe,EAAAf,KAAA,CACA,KAAAgC,IAAA,MAAAhC,KAAA,CAAAqB,MAAA,CAEAC,OAAAC,CAAA,EACA,IAAAC,EAAAD,GAAA,EACAC,CAAA,GAAAA,GACA,KAAAxB,KAAA,OAAAe,KAAA,CAAAf,KAAA,EACA,MAAAA,KAAA,MAAAA,KAAA,CAAA4D,KAAA,IACA,KAAA5D,KAAA,CAAAhB,IAAA,MAAAiB,KAAA,MACA,KAAA+B,IAAA,KAGA,KAAAA,IAAA,GAAAR,EAAA,KAEA,IAAAwE,EAAA,KAAAjF,KAAA,CAAAhB,CAAA,CAAAkB,MAAA,CAAAW,OAAA,MAAA5B,KAAA,MAAAgC,IAAA,IAVAT,MAAAA,EAUA,GACA,MAAAtB,KAAA,CAAA+F,CACA,CACA,CAGA,MAAAC,EACAnG,YAAAE,CAAA,CAAAG,CAAA,CAAAwC,CAAA,EACA,KAAA3C,KAAA,CAAAA,EACA,KAAAG,GAAA,CAAAA,EACA,KAAAwC,KAAA,CAAAA,EACA,KAAAtC,MAAA,CAAAL,EAAAK,MAAA,CACA,QAAAsC,KAAA,EACA,KAAAuD,SAAA,EACA,CACA,OAAAC,OAAAnG,CAAA,CAAAG,EAAAH,EAAAM,UAAA,CAAAN,EAAAK,MAAA,CAAAgB,MAAA,EACA,WAAA4E,EAAAjG,EAAAG,EAAAA,EAAAH,EAAAM,UAAA,CACA,CACA4F,WAAA,CACA,IAAArD,EAAA,KAAA7C,KAAA,CAAAS,MAAA,CACA,MAAAoC,IACA,KAAAF,KAAA,MAAA3C,KAAA,CAAAM,UAAA,CAAAuC,EAAAvC,UAAA,CACA,KAAAN,KAAA,CAAA6C,EACA,KAAAxC,MAAA,CAAAwC,EAAAxC,MAAA,CAEA,CACA,IAAA+F,IAAA,QAAkB,KAAA/F,MAAA,MAAAsC,KAAA,IAClB,IAAA5B,OAAgB,aAAAV,MAAA,MAAAsC,KAAA,IAChB,IAAAL,KAAA,QAAiB,KAAAjC,MAAA,MAAAsC,KAAA,IACjB,IAAAJ,MAAA,aAAAlC,MAAA,MAAAsC,KAAA,IACAE,MAAA,CACA,KAAAF,KAAA,IACA,KAAAxC,GAAA,IACA,QAAAwC,KAAA,EACA,KAAAuD,SAAA,EACA,CACAG,MAAA,CACA,WAAAJ,EAAA,KAAAjG,KAAA,MAAAG,GAAA,MAAAwC,KAAA,CACA,EAGA,MAAA2D,EACAxG,aAAA,CACA,KAAAiB,KAAA,IACA,KAAAoC,KAAA,IACA,KAAAb,GAAA,IACA,KAAAiE,QAAA,IACA,KAAA/F,SAAA,GACA,KAAAgG,IAAA,GACA,KAAAtF,OAAA,EACA,CACA,CACA,IAAAuF,EAAA,IAAAH,CAKA,OAAAI,EAEA5G,YAEA6G,CAAA,CAEAC,CAAA,EACA,KAAAD,KAAA,CAAAA,EACA,KAAAC,MAAA,CAAAA,EAEA,KAAAC,KAAA,IAEA,KAAAC,QAAA,GAEA,KAAAC,MAAA,IACA,KAAAC,SAAA,GAGA,KAAAnE,IAAA,IAEA,KAAAoE,KAAA,CAAAR,EACA,KAAAS,UAAA,GACA,KAAA/G,GAAA,MAAAgH,QAAA,CAAAP,CAAA,IAAAQ,IAAA,CACA,KAAAC,KAAA,CAAAT,CAAA,IACA,KAAAtE,GAAA,CAAAsE,CAAA,CAAAA,EAAAvF,MAAA,IAAAiG,EAAA,CACA,KAAAC,QAAA,EACA,CAEAC,cAAAC,CAAA,CAAAC,CAAA,EACA,IAAAL,EAAA,KAAAA,KAAA,CAAA1E,EAAA,KAAAuE,UAAA,CACA/G,EAAA,KAAAA,GAAA,CAAAsH,EACA,KAAAtH,EAAAkH,EAAAD,IAAA,GACA,IAAAzE,EACA,YACA,IAAAE,EAAA,KAAA+D,MAAA,GAAAjE,EAAA,CACAxC,GAAAkH,EAAAD,IAAA,CAAAvE,EAAAyE,EAAA,CACAD,EAAAxE,CACA,CACA,KAAA6E,EAAA,EAAAvH,EAAAkH,EAAAC,EAAA,CAAAnH,GAAAkH,EAAAC,EAAA,GACA,GAAA3E,GAAA,KAAAiE,MAAA,CAAAvF,MAAA,GACA,YACA,IAAAwB,EAAA,KAAA+D,MAAA,GAAAjE,EAAA,CACAxC,GAAA0C,EAAAuE,IAAA,CAAAC,EAAAC,EAAA,CACAD,EAAAxE,CACA,CACA,OAAA1C,CACA,CAEAwH,QAAAxH,CAAA,EACA,GAAAA,GAAA,KAAAkH,KAAA,CAAAD,IAAA,EAAAjH,EAAA,KAAAkH,KAAA,CAAAC,EAAA,CACA,OAAAnH,CAAA,CACA,QAAAkH,KAAA,KAAAT,MAAA,CACA,GAAAS,EAAAC,EAAA,CAAAnH,EACA,OAAAyH,KAAAC,GAAA,CAAA1H,EAAAkH,EAAAD,IAAA,EACA,YAAA9E,GAAA,CAWAwF,KAAAL,CAAA,EACA,IAAAM,EAAA,KAAAjB,QAAA,CAAAW,EAAAtH,EAAAuE,EACA,GAAAqD,GAAA,GAAAA,EAAA,KAAAlB,KAAA,CAAAxF,MAAA,CACAlB,EAAA,KAAAA,GAAA,CAAAsH,EACA/C,EAAA,KAAAmC,KAAA,CAAAmB,UAAA,CAAAD,OAEA,CACA,IAAAE,EAAA,KAAAT,aAAA,CAAAC,EAAA,GACA,GAAAQ,IAAA,EAAAA,EACA,UAEA,GAAA9H,CADAA,EAAA8H,CAAA,GACA,KAAAjB,SAAA,EAAA7G,EAAA,KAAA6G,SAAA,MAAAD,MAAA,CAAA1F,MAAA,CACAqD,EAAA,KAAAqC,MAAA,CAAAiB,UAAA,CAAA7H,EAAA,KAAA6G,SAAA,MAEA,CACA,IAAAnG,EAAA,KAAAqG,UAAA,CAAAG,EAAA,KAAAA,KAAA,CACA,KAAAA,EAAAC,EAAA,EAAAnH,GACAkH,EAAA,KAAAT,MAAA,GAAA/F,EAAA,CACA,KAAAkG,MAAA,MAAAJ,KAAA,CAAAE,KAAA,MAAAG,SAAA,CAAA7G,GACAA,EAAA,KAAA4G,MAAA,CAAA1F,MAAA,CAAAgG,EAAAC,EAAA,EACA,MAAAP,MAAA,MAAAA,MAAA,CAAAnD,KAAA,GAAAyD,EAAAC,EAAA,CAAAnH,EAAA,EACAuE,EAAA,KAAAqC,MAAA,CAAAiB,UAAA,GACA,EACA,OACA7H,GAAA,KAAA8G,KAAA,CAAAzG,SAAA,EACA,MAAAyG,KAAA,CAAAzG,SAAA,CAAAL,EAAA,GACAuE,CACA,CAIAwD,YAAAjB,CAAA,CAAAkB,EAAA,GACA,IAAA7F,EAAA6F,EAAA,KAAAX,aAAA,CAAAW,EAAA,SAAAhI,GAAA,CACA,GAAAmC,IAAA,EAAAA,GAAAA,EAAA,KAAA2E,KAAA,CAAAlG,KAAA,CACA,4CACA,KAAAkG,KAAA,CAAA9D,KAAA,CAAA8D,EACA,KAAAA,KAAA,CAAA3E,GAAA,CAAAA,CACA,CACA8F,UAAA,CACA,QAAAjI,GAAkB,OAAA6G,SAAkB,OAAA7G,GAAA,MAAA6G,SAAA,MAAAD,MAAA,CAAA1F,MAAA,EACpC,IAAAwF,MAAAA,CAAA,CAAAM,SAAAA,CAAA,OACA,KAAAN,KAAA,MAAAE,MAAA,CACA,KAAAI,QAAA,MAAAH,SAAA,CACA,KAAAD,MAAA,CAAAF,EACA,KAAAG,SAAA,CAAAG,EACA,KAAAL,QAAA,MAAA3G,GAAA,MAAAgH,QAAA,KAEA,CACA,KAAAJ,MAAA,MAAAF,KAAA,CACA,KAAAG,SAAA,MAAAG,QAAA,CACA,IAAAkB,EAAA,KAAA1B,KAAA,CAAAE,KAAA,MAAA1G,GAAA,EACAmC,EAAA,KAAAnC,GAAA,CAAAkI,EAAAhH,MAAA,CACA,KAAAwF,KAAA,CAAAvE,EAAA,KAAA+E,KAAA,CAAAC,EAAA,CAAAe,EAAAzE,KAAA,QAAAyD,KAAA,CAAAC,EAAA,MAAAnH,GAAA,EAAAkI,CAAA,CACA,KAAAlB,QAAA,MAAAhH,GAAA,CACA,KAAA2G,QAAA,EACA,EAEAS,UAAA,QACA,KAAAT,QAAA,OAAAD,KAAA,CAAAxF,MAAA,GACA,KAAA+G,QAAA,GACA,KAAAtB,QAAA,OAAAD,KAAA,CAAAxF,MAAA,EACA,KAAAwB,IAAA,IAEA,KAAAA,IAAA,MAAAgE,KAAA,CAAAmB,UAAA,MAAAlB,QAAA,CADA,CAKAwB,QAAAC,EAAA,GAEA,IADA,KAAAzB,QAAA,EAAAyB,EACA,KAAApI,GAAA,CAAAoI,GAAA,KAAAlB,KAAA,CAAAC,EAAA,GACA,QAAAJ,UAAA,OAAAN,MAAA,CAAAvF,MAAA,GACA,YAAAmH,OAAA,GACAD,GAAA,KAAAlB,KAAA,CAAAC,EAAA,MAAAnH,GAAA,CACA,KAAAkH,KAAA,MAAAT,MAAA,QAAAM,UAAA,EACA,KAAA/G,GAAA,MAAAkH,KAAA,CAAAD,IAAA,CAKA,OAHA,KAAAjH,GAAA,EAAAoI,EACA,KAAApI,GAAA,OAAA8G,KAAA,CAAAzG,SAAA,EACA,MAAAyG,KAAA,CAAAzG,SAAA,MAAAL,GAAA,IACA,KAAAoH,QAAA,EACA,CACAiB,SAAA,CAIA,OAHA,KAAArI,GAAA,MAAAgH,QAAA,MAAA7E,GAAA,CACA,KAAA+E,KAAA,MAAAT,MAAA,MAAAM,UAAA,MAAAN,MAAA,CAAAvF,MAAA,IACA,KAAAwF,KAAA,IACA,KAAAhE,IAAA,GACA,CAEAY,MAAAtD,CAAA,CAAA8G,CAAA,EAUA,GATAA,GACA,KAAAA,KAAA,CAAAA,EACAA,EAAAlG,KAAA,CAAAZ,EACA8G,EAAAzG,SAAA,CAAAL,EAAA,EACA8G,EAAA9D,KAAA,CAAA8D,EAAAV,QAAA,KAGA,KAAAU,KAAA,CAAAR,EAEA,KAAAtG,GAAA,EAAAA,EAAA,CAEA,GADA,KAAAA,GAAA,CAAAA,EACAA,GAAA,KAAAmC,GAAA,CAEA,OADA,KAAAkG,OAAA,GACA,KAEA,KAAArI,EAAA,KAAAkH,KAAA,CAAAD,IAAA,EACA,KAAAC,KAAA,MAAAT,MAAA,QAAAM,UAAA,EACA,KAAA/G,GAAA,KAAAkH,KAAA,CAAAC,EAAA,EACA,KAAAD,KAAA,MAAAT,MAAA,QAAAM,UAAA,EACA/G,GAAA,KAAAgH,QAAA,EAAAhH,EAAA,KAAAgH,QAAA,MAAAN,KAAA,CAAAxF,MAAA,CACA,KAAAyF,QAAA,CAAA3G,EAAA,KAAAgH,QAAA,EAGA,KAAAN,KAAA,IACA,KAAAC,QAAA,IAEA,KAAAS,QAAA,EACA,QACA,KAGAkB,KAAArB,CAAA,CAAAE,CAAA,EACA,GAAAF,GAAA,KAAAD,QAAA,EAAAG,GAAA,KAAAH,QAAA,MAAAN,KAAA,CAAAxF,MAAA,CACA,YAAAwF,KAAA,CAAAjD,KAAA,CAAAwD,EAAA,KAAAD,QAAA,CAAAG,EAAA,KAAAH,QAAA,EACA,GAAAC,GAAA,KAAAJ,SAAA,EAAAM,GAAA,KAAAN,SAAA,MAAAD,MAAA,CAAA1F,MAAA,CACA,YAAA0F,MAAA,CAAAnD,KAAA,CAAAwD,EAAA,KAAAJ,SAAA,CAAAM,EAAA,KAAAN,SAAA,EACA,GAAAI,GAAA,KAAAC,KAAA,CAAAD,IAAA,EAAAE,GAAA,KAAAD,KAAA,CAAAC,EAAA,CACA,YAAAX,KAAA,CAAA8B,IAAA,CAAArB,EAAAE,EAAA,CACA,IAAA5C,EAAA,GACA,QAAAgE,KAAA,KAAA9B,MAAA,EACA,GAAA8B,EAAAtB,IAAA,EAAAE,EACA,MACAoB,EAAApB,EAAA,CAAAF,GACA1C,CAAAA,GAAA,KAAAiC,KAAA,CAAA8B,IAAA,CAAAb,KAAAC,GAAA,CAAAa,EAAAtB,IAAA,CAAAA,GAAAQ,KAAAe,GAAA,CAAAD,EAAApB,EAAA,CAAAA,GAAA,CACA,CACA,OAAA5C,CACA,CACA,CAEA,MAAAkE,EACA9I,YAAAkF,CAAA,CAAAoB,CAAA,EACA,KAAApB,IAAA,CAAAA,EACA,KAAAoB,EAAA,CAAAA,CACA,CACAa,MAAAN,CAAA,CAAA3G,CAAA,GAAA6I,SAwCA7D,CAAA,CAAA2B,CAAA,CAAA3G,CAAA,CAAA8I,CAAA,CAA6C,CAC7C,IAAA7I,EAAA,EAAiB8I,EAAA,GAAAD,EAAA,CAAA7H,OAAAA,CAAA,EAAAjB,EAAAD,CAAA,EAAAuF,QAAAA,CAAA,EAAArE,EACjB+H,EAAA,KACA,CAAAD,EAAA/D,CAAA,CAAA/E,EAAA,MADA,CAGA,IAAAgJ,EAAAjE,CAAA,CAAA/E,EAAA,GAIA,QAAAY,EAAAZ,EAAA,EAAAY,EAAAoI,EAAApI,GAAA,EACA,IAAAmE,CAAA,CAAAnE,EAAA,GAAAkI,CAAA,KACA,IAAA1G,EAAA2C,CAAA,CAAAnE,EAAA,CACA,GAAAyE,EAAA4D,MAAA,CAAA7G,IACAsE,CAAAA,IAAAA,EAAAM,KAAA,CAAA9D,KAAA,EAAAwD,EAAAM,KAAA,CAAA9D,KAAA,EAAAd,GAAApB,EAAAkI,SAAA,CAAA9G,EAAAsE,EAAAM,KAAA,CAAA9D,KAAA,IACAwD,EAAAuB,WAAA,CAAA7F,GACA,MACA,CACA,IACAQ,EAAA8D,EAAA9D,IAAA,CAAAuG,EAAA,EAAAC,EAAArE,CAAA,CAAA/E,EAAA,GAEA,GAAA0G,EAAA9D,IAAA,IAAAwG,EAAAD,GAAApE,OAAAA,CAAA,CAAAiE,EAAAI,EAAAA,EAAA,IAAArE,OAAAA,CAAA,CAAAiE,EAAAI,EAAAA,EAAA,IACApJ,EAAA+E,CAAA,CAAAiE,EAAAI,EAAAA,EAAA,GACA,SAAAL,CAAA,CACA,KAEAI,EAAAC,GAAA,CACA,IAAAC,EAAA,EAAAD,GAAA,EACA1G,EAAAsG,EAAAK,EAAAA,CAAAA,GAAA,GACAlC,EAAApC,CAAA,CAAArC,EAAA,CAAA2E,EAAAtC,CAAA,CAAArC,EAAA,UACA,GAAAE,EAAAuE,EACAiC,EAAAC,OACA,GAAAzG,GAAAyE,EACA8B,EAAAE,EAAA,MACA,CACArJ,EAAA+E,CAAA,CAAArC,EAAA,GACAgE,EAAA2B,OAAA,GACA,SAAAU,CAAA,CACA,CAEA,MACA,EAhFA,KAAAhE,IAAA,CAAA2B,EAAA3G,EAAA,KAAAoG,EAAA,EACA,CACAwC,EAAAW,SAAA,CAAAC,UAAA,CAAAZ,EAAAW,SAAA,CAAAE,QAAA,CAAAb,EAAAW,SAAA,CAAAG,MAAA,GAGA,OAAApK,EAMAQ,YAEAmH,CAAA,CAAA0C,EAAA,IACA,KAAA1C,KAAA,CAAAA,EACA,KAAAuC,UAAA,GAAAG,EAAAH,UAAA,CACA,KAAAC,QAAA,GAAAE,EAAAF,QAAA,CACA,KAAAC,MAAA,GAAAC,EAAAD,MAAA,CAEA,CAkEA,SAAAE,EAAAjD,CAAA,CAAAkD,EAAAC,WAAA,EACA,oBAAAnD,EACA,OAAAA,CAAA,CACA,IAAAoD,EAAA,KACA,QAAA5J,EAAA,EAAA6J,EAAA,EAAA7J,EAAAwG,EAAAtF,MAAA,GACA,IAAA8B,EAAe,EACf,QACA,IAAAN,EAAA8D,EAAAqB,UAAA,CAAA7H,KAAA8J,EAAA,GACA,GAAApH,KAAAA,EAAA,CACAM,EAAA,MACA,MACA,GACA,IACAN,IACAA,GAAA,IACAA,IACA,IAAAqH,EAAArH,EAAA,GAMA,GALAqH,GAAA,KACAA,GAAA,GACAD,EAAA,IAEA9G,GAAA+G,EACAD,EACA,MACA9G,GAAA,EACA,CACA4G,EACAA,CAAA,CAAAC,IAAA,CAAA7G,EAEA4G,EAAA,IAAAF,EAAA1G,EACA,CACA,OAAA4G,CAAA,CAIA,IAAAI,EAAA,SAAAvK,GAAAA,EAAAwK,GAAA,cAAAC,IAAA,CAAAzK,EAAAwK,GAAA,CAAAE,GAAA,EACAC,EAAA,KAKA,SAAAC,EAAAC,CAAA,CAAAtK,CAAA,CAAAuK,CAA6B,EAC7B,IAAAC,EAAAF,EAAAE,MAAA,CAAAhL,EAAAiL,EAAA,CAAAC,gBAAA,EAEA,IADAF,EAAWG,MAAA,CAAA3K,KAEX,IAAAuK,CAAAA,EAAmB,EAAAC,EAAAI,WAAA,CAAA5K,GAAAwK,EAAAK,UAAA,CAAA7K,EAAA,EACnB,QACA,IAAAuK,EAAA,EAAAC,EAAArD,EAAA,CAAAnH,EAAAwK,EAAAvD,IAAA,CAAAjH,CAAA,IAAAwK,EAAAlJ,IAAA,CAAAwJ,OAAA,CACA,OAAAP,EAAA,EAAA9C,KAAAC,GAAA,GAAAD,KAAAe,GAAA,CAAAgC,EAAArD,EAAA,GAAAnH,EAAA,KACAyH,KAAAe,GAAA,CAAA8B,EAAApJ,MAAA,CAAAuG,KAAAC,GAAA,CAAA8C,EAAAvD,IAAA,GAAAjH,EAAA,KACA,GAAAuK,EAAA,EAAAC,EAAAO,WAAA,GAAAP,EAAAQ,WAAA,GACA,MACA,IAAAR,EAAAlK,MAAA,GACA,OAAAiK,EAAA,IAAAD,EAAApJ,MAAA,CACA,CAfC5B,CADDA,EAEAA,GAAAA,CAAAA,EAAA,IADC,CAAAA,EAAA,MAAwB,aAkBzB,OAAA2L,EACAtL,YAAAuL,CAAA,CAAAC,CAAA,EACA,KAAAD,SAAA,CAAAA,EACA,KAAAC,OAAA,CAAAA,EACA,KAAAzK,CAAA,GACA,KAAA0K,QAAA,MACA,KAAAC,QAAA,IACA,KAAAC,MAAA,IACA,KAAAC,KAAA,IACA,KAAA3K,KAAA,IACA,KAAA4B,KAAA,IACA,KAAAgJ,YAAA,EACA,CACAA,cAAA,CACA,IAAAC,EAAA,KAAAL,QAAA,MAAA1K,CAAA,OAAAwK,SAAA,CAAAhK,MAAA,WAAAgK,SAAA,MAAAxK,CAAA,IACA,GAAA+K,EAAA,CAGA,IAFA,KAAAJ,QAAA,CAAAI,EAAAC,SAAA,CAAArB,EAAAoB,EAAAnB,IAAA,CAAAmB,EAAAxE,IAAA,CAAAwE,EAAAnE,MAAA,IAAAmE,EAAAnE,MAAA,CAAAmE,EAAAxE,IAAA,CACA,KAAAqE,MAAA,CAAAG,EAAAE,OAAA,CAAAtB,EAAAoB,EAAAnB,IAAA,CAAAmB,EAAAtE,EAAA,CAAAsE,EAAAnE,MAAA,KAAAmE,EAAAnE,MAAA,CAAAmE,EAAAtE,EAAA,CACA,KAAAoE,KAAA,CAAArK,MAAA,EACA,KAAAqK,KAAA,CAAAtJ,GAAA,GACA,KAAArB,KAAA,CAAAqB,GAAA,GACA,KAAAO,KAAA,CAAAP,GAAA,GAEA,KAAAsJ,KAAA,CAAA1M,IAAA,CAAA4M,EAAAnB,IAAA,EACA,KAAA1J,KAAA,CAAA/B,IAAA,EAAA4M,EAAAnE,MAAA,EACA,KAAA9E,KAAA,CAAA3D,IAAA,IACA,KAAA+M,SAAA,MAAAP,QAAA,MAGA,KAAAO,SAAA,IACA,CAGAC,OAAA7L,CAAA,EACA,GAAAA,EAAA,KAAA4L,SAAA,CACA,YACA,UAAAR,QAAA,OAAAE,MAAA,EAAAtL,GACA,KAAAwL,YAAA,GACA,SAAAJ,QAAA,CACA,OAAe,KACf,QACA,IAAA9F,EAAA,KAA4BiG,KAAA,CAAArK,MAAA,GAC5B,GAAAoE,EAAA,EAEA,OADA,KAAAkG,YAAA,GACA,KAEA,IAAAjJ,EAAA,KAAAgJ,KAAA,CAAAjG,EAAA,CAAA9C,EAAA,KAAAA,KAAA,CAAA8C,EAAA,CACA,GAAA9C,GAAAD,EAAAuJ,QAAA,CAAA5K,MAAA,EACA,KAAAqK,KAAA,CAAAtJ,GAAA,GACA,KAAArB,KAAA,CAAAqB,GAAA,GACA,KAAAO,KAAA,CAAAP,GAAA,GACA,SACA,IACAS,EAAAH,EAAAuJ,QAAA,CAAAtJ,EAAA,CACA5B,EAAA,KAAAA,KAAA,CAAA0E,EAAA,CAAA/C,EAAAwJ,SAAA,CAAAvJ,EAAA,CACA,GAAA5B,EAAAZ,EAEA,OADA,KAAA4L,SAAA,CAAAhL,EACA,KAEA,GAAA8B,aAAAlD,EAAAwM,EAAA,EACA,GAAApL,GAAAZ,EAAA,CACA,GAAAY,EAAA,KAAAyK,QAAA,CACA,YACA,IAAAlJ,EAAAvB,EAAA8B,EAAAxB,MAAA,CACA,GAAAiB,GAAA,KAAAmJ,MAAA,EACA,IAAAjL,EAAAqC,EAAAuJ,IAAA,CAAAzM,EAAA0M,EAAA,CAAA7L,SAAA,EACA,IAAAA,GAAA8B,EAAA9B,EAAA,KAAA+K,QAAA,CAAAjE,EAAA,CACA,OAAAzE,CAAA,CACA,CACA,IACA,CAAAF,KAAA,CAAA8C,EAAA,GACA1E,EAAA8B,EAAAxB,MAAA,EAAAuG,KAAAC,GAAA,MAAA2D,QAAA,CAAArL,KACA,KAAAuL,KAAA,CAAA1M,IAAA,CAAA6D,GACA,KAAA9B,KAAA,CAAA/B,IAAA,CAAA+B,GACA,KAAA4B,KAAA,CAAA3D,IAAA,IAEA,MAEA,KAAA2D,KAAA,CAAA8C,EAAA,GACA,KAAAsG,SAAA,CAAAhL,EAAA8B,EAAAxB,MAAA,CAGA,CACA,CACA,MAAAiL,EACAxM,YAAAmB,CAAA,CAAAuC,CAAA,EACA,KAAAA,MAAA,CAAAA,EACA,KAAA+I,MAAA,IACA,KAAAC,SAAA,MACA,KAAAC,OAAA,IACA,KAAAF,MAAA,CAAAtL,EAAAyL,UAAA,CAAAC,GAAA,CAAA/L,GAAA,IAAA0F,EACA,CACAsG,WAAA5M,CAAA,EACA,IAAA6M,EAAA,EACAC,EAAc,IAAS,CACvB,CAAA7L,OAAAA,CAAA,EAAAjB,EAAAD,CAAA,EAAA2M,WAAAA,CAAA,EAAAzL,EACAuF,EAAAvF,EAAAiD,SAAA,CAAAlE,EAAAC,KAAA,IACAiB,EAAAlB,EAAAO,UAAA,CAAAP,EAAAO,UAAA,CAAAmF,IAAA,GACAlF,EAAwB,EACxB,QAAAK,EAAA,EAAAA,EAAA6L,EAAArL,MAAA,CAAAR,IAAA,CACA,OAAAA,EAAA2F,CAAA,KACA,SACA,IAAAuG,EAAAL,CAAA,CAAA7L,EAAA,CAAAoG,EAAA,KAAAsF,MAAA,CAAA1L,EAAA,CACA,GAAAiM,CAAAA,CAAAA,GAAAC,EAAAtD,QAAA,IAEAsD,CAAAA,EAAAvD,UAAA,EAAAvC,EAAAlG,KAAA,EAAAf,EAAAG,GAAA,EAAA8G,EAAAT,IAAA,EAAAA,GAAAS,EAAA/F,OAAA,EAAAA,CAAA,IACA,KAAA8L,iBAAA,CAAA/F,EAAA8F,EAAA/M,GACAiH,EAAAT,IAAA,CAAAA,EACAS,EAAA/F,OAAA,CAAAA,GAEA+F,EAAAzG,SAAA,CAAAyG,EAAA3E,GAAA,KACA9B,CAAAA,EAAAoH,KAAAC,GAAA,CAAAZ,EAAAzG,SAAA,CAAAA,EAAA,EACAyG,GAAAA,EAAA9D,KAAA,GACA,IAAA8J,EAAAJ,EAIA,GAHA5F,EAAAV,QAAA,KACAsG,CAAAA,EAAA,KAAAK,UAAA,CAAAlN,EAAAiH,EAAAV,QAAA,CAAAU,EAAA3E,GAAA,CAAAuK,EAAA,EACAA,EAAA,KAAAK,UAAA,CAAAlN,EAAAiH,EAAA9D,KAAA,CAAA8D,EAAA3E,GAAA,CAAAuK,GACA,CAAAE,EAAArD,MAAA,GACAoD,EAAA7F,EACA4F,EAAAI,GACA,MAhBA,CAoBA,UAAAR,OAAA,CAAApL,MAAA,CAAAwL,GACA,KAAAJ,OAAA,CAAArK,GAAA,GAUA,OATA5B,GACAR,EAAA6F,YAAA,CAAArF,GACAsM,GAAA9M,EAAAG,GAAA,OAAAqD,MAAA,CAAAlB,GAAA,GAEAwK,CADAA,EAAA,IAAAxG,CAAA,EACAnD,KAAA,CAAAnD,EAAAD,CAAA,CAAAkB,MAAA,CAAAkM,OAAA,CACAL,EAAA/L,KAAA,CAAA+L,EAAAxK,GAAA,CAAAtC,EAAAG,GAAA,CACA0M,EAAA,KAAAK,UAAA,CAAAlN,EAAA8M,EAAA3J,KAAA,CAAA2J,EAAAxK,GAAA,CAAAuK,IAEA,KAAAL,SAAA,CAAAM,EACA,KAAAL,OAAA,CAEAW,aAAApN,CAAA,EACA,QAAAwM,SAAA,CACA,YAAAA,SAAA,CACA,IAAAM,EAAA,IAAAxG,EAAA,CAAAnG,IAAAA,CAAA,CAAAJ,EAAAA,CAAA,EAAAC,EAIA,OAHA8M,EAAA/L,KAAA,CAAAZ,EACA2M,EAAAxK,GAAA,CAAAsF,KAAAe,GAAA,CAAAxI,EAAA,EAAAJ,EAAAyD,MAAA,CAAAlB,GAAA,EACAwK,EAAA3J,KAAA,CAAAhD,GAAAJ,EAAAyD,MAAA,CAAAlB,GAAA,CAAAvC,EAAAkB,MAAA,CAAAkM,OAAA,GACAL,CACA,CACAE,kBAAA/F,CAAA,CAAA8F,CAAA,CAAA/M,CAAA,EACA,IAAAe,EAAA,KAAAyC,MAAA,CAAAmE,OAAA,CAAA3H,EAAAG,GAAA,EAEA,GADA4M,EAAA9F,KAAA,MAAAzD,MAAA,CAAAC,KAAA,CAAA1C,EAAAkG,GAAAjH,GACAiH,EAAkB9D,KAAA,IAAS,CAC3B,IAAAlC,OAAAA,CAAA,EAA4BjB,EAAAD,CAAA,CAC5B,QAAAc,EAAA,EAAAA,EAAAI,EAAAoM,WAAA,CAAAhM,MAAA,CAAAR,IACA,GAAAI,EAAAoM,WAAA,CAAAxM,EAAA,EAAAoG,EAAA9D,KAAA,EACA,IAAAuB,EAAAzD,EAAAqM,YAAA,CAAAzM,EAAA,MAAA2C,MAAA,CAAAiF,IAAA,CAAAxB,EAAAlG,KAAA,CAAAkG,EAAA3E,GAAA,EAAAtC,GACA,GAAA0E,GAAA,GAAA1E,EAAAD,CAAA,CAAAkB,MAAA,CAAAqE,OAAA,CAAA4D,MAAA,CAAAxE,GAAA,IACA,CAAAA,EAAAA,CAAA,KACAuC,EAAA9D,KAAA,CAAAuB,GAAA,EAEAuC,EAAAV,QAAA,CAAA7B,GAAA,EACA,MACA,CACA,MAGAuC,EAAA9D,KAAA,GACA8D,EAAA3E,GAAA,MAAAkB,MAAA,CAAAmE,OAAA,CAAA5G,EAAA,EACA,CAEAwM,UAAAhM,CAAA,CAAA0F,CAAA,CAAA3E,CAAA,CAAAK,CAAA,EAEA,QAAA9B,EAAA,EAAAA,EAAA8B,EAAA9B,GAAA,EACA,QAAA4L,OAAA,CAAA5L,EAAA,EAAAU,EACA,OAAAoB,CAAA,CAIA,OAHA,KAAA8J,OAAA,CAAA9J,IAAA,CAAApB,EACA,KAAAkL,OAAA,CAAA9J,IAAA,CAAAsE,EACA,KAAAwF,OAAA,CAAA9J,IAAA,CAAAL,EACAK,CACA,CACAuK,WAAclN,CAAA,CAAQiH,CAAA,CAAA3E,CAAA,CAAWK,CAAA,EACjC,IAAA1C,MAAAA,CAAA,EAAAD,EAA0B,CAAAiB,OAAAA,CAAS,EAAAjB,EAAAD,CAAA,EAAAiF,KAAAA,CAAA,EAAA/D,EACnC,QAAAuM,EAAA,EAAAA,EAAA,EAAAA,IACA,QAAA3M,EAAAI,EAAAiD,SAAA,CAAAjE,EAAAuN,EAAA,MAAA3M,GAAA,GACA,GAAAmE,OAAAA,CAAA,CAAAnE,EAAA,EACA,GAAAmE,GAAAA,CAAA,CAAAnE,EAAA,GACAA,EAAA4M,EAAAzI,EAAAnE,EAAA,OAEA,CACA,GAAA8B,GAAAqC,GAAAA,CAAA,CAAAnE,EAAA,IACA8B,CAAAA,EAAA,KAAA4K,SAAA,CAAAE,EAAAzI,EAAAnE,EAAA,GAAAoG,EAAA3E,EAAAK,EAAA,EACA,MACA,CACA,CACA,CAAA9B,EAAA,EAAAoG,GACAtE,CAAAA,EAAA,KAAA4K,SAAA,CAAAE,EAAAzI,EAAAnE,EAAA,GAAAoG,EAAA3E,EAAAK,EAAA,CACA,CAEA,OAAAA,CACA,CACA,CAGAjD,CADAA,EAYAA,GAAAA,CAAAA,EAAA,IAXA,CAAAA,EAAA,uBACAA,CAAA,CAAAA,EAAA,6CAGAA,CAAA,CAAAA,EAAA,iDACAA,CAAA,CAAAA,EAAA,wCAIAA,CAAA,CAAAA,EAAA,0BACCA,CAAA,CAAAA,EAAA,KAAkB,aAEnB,OAAAgO,EACA5N,YAAAmB,CAAA,CAAA0F,CAAA,CAAA0E,CAAA,CAAAzE,CAAA,EACA,KAAA3F,MAAA,CAAAA,EACA,KAAA0F,KAAA,CAAAA,EACA,KAAAC,MAAA,CAAAA,EACA,KAAA+G,UAAA,GACA,KAAAC,WAAA,MACA,KAAAC,WAAA,GACA,KAAAzK,MAAA,IACA,KAAA0K,SAAA,MACA,KAAAtK,MAAA,KAAAkD,EAAAC,EAAAC,GACA,KAAA2F,MAAA,KAAAD,EAAArL,EAAA,KAAAuC,MAAA,EACA,KAAAuK,OAAc,CAAO9M,EAAAyB,GAAA,IACrB,IAAA0E,KAAAA,CAAA,EAAAR,CAAA,IACA,KAAAoH,MAAA,EAAAnO,EAAAkB,KAAA,MAAAE,EAAAyB,GAAA,IAAA0E,GAAA,CACA,KAAAiE,SAAA,CAAAA,EAAAhK,MAAA,OAAAmC,MAAA,CAAAlB,GAAA,CAAA8E,EAAAnG,EAAAA,EAAAgN,YAAA,CACA,IAAA7C,EAAAC,EAAApK,EAAAqK,OAAA,OAEA,IAAA4C,WAAA,CACA,YAAAL,WAAA,CAQAvF,SAAA,CACA,IAGA6F,EAAAC,EAHAJ,EAAA,KAAAA,MAAA,CAAA7N,EAAA,KAAA0N,WAAA,CAEAQ,EAAA,KAAAL,MAAA,IAKA,QAAAnN,EAAA,EAAAA,EAAAmN,EAAA3M,MAAA,CAAAR,IAAA,CACA,IAAAb,EAAmBgO,CAAA,CAAAnN,EAAA,CACnB,QAEA,GADA,KAAA0L,MAAA,CAAAC,SAAA,MACAxM,EAAAG,GAAA,CAAAA,EACAkO,EAAArP,IAAA,CAAAgB,OAKA,CAHA,QAAAsO,YAAA,CAAAtO,EAAAqO,EAAAL,GACA,SAGAG,IACAA,EAAA,GACAC,EAAA,IAEAD,EAAAnP,IAAA,CAAAgB,GACA,IAAAuO,EAAA,KAAAhC,MAAA,CAAAa,YAAA,CAAApN,GACAoO,EAAApP,IAAA,CAAAuP,EAAApL,KAAA,CAAAoL,EAAAjM,GAAA,CACA,MACA,CAEA,CACA,IAAA+L,EAAAhN,MAAA,EACA,IAAAmN,EAAAL,GAAAM,SA6eAT,CAAA,EACA,IAAA1J,EAAA,KACA,QAAAtE,KAAAgO,EAAA,CACA,IAAAG,EAAAnO,EAAAD,CAAA,CAAA+N,SAAA,CACA9N,CAAAA,EAAAG,GAAA,EAAAH,EAAAD,CAAA,CAAAyD,MAAA,CAAAlB,GAAA,EAAA6L,IAAA,EAAAA,GAAAnO,EAAAG,GAAA,CAAAgO,CAAA,GACAnO,EAAAD,CAAA,CAAAkB,MAAA,CAAAiB,SAAA,CAAAlC,EAAAC,KAAA,KACA,EAAAqE,GAAAA,EAAAlE,KAAA,CAAAJ,EAAAI,KAAA,GACAkE,CAAAA,EAAAtE,CAAA,CACA,CACA,OAAAsE,CACA,EAvfA6J,GACA,GAAAK,EACA,YAAAE,WAAA,CAAAF,EAAA,CACA,QAAAvN,MAAA,CAAA8E,MAAA,CAGA,MAFAoE,GAAAgE,GACAQ,QAAAC,GAAA,2BAAArC,MAAA,CAAAC,SAAA,MAAAvL,MAAA,CAAA4N,OAAA,MAAAtC,MAAA,CAAAC,SAAA,CAAArJ,KAAA,WACA,2BAAAhD,EAAA,CAEA,KAAAwN,UAAA,EACA,MAAAA,UAAA,GACA,IACA,KAAAA,UAAA,EAAAQ,EAAA,CACA,IAAAK,EAAA,WAAAV,SAAA,EAAAK,CAAA,IAAAhO,GAAA,MAAA2N,SAAA,CAAAK,CAAA,IACA,KAAAW,WAAA,CAAAX,EAAAC,EAAAC,EAAA,CACA,GAAAG,EACA,YAAAE,WAAA,CAAAF,EAAA1J,QAAA,IACA,GACA,KAAA6I,UAAA,EACA,IAAAoB,EAAA,QAAApB,UAAA,UAAAA,UAAA,CACA,GAAAU,EAAAhN,MAAA,CAAA0N,EAEA,IADAV,EAAAW,IAAA,EAAAC,EAAAC,IAAAA,EAAA9O,KAAA,CAAA6O,EAAA7O,KAAA,EACAiO,EAAAhN,MAAA,CAAA0N,GACAV,EAAAjM,GAAA,EACA,CACAiM,EAAA7J,IAAA,CAAAD,GAAAA,EAAArE,SAAA,CAAAC,IACA,KAAAwN,UAAA,EACA,MACA,GAAAU,EAAAhN,MAAA,GAIA8N,EAAA,QAAAtO,EAAA,EAAAA,EAAAwN,EAAAhN,MAAA,GAAAR,IAAA,CACA,IAAAb,EAAAqO,CAAoC,CAAAxN,EAAA,CACpC,QAAAuO,EAAAvO,EAAA,EAAAuO,EAAAf,EAAAhN,MAAA,CAAA+N,IAAA,CACA,IAAAjK,EAAAkJ,CAAA,CAAAe,EAAA,CACA,GAAApP,EAAAkF,SAAA,CAAAC,IACAnF,EAAAK,MAAA,CAAAgB,MAAA,MAAA8D,EAAA9E,MAAA,CAAAgB,MAAA,MACA,MAAAjB,KAAA,CAAA+E,EAAA/E,KAAA,EAAAJ,EAAAK,MAAA,CAAAgB,MAAA,CAAA8D,EAAA9E,MAAA,CAAAgB,MAAA,IACAgN,EAAAgB,MAAA,CAAAD,IAAA,OAEA,CACAf,EAAAgB,MAAA,CAAAxO,IAAA,GACA,SAAAsO,CAAA,CACA,CACA,CAEA,CACA,IACA,CAAAtB,WAAwB,CAAAQ,CAAA,IAAAlO,GAAA,CACxB,QAAAU,EAAA,EAAAA,EAAAwN,EAAAhN,MAAA,CAAAR,IACAwN,CAAA,CAAAxN,EAAA,CAAAV,GAAA,MAAA0N,WAAA,EACA,MAAAA,WAAA,CAAAQ,CAAA,CAAAxN,EAAA,CAAAV,GAAA,EACA,YAEAmP,OAAAnP,CAAA,EACA,cAAA2N,SAAA,OAAAA,SAAA,CAAA3N,EACA,iDACA,KAAA2N,SAAA,CAAA3N,CACA,CAKAmO,aAAAtO,CAAA,CAAAgO,CAAA,CAAAtK,CAAiC,EACjC,IAAA3C,EAAAf,EAAAG,GAAA,EAAAc,OAAAA,CAAA,OACAe,EAAAmI,EAAA,KAAAoF,OAAA,CAAAvP,GAAA,UACA,cAAA8N,SAAA,EAAA/M,EAAA,KAAA+M,SAAA,CACA,OAAA9N,EAAA2E,WAAA,GAAA3E,EAAA,KACA,QAAAqL,SAAA,EACA,IAAAmE,EAAAxP,EAAAO,UAAA,EAAAP,EAAAO,UAA4D,CAAA+C,OAAO,CAAAyC,MAAA,CAAA0J,EAAAD,EAAAxP,EAAAO,UAAA,CAAAmF,IAAA,GACnE,QAAAgK,EAAA,KAAArE,SAAA,CAAAW,MAAA,CAAAjL,GAAA2O,GAAA,CACA,IAAAC,EAAA,KAAA1O,MAAA,CAAAqK,OAAA,CAAAsE,KAAA,CAAAF,EAAAjO,IAAA,CAAA2E,EAAA,GAAAsJ,EAA8EjO,IAAA,CAAAR,EAAAW,OAAA,CAAA5B,EAAAC,KAAA,CAAAyP,EAAAjO,IAAA,CAAA2E,EAAA,KAC9E,GAAAuJ,EAAA,IAAAD,EAAArO,MAAA,IAAAmO,GAAA,CAAAE,EAAAtD,IAAA,CAAAzM,EAAA0M,EAAA,CAAAwD,WAAA,OAAAJ,CAAA,EAIA,OAHAzP,EAAAkD,OAAA,CAAAwM,EAAAC,GACAxF,GACAwE,QAAAC,GAAA,CAAA5M,EAAA,KAAAuN,OAAA,CAAAvP,GAAA,kBAAAiB,EAAA4N,OAAA,CAAAa,EAAAjO,IAAA,CAAA2E,EAAA,MACA,EACA,CACA,IAAAsJ,CAAAA,aAAA/P,EAAAwM,EAAA,GAAAuD,GAAAA,EAAAzD,QAAA,CAAA5K,MAAA,EAAAqO,EAAAxD,SAAA,MACA,MACA,IAAA4D,EAAAJ,EAAAzD,QAAqC,IACrC,GAAA6D,aAAAnQ,EAAAwM,EAAA,EAAAuD,GAAAA,EAAAxD,SAAA,IACAwD,EAAAI,OAEA,MAEA,KACAC,EAAA9O,EAAAiD,SAAA,CAAAlE,EAAAC,KAAA,IACA,GAAA8P,EAAA,EAIA,OAHA/P,EAAAsB,MAAA,CAAAyO,GACA5F,GACAwE,QAAAC,GAAA,CAAA5M,EAAA,KAAAuN,OAAA,CAAAvP,GAAA,uBAAAiB,EAAA4N,OAAA,CAAAkB,MAAAA,GAAA,IACA,EACA,CACA,GAAA/P,EAAAA,KAAA,CAAAqB,MAAA,OACA,KAAArB,EAAAA,KAAA,CAAAqB,MAAA,MAAArB,EAAA2E,WAAA,KACA,IACA8H,EAAA,IAAwB,CAAAF,MAAA,CAAAK,UAAmB,CAAA5M,GAC3C,QAAAa,EAAA,EAAAA,EAAA4L,EAAApL,MAAA,GACA,IAAAE,EAAAkL,CAAA,CAAA5L,IAAA,CAAAwB,EAAAoK,CAAA,CAAA5L,IAAA,CAAAyB,EAAAmK,CAAA,CAAA5L,IAAA,CACA4E,EAAA5E,GAAA4L,EAAApL,MAAA,GAAAqC,EACAsM,EAAAvK,EAAAzF,EAAAA,EAAA0D,KAAA,GAKA,GAJAsM,EAAA/M,KAAA,CAAA1B,EAAAc,EAAAC,GACA6H,GACAwE,QAAAC,GAAA,CAAA5M,EAAmC,KAAAuN,OAAA,CAAAS,GAAA,UAAAzO,MAAAA,CAAkD,GAAM,UAC3F,aAAAN,EAAA4N,OAAA,CAAAtN,MAAAA,GAAA,SAAAN,EAAA4N,OAAA,CAAAxM,GAAA,KAAAtB,EAAA,EAAAiP,GAAAhQ,EAAA,iBACAyF,EACA,QAIA,CAHAuK,EAAA7P,GAAA,CAAAY,EACAiN,EAAAhP,IAAA,CAAAgR,GAEAtM,EAAA1E,IAAA,CAAAgR,EACA,CACA,QACA,CAIAC,aAAAjQ,CAAA,CAAAqO,CAAA,EACA,IAAAlO,EAAeH,EAAAG,GAAA,CACf,QACA,SAAAmO,YAAA,CAAAtO,EAAA,WACA,SACA,GAAAA,EAAAG,GAAA,CAAAA,EAEA,OADA+P,EAAAlQ,EAAAqO,GACA,EACA,CAEA,CACAS,YAAAd,CAAA,CAAAzB,CAAA,CAAA8B,CAAA,EACA,IAAAG,EAAA,IAAwB,CAAA2B,EAAA,GACxB,QAAAtP,EAAA,EAAAA,EAAAmN,EAAA3M,MAAA,CAAAR,IAAA,CACA,IAAAb,EAAAgO,CAAA,CAAAnN,EAAA,CAAAoG,EAAAsF,CAAA,CAAA1L,GAAA,GAAAuP,EAAA7D,CAAA,EAAA1L,GAAA,MACAmB,EAAAmI,EAAA,KAAAoF,OAAA,CAAAvP,GAAA,UACA,GAAAA,EAAA+E,OAAA,GACAoL,IAEAA,EAAA,GACAnQ,EAAAiF,OAAA,GACAkF,GACAwE,QAAAC,GAAA,CAAA5M,EAAA,KAAAuN,OAAA,CAAAvP,GAAA,gBACA,KAAAiQ,YAAA,CAAAjQ,EAAAqO,KALA,SASA,IAAAgC,EAAArQ,EAA4B0D,KAAA,GAAA4M,EAAAtO,EAC5B,QAAAoN,EAAA,EAIA,EAJAzK,WAAA,IAAAyK,EAAA,KACAjF,GACAwE,QAAAC,GAAA,CAAA0B,EAAA,KAAAf,OAAA,CAAAc,GAAA,wBACA,KAAAJ,YAAA,CAAAI,EAAAhC,IAHAe,IAMAjF,GACAmG,CAAAA,EAAA,KAAAf,OAAA,CAAAc,GAAA,QAEA,QAAAE,KAAAvQ,EAAAoE,eAAA,CAAA6C,GACAkD,GACAwE,QAAAC,GAAA,CAAA5M,EAAA,KAAAuN,OAAA,CAAAgB,GAAA,yBACA,KAAAN,YAAA,CAAAM,EAAAlC,EAEA,MAAA7K,MAAA,CAAAlB,GAAA,CAAAtC,EAAAG,GAAA,EACAiQ,GAAApQ,EAAAG,GAAA,GACAiQ,IACAnJ,EAAA,GAEAjH,EAAA6D,eAAA,CAAAoD,EAAAmJ,GACAjG,GACAwE,QAAAC,GAAA,CAAA5M,EAAA,KAAAuN,OAAA,CAAAvP,GAAA,6BAAAiB,MAAA,CAAA4N,OAAA,CAAA5H,GAAA,IACAiJ,EAAAlQ,EAAAqO,IAEA,EAAAG,GAAAA,EAAApO,KAAA,CAAAJ,EAAAI,KAAA,GACAoO,CAAAA,EAAAxO,CAAA,CAEA,CACA,OAAAwO,CACA,CAEAE,YAAA1O,CAAA,EAEA,OADAA,EAAA8F,KAAe,GACfnG,EAAAwM,EAAA,CAAAqE,KAAA,EAAAnQ,OAAA4F,EAAAE,MAAA,CAAAnG,GACAsL,QAAA,KAAArK,MAAA,CAAAqK,OAAA,CACAmF,MAAA,KAAA1C,OAAA,CACA2C,gBAAA,KAAAzP,MAAA,CAAAgN,YAAA,CACA7K,OAAA,KAAAA,MAAA,CACArC,MAAA,KAAA6F,MAAA,IAAAQ,IAAA,CACA/F,OAAArB,EAAAG,GAAA,MAAAyG,MAAA,IAAAQ,IAAA,CACAuJ,cAAA,KAAA1P,MAAA,CAAAY,aAAA,EACA,CACA0N,QAAAvP,CAAA,EACA,IAAAoG,EAAA,CAAAmE,GAAAA,CAAAA,EAAA,IAAAqG,OAAA,GAAAC,GAAA,CAAA7Q,GAGA,OAFAoG,GACAmE,EAAAiD,GAAA,CAAAxN,EAAAoG,EAAA0K,OAAAC,aAAA,MAAAnD,WAAA,KACAxH,EAAApG,CACA,CACA,CACA,SAAAkQ,EAAoBlQ,CAAA,CAAAqO,CAAA,CAAsB,CAC1C,QAAAxN,EAAA,EAAAA,EAAAwN,EAAAhN,MAAA,CAAAR,IAAA,CACA,IAAAsE,EAAAkJ,CAAA,CAAAxN,EAAA,CACA,GAAAsE,EAAAhF,GAAA,EAAAH,EAAAG,GAAA,EAAAgF,EAAAD,SAAA,CAAAlF,GAAA,CACAqO,CAAA,CAAAxN,EAAA,CAAAT,KAAA,CAAAJ,EAAAI,KAAA,EACAiO,CAAAA,CAAA,CAAAxN,EAAA,CAAAb,CAAA,EACA,MACA,EAEAqO,EAAArP,IAAA,CAAAgB,EACA,CACA,MAAAgR,EACAlR,YAAAmR,CAAA,CAAA1L,CAAA,CAAA2L,CAAA,EACA,KAAAD,MAAA,CAAAA,EACA,KAAA1L,KAAA,CAAAA,EACA,KAAA2L,QAAA,CAAAA,CACA,CACAhI,OAAA7G,CAAA,cAAA6O,QAAA,UAAAA,QAAA,CAAA7O,EAAA,CACA,CACA,IAAA+D,EAAA+K,GAAAA,CAWA,OAAA9R,EAEAS,YAAAsR,CAAA,EACA,KAAArQ,KAAA,CAAAqQ,EAAArQ,KAAA,CACA,KAAA6B,KAAA,CAAAwO,EAAAxO,KAAA,EAAAwD,EACA,KAAA9E,MAAA,CAAA8P,EAAA9P,MAAA,EAAA8E,EACA,KAAA7C,KAAA,CAAA6N,EAAA7N,KAAA,EAAA6C,EACA,KAAAV,IAAA,CAAA0L,EAAA1L,IAAA,UACA,KAAAK,MAAA,CAAAqL,CAAA,IAAAA,EAAArL,MAAA,CAEA,CAIA,MAAAxG,UAAAI,EAAA0R,EAAA,CAEAvR,YAAAsR,CAAA,EAIA,GAHA,QAEA,KAAAE,QAAA,IACAF,IAAAA,EAAAG,OAAA,CACA,oCAAAH,EAAAG,OAAA,wCACA,IAAAC,EAAAJ,EAAAI,SAAA,CAAA9N,KAAA,KACA,MAAA7B,aAAwB,CAAA2P,EAAAnQ,MAAA,CACxB,QAAAR,EAAA,EAAAA,EAAAuQ,EAAAK,eAAA,CAAA5Q,IACA2Q,EAAAxS,IAAA,KACA,IAAA0S,EAAAC,OAAAC,IAAA,CAAAR,EAAAS,QAAA,EAAAlF,GAAA,CAAAjE,GAAA0I,EAAAS,QAAA,CAAAnJ,EAAA,KACAoJ,EAAwB,GACxB,QAAAjR,EAAA,EAAAA,EAAA2Q,EAAAnQ,MAAA,CAAAR,IACAiR,EAAA9S,IAAA,KACA,SAAA+S,EAAAC,CAAA,CAAA5F,CAAA,CAAAjJ,CAAA,EACA2O,CAAA,CAAAE,EAAA,CAAAhT,IAAA,EAAAoN,EAAAA,EAAA6F,WAAA,CAAAnB,OAAA3N,IAAA,CACA,CACA,GAAAiO,EAAAU,SAAA,CACA,QAAAI,KAAAd,EAAAU,SAAA,EACA,IAAA1F,EAAA8F,CAAA,IAC2B,UAA3B,OAA2B9F,GAC3BA,CAAAA,EAAAzM,EAAoD0M,EAAA,CAAAD,EAAA,EACpD,QAAAvL,EAAA,EAAAA,EAAAqR,EAAA7Q,MAAA,GACA,IAAAwB,EAAAqP,CAAA,CAAArR,IAAA,CACA,GAAAgC,GAAA,EACAkP,EAAAlP,EAAAuJ,EAAA8F,CAAA,CAAArR,IAAA,MAEA,CACA,IAAAsC,EAAA+O,CAA4C,CAAArR,EAAA,CAAAgC,EAAO,CACnD,QAAAuM,EAAA,CAAAvM,EAAAuM,EAAA,EAAAA,IACA2C,EAAAG,CAAA,CAAArR,IAAA,CAAAuL,EAAAjJ,EACAtC,CAAAA,GACA,EAEA,KACA,CAAAyK,OAAA,KAAA3L,EAAAwS,EAAA,CAAAX,EAAA7E,GAAA,EAAAyF,EAAAvR,IAAAlB,EAAA0S,EAAA,CAAAC,MAAA,EACAF,KAAAvR,GAAA,KAAAgB,aAAA,CAAA0Q,KAAAA,EAAAH,CAAA,CACAhM,GAAAvF,EACA2R,MAAAV,CAAA,CAAAjR,EAAA,CACA6B,IAAAgP,EAAAe,OAAA,CAAA5R,GAAA,GACA6R,MAAA7R,GAAAA,EACS8R,QAAAvB,EAAAwB,YAAA,EAAAxB,EAAAwB,YAAA,CAAAH,OAAA,CAAA5R,GAAA,EACT,KACAuQ,EAAAyB,WAAA,EACA,MAAAvH,OAAA,MAAAA,OAAA,CAAA5B,MAAA,IAAA0H,EAAAyB,WAAA,GACA,KAAA9M,MAAA,IACA,KAAAkI,YAAA,CAAAtO,EAAAmT,EAAA,CACA,IAAAC,EAAAnJ,EAAAwH,EAAA4B,SAAA,CACA,MAAA9R,OAAA,CAAAkQ,EAAAlQ,OAAA,CACA,KAAA+R,gBAAA,CAAA7B,EAAA/D,WAAA,KACA,KAAAA,WAAwB,KAAAvD,YAAA,KAAAmJ,gBAAkC,CAAA5R,MAAA,EAC1D,QAAAR,EAAA,EAAAA,EAAA,KAAAoS,gBAAA,CAAA5R,MAAA,CAAAR,IACA,KAAAwM,WAAA,CAAAxM,EAAA,MAAAoS,gBAAA,CAAApS,EAAA,CAAAwB,IAAA,CACA,KAAAiL,YAAA,MAAA2F,gBAAA,CAAAtG,GAAA,CAAAuG,GACA,KAAAC,MAAA,CAAAvJ,EAAAwH,EAAA+B,MAAA,CAAAC,aACA,KAAApO,IAAA,CAAA4E,EAAAwH,EAAAiC,SAAA,EACA,KAAArN,IAAA,CAAA4D,EAAAwH,EAAApL,IAAA,EACA,KAAAsN,OAAA,CAAAlC,EAAAkC,OAAA,CACA,KAAA5G,UAAA,CAAA0E,EAAA1E,UAAA,CAAAC,GAAA,CAAAxJ,GAAA,iBAAAA,EAAA,IAAAyF,EAAAmK,EAAA5P,GAAAA,CAAA,EACA,KAAA0O,QAAA,CAAAT,EAAAS,QAAA,CACA,KAAA0B,QAAA,CAAAnC,EAAAmC,QAAA,KACA,KAAAC,kBAAA,CAAApC,EAAAoC,kBAAA,OACA,KAAAC,cAAA,CAAArC,EAAAsC,SAAA,CACA,KAAAC,SAAA,CAAAvC,EAAAuC,SAAA,OACA,KAAA5Q,OAAA,MAAAuI,OAAA,CAAAsE,KAAA,CAAAvO,MAAA,GACA,KAAAiE,OAAA,MAAAsO,YAAA,GACA,KAAAlR,GAAA,MAAAmP,QAAA,CAAAF,OAAAC,IAAA,MAAAC,QAAA,MAEAgC,YAAAlN,CAAA,CAAA0E,CAAA,CAAAzE,CAAA,EACA,IAAAkN,EAAA,IAAApG,EAAA,KAAA/G,EAAA0E,EAAAzE,GACA,QAAAmN,KAAA,KAAAzC,QAAA,CACAwC,EAAAC,EAAAD,EAAAnN,EAAA0E,EAAAzE,GACA,OAAAkN,CACA,CAEAlS,QAAA3B,CAAA,CAAAoC,CAAA,CAAA2R,EAAA,IACA,IAAAC,EAAA,KAAAjO,IAAA,CACA,GAAA3D,GAAA4R,CAAA,IACA,UACA,QAAA9T,EAAA8T,CAAA,CAAA5R,EAAA,MACA,IAAA6R,EAAAD,CAAA,CAAA9T,IAAA,CAAAsF,EAAAyO,EAAAA,EACArP,EAAAoP,CAAA,CAAA9T,IAAA,CACA,GAAAsF,GAAAuO,EACA,OAAAnP,CAAA,CACA,QAAAvC,EAAAnC,EAAA+T,CAAAA,GAAA,GAAA/T,EAAAmC,EAAAnC,IACA,GAAA8T,CAAA,CAAA9T,EAAA,EAAAF,EACA,OAAA4E,CAAA,CACA,GAAAY,EACA,UAEA,CAEAtB,UAAAlE,CAAA,CAAAkU,CAAA,EACA,IAAAnP,EAAA,KAAAA,IAA0B,CAC1B,QAAAwI,EAAA,EAAAA,EAAA,EAAAA,IACA,QAAA3M,EAAA,KAAAqD,SAAA,CAAAjE,EAAAuN,EAAA,KAAA3K,GAAAhC,GAAA,GACA,UAAAgC,CAAAA,EAAAmC,CAAA,CAAAnE,EAAA,GACA,GAAAmE,GAAAA,CAAA,CAAAnE,EAAA,GACAgC,EAAAmC,CAAA,CAAAnE,EAAA4M,EAAAzI,EAAAnE,EAAA,SACA,GAAAmE,GAAAA,CAAA,CAAAnE,EAAA,GACA,OAAA4M,EAAAzI,EAAAnE,EAAA,QAEA,MACA,GACAgC,GAAAsR,GAAAtR,GAAAA,EACA,OAAA4K,EAAAzI,EAAAnE,EAAA,GAGA,QACA,CAEAqD,UAAAjE,CAAA,CAAAmU,CAAA,EACA,YAAAjB,MAAA,GAAAlT,EAAAmU,EAAA,CAGAlS,UAAAjC,CAAA,CAAAoU,CAAA,EACA,YAAAnQ,SAAA,CAAAjE,EAAA,GAAAoU,CAAA,GACA,CAEAzP,YAAA3E,CAAA,CAAAsB,CAAA,EACA,GAAAA,GAAA,KAAA2C,SAAA,CAAAjE,EAAA,GACA,SACA,QAAAY,EAAA,KAAAqD,SAAA,CAAAjE,EAAA,IAAAY,GAAA,GACA,eAAAmE,IAAA,CAAAnE,EAAA,EACA,WAAAmE,IAAA,CAAAnE,EAAA,GAGA,SAFAA,EAAA4M,EAAA,KAAAzI,IAAA,CAAAnE,EAAA,EAGA,IACAU,GAAAkM,EAAA,KAAAzI,IAAA,CAAAnE,EAAA,GACA,SAEA,CAGAwD,WAAApE,CAAA,EACA,IAAAyE,EAAA,GACA,QAAA7D,EAAA,KAAAqD,SAAA,CAAAjE,EAAA,IAAAY,GAAA,GACA,eAAAmE,IAAA,CAAAnE,EAAA,EACA,WAAAmE,IAAA,CAAAnE,EAAA,GACAA,EAAA4M,EAAA,KAAAzI,IAAA,CAAAnE,EAAA,QAEA,MACA,GACA,QAAAmE,IAAA,CAAAnE,EAAA,QACA,IAAAsC,EAAA,KAAA6B,IAAA,CAAAnE,EAAA,GACA6D,EAAAF,IAAA,EAAAC,EAAA5D,IAAA,EAAAA,GAAA4D,GAAAtB,IACAuB,EAAA1F,IAAA,MAAAgG,IAAA,CAAAnE,EAAA,CAAAsC,EACA,EAEA,OAAAuB,CACA,CAEAyE,UAAAlC,CAAA,CAAAqN,CAAA,EACA,IAAAC,EAAAC,EAAA,KAAAxP,IAAA,MAAAyO,cAAA,CAAAa,GACA,OAAAC,EAAA,GAAAC,EAAA,KAAAxP,IAAA,MAAAyO,cAAA,CAAAxM,GAAAsN,CACA,CAIAE,UAAAC,CAAA,EAGA,IAAAC,EAAAhD,OAAAiD,MAAA,CAAAjD,OAAAxL,MAAA,CAAA5G,EAAAgK,SAAA,QAGA,GAFAmL,EAAAlC,KAAA,EACAmC,CAAAA,EAAArJ,OAAA,MAAAA,OAAA,CAAA5B,MAAA,IAAAgL,EAAAlC,KAAA,GACAkC,EAAAhS,GAAA,EACA,IAAAmS,EAAA,KAAAhD,QAAA,CAAA6C,EAAAhS,GAAA,EACA,IAAAmS,EACA,0CAAAH,EAAAhS,GAAA,IACAiS,EAAAjS,GAAA,CAAAmS,CACA,QACAH,EAAAhI,UAAA,EACAiI,CAAAA,EAAAjI,UAAA,MAAAA,UAAA,CAAAC,GAAA,CAAAmI,GAAA,CACA,IAAAC,EAAAL,EAAAhI,UAAA,CAAAsI,IAAA,CAAAtM,GAAAA,EAAAtB,IAAA,EAAA0N,GACa,OAAAC,EAAAA,EAAAzN,EAAA,CAAAwN,CAAA,EACb,EACAJ,EAAApH,YAAA,GACAqH,EAAArH,YAAA,MAAAA,YAAA,CAAA1J,KAAA,GACA+Q,EAAA1B,gBAAA,MAAAA,gBAAA,CAAAtG,GAAA,EAAApI,EAAA1D,IAAA,CACA,IAAAkU,EAAAL,EAAApH,YAAA,CAAA0H,IAAA,CAAAtM,GAAAA,EAAAtB,IAAA,EAAA7C,EAAA0Q,QAAA,EACA,IAAAF,EACA,OAAAxQ,CAAA,CACA,IAAA6M,EAAAO,OAAAiD,MAAA,CAAAjD,OAAAiD,MAAA,IAAArQ,GAAA,CAAA0Q,SAAAF,EAAAzN,EAAA,GAEa,OADbqN,EAAArH,YAAA,CAAAzM,EAAA,CAAAqS,EAAA9B,GACaA,CACb,IAEAsD,EAAAQ,cAAA,EACAP,CAAAA,EAAAzT,OAAA,CAAAwT,EAAAQ,cAAA,EACAR,EAAApP,OAAA,EACAqP,CAAAA,EAAArP,OAAA,MAAAsO,YAAA,CAAAc,EAAApP,OAAA,GACA,MAAAoP,EAAA3O,MAAA,EACA4O,CAAAA,EAAA5O,MAAA,CAAA2O,EAAA3O,MAAA,EACA2O,EAAAS,IAAA,EACAR,CAAAA,EAAArD,QAAA,CAAAqD,EAAArD,QAAA,CAAAxQ,MAAA,CAAA4T,EAAAS,IAAA,GACA,MAAAT,EAAAzG,YAAA,EACA0G,CAAAA,EAAA1G,YAAA,CAAAyG,EAAAzG,YAAA,EACA0G,CACA,CAGAS,aAAA,CACA,YAAA9D,QAAA,CAAAjQ,MAAA,EACA,CAKAwN,QAAAxM,CAAA,EACA,YAAAsR,SAAA,MAAAA,SAAA,CAAAtR,EAAA,CAAAyO,OAAAzO,GAAA,KAAAU,OAAA,OAAAuI,OAAA,CAAAsE,KAAA,CAAAvN,EAAA,CAAA+P,IAAA,EAAA/P,EAAA,CAIA,IAAA8K,SAAA,aAAApK,OAAA,GAEA,IAAAsS,SAAA,aAAA/J,OAAA,CAAAsE,KAAA,MAAAlN,GAAA,KAEAf,kBAAAU,CAAA,EACA,IAAAiT,EAAA,KAAA9B,kBAAA,CACA,OAAA8B,IAAA,EAAAA,EAAA,EAAAA,CAAA,CAAAjT,EAAA,IAGAuR,aAAAtO,CAAA,EACA,IAAAiQ,EAAA5D,OAAAC,IAAA,MAAA2B,QAAA,EAAAhO,EAAAgQ,EAAA5I,GAAA,SACA,GAAArH,EACA,QAAAkQ,KAAAlQ,EAAA5B,KAAA,OACA,IAAA0C,EAAAmP,EAAA9C,OAAA,CAAA+C,GACApP,GAAA,GACAb,CAAAA,CAAA,CAAAa,EAAA,IACA,KACA8K,EAAA,IAAwB,CACxB,QAAArQ,EAAA,EAAAA,EAAA0U,EAAAlU,MAAA,CAAAR,IACA,IAAA0E,CAAA,CAAA1E,EAAA,CACA,QAAAuO,EAAA,KAAAmE,QAAA,CAAAgC,CAAA,CAAA1U,EAAA,EAAAuF,EAAA,OAAAA,CAAAA,EAAA,KAAApB,IAAA,CAAAoK,IAAA,GACA,CAAA8B,GAAAA,CAAAA,EAAA,IAAAuE,WAAA,KAAAnC,OAAA,MAAAlN,EAAA,EACA,CACA,WAAA4K,EAAA1L,EAAAC,EAAA2L,EACA,CAGA,OAAAe,YAAAb,CAAA,EACA,WAAA7R,EAAA6R,EACA,CACA,CACA,SAAA3D,EAAAzI,CAAA,CAAArB,CAAA,SAAAqB,CAAA,CAAArB,EAAA,CAAAqB,CAAA,CAAArB,EAAA,OACA,SAAA6Q,EAAAxP,CAAA,CAAAjE,CAA8B,CAAAsB,CAAA,EAC9B,QAAAxB,EAAAE,EAAA8B,EAAA,OAAAA,CAAAA,EAAAmC,CAAA,CAAAnE,EAAA,EAAAA,IACA,GAAAgC,GAAAR,EACA,OAAAxB,EAAAE,CAAA,CACA,SACA,CAYA,SAAAmS,EAAA9B,CAAA,EACA,GAAAA,EAAA6D,QAAA,EACA,IAAAzO,EAAA4K,EAAA1H,MAAA,KACA,OAAAvG,EAAAnD,IAAA,EAAAiV,QAAA,CAAA9R,EAAAnD,IAAA,EAAAwG,CACA,QACA4K,EAAAP,GAAA,CAE2E","sources":["webpack://_N_E/./node_modules/@lezer/lr/dist/index.js","webpack://_N_E/<anon>"],"sourcesContent":["import { Parser, NodeSet, NodeType, DefaultBufferLength, NodeProp, Tree, IterMode } from '@lezer/common';\n\n/// A parse stack. These are used internally by the parser to track\n/// parsing progress. They also provide some properties and methods\n/// that external code such as a tokenizer can use to get information\n/// about the parse state.\nclass Stack {\n    /// @internal\n    constructor(\n    /// The parse that this stack is part of @internal\n    p, \n    /// Holds state, input pos, buffer index triplets for all but the\n    /// top state @internal\n    stack, \n    /// The current parse state @internal\n    state, \n    // The position at which the next reduce should take place. This\n    // can be less than `this.pos` when skipped expressions have been\n    // added to the stack (which should be moved outside of the next\n    // reduction)\n    /// @internal\n    reducePos, \n    /// The input position up to which this stack has parsed.\n    pos, \n    /// The dynamic score of the stack, including dynamic precedence\n    /// and error-recovery penalties\n    /// @internal\n    score, \n    // The output buffer. Holds (type, start, end, size) quads\n    // representing nodes created by the parser, where `size` is\n    // amount of buffer array entries covered by this node.\n    /// @internal\n    buffer, \n    // The base offset of the buffer. When stacks are split, the split\n    // instance shared the buffer history with its parent up to\n    // `bufferBase`, which is the absolute offset (including the\n    // offset of previous splits) into the buffer at which this stack\n    // starts writing.\n    /// @internal\n    bufferBase, \n    /// @internal\n    curContext, \n    /// @internal\n    lookAhead = 0, \n    // A parent stack from which this was split off, if any. This is\n    // set up so that it always points to a stack that has some\n    // additional buffer content, never to a stack with an equal\n    // `bufferBase`.\n    /// @internal\n    parent) {\n        this.p = p;\n        this.stack = stack;\n        this.state = state;\n        this.reducePos = reducePos;\n        this.pos = pos;\n        this.score = score;\n        this.buffer = buffer;\n        this.bufferBase = bufferBase;\n        this.curContext = curContext;\n        this.lookAhead = lookAhead;\n        this.parent = parent;\n    }\n    /// @internal\n    toString() {\n        return `[${this.stack.filter((_, i) => i % 3 == 0).concat(this.state)}]@${this.pos}${this.score ? \"!\" + this.score : \"\"}`;\n    }\n    // Start an empty stack\n    /// @internal\n    static start(p, state, pos = 0) {\n        let cx = p.parser.context;\n        return new Stack(p, [], state, pos, pos, 0, [], 0, cx ? new StackContext(cx, cx.start) : null, 0, null);\n    }\n    /// The stack's current [context](#lr.ContextTracker) value, if\n    /// any. Its type will depend on the context tracker's type\n    /// parameter, or it will be `null` if there is no context\n    /// tracker.\n    get context() { return this.curContext ? this.curContext.context : null; }\n    // Push a state onto the stack, tracking its start position as well\n    // as the buffer base at that point.\n    /// @internal\n    pushState(state, start) {\n        this.stack.push(this.state, start, this.bufferBase + this.buffer.length);\n        this.state = state;\n    }\n    // Apply a reduce action\n    /// @internal\n    reduce(action) {\n        let depth = action >> 19 /* ReduceDepthShift */, type = action & 65535 /* ValueMask */;\n        let { parser } = this.p;\n        let dPrec = parser.dynamicPrecedence(type);\n        if (dPrec)\n            this.score += dPrec;\n        if (depth == 0) {\n            this.pushState(parser.getGoto(this.state, type, true), this.reducePos);\n            // Zero-depth reductions are a special case—they add stuff to\n            // the stack without popping anything off.\n            if (type < parser.minRepeatTerm)\n                this.storeNode(type, this.reducePos, this.reducePos, 4, true);\n            this.reduceContext(type, this.reducePos);\n            return;\n        }\n        // Find the base index into `this.stack`, content after which will\n        // be dropped. Note that with `StayFlag` reductions we need to\n        // consume two extra frames (the dummy parent node for the skipped\n        // expression and the state that we'll be staying in, which should\n        // be moved to `this.state`).\n        let base = this.stack.length - ((depth - 1) * 3) - (action & 262144 /* StayFlag */ ? 6 : 0);\n        let start = this.stack[base - 2];\n        let bufferBase = this.stack[base - 1], count = this.bufferBase + this.buffer.length - bufferBase;\n        // Store normal terms or `R -> R R` repeat reductions\n        if (type < parser.minRepeatTerm || (action & 131072 /* RepeatFlag */)) {\n            let pos = parser.stateFlag(this.state, 1 /* Skipped */) ? this.pos : this.reducePos;\n            this.storeNode(type, start, pos, count + 4, true);\n        }\n        if (action & 262144 /* StayFlag */) {\n            this.state = this.stack[base];\n        }\n        else {\n            let baseStateID = this.stack[base - 3];\n            this.state = parser.getGoto(baseStateID, type, true);\n        }\n        while (this.stack.length > base)\n            this.stack.pop();\n        this.reduceContext(type, start);\n    }\n    // Shift a value into the buffer\n    /// @internal\n    storeNode(term, start, end, size = 4, isReduce = false) {\n        if (term == 0 /* Err */ &&\n            (!this.stack.length || this.stack[this.stack.length - 1] < this.buffer.length + this.bufferBase)) {\n            // Try to omit/merge adjacent error nodes\n            let cur = this, top = this.buffer.length;\n            if (top == 0 && cur.parent) {\n                top = cur.bufferBase - cur.parent.bufferBase;\n                cur = cur.parent;\n            }\n            if (top > 0 && cur.buffer[top - 4] == 0 /* Err */ && cur.buffer[top - 1] > -1) {\n                if (start == end)\n                    return;\n                if (cur.buffer[top - 2] >= start) {\n                    cur.buffer[top - 2] = end;\n                    return;\n                }\n            }\n        }\n        if (!isReduce || this.pos == end) { // Simple case, just append\n            this.buffer.push(term, start, end, size);\n        }\n        else { // There may be skipped nodes that have to be moved forward\n            let index = this.buffer.length;\n            if (index > 0 && this.buffer[index - 4] != 0 /* Err */)\n                while (index > 0 && this.buffer[index - 2] > end) {\n                    // Move this record forward\n                    this.buffer[index] = this.buffer[index - 4];\n                    this.buffer[index + 1] = this.buffer[index - 3];\n                    this.buffer[index + 2] = this.buffer[index - 2];\n                    this.buffer[index + 3] = this.buffer[index - 1];\n                    index -= 4;\n                    if (size > 4)\n                        size -= 4;\n                }\n            this.buffer[index] = term;\n            this.buffer[index + 1] = start;\n            this.buffer[index + 2] = end;\n            this.buffer[index + 3] = size;\n        }\n    }\n    // Apply a shift action\n    /// @internal\n    shift(action, next, nextEnd) {\n        let start = this.pos;\n        if (action & 131072 /* GotoFlag */) {\n            this.pushState(action & 65535 /* ValueMask */, this.pos);\n        }\n        else if ((action & 262144 /* StayFlag */) == 0) { // Regular shift\n            let nextState = action, { parser } = this.p;\n            if (nextEnd > this.pos || next <= parser.maxNode) {\n                this.pos = nextEnd;\n                if (!parser.stateFlag(nextState, 1 /* Skipped */))\n                    this.reducePos = nextEnd;\n            }\n            this.pushState(nextState, start);\n            this.shiftContext(next, start);\n            if (next <= parser.maxNode)\n                this.buffer.push(next, start, nextEnd, 4);\n        }\n        else { // Shift-and-stay, which means this is a skipped token\n            this.pos = nextEnd;\n            this.shiftContext(next, start);\n            if (next <= this.p.parser.maxNode)\n                this.buffer.push(next, start, nextEnd, 4);\n        }\n    }\n    // Apply an action\n    /// @internal\n    apply(action, next, nextEnd) {\n        if (action & 65536 /* ReduceFlag */)\n            this.reduce(action);\n        else\n            this.shift(action, next, nextEnd);\n    }\n    // Add a prebuilt (reused) node into the buffer.\n    /// @internal\n    useNode(value, next) {\n        let index = this.p.reused.length - 1;\n        if (index < 0 || this.p.reused[index] != value) {\n            this.p.reused.push(value);\n            index++;\n        }\n        let start = this.pos;\n        this.reducePos = this.pos = start + value.length;\n        this.pushState(next, start);\n        this.buffer.push(index, start, this.reducePos, -1 /* size == -1 means this is a reused value */);\n        if (this.curContext)\n            this.updateContext(this.curContext.tracker.reuse(this.curContext.context, value, this, this.p.stream.reset(this.pos - value.length)));\n    }\n    // Split the stack. Due to the buffer sharing and the fact\n    // that `this.stack` tends to stay quite shallow, this isn't very\n    // expensive.\n    /// @internal\n    split() {\n        let parent = this;\n        let off = parent.buffer.length;\n        // Because the top of the buffer (after this.pos) may be mutated\n        // to reorder reductions and skipped tokens, and shared buffers\n        // should be immutable, this copies any outstanding skipped tokens\n        // to the new buffer, and puts the base pointer before them.\n        while (off > 0 && parent.buffer[off - 2] > parent.reducePos)\n            off -= 4;\n        let buffer = parent.buffer.slice(off), base = parent.bufferBase + off;\n        // Make sure parent points to an actual parent with content, if there is such a parent.\n        while (parent && base == parent.bufferBase)\n            parent = parent.parent;\n        return new Stack(this.p, this.stack.slice(), this.state, this.reducePos, this.pos, this.score, buffer, base, this.curContext, this.lookAhead, parent);\n    }\n    // Try to recover from an error by 'deleting' (ignoring) one token.\n    /// @internal\n    recoverByDelete(next, nextEnd) {\n        let isNode = next <= this.p.parser.maxNode;\n        if (isNode)\n            this.storeNode(next, this.pos, nextEnd, 4);\n        this.storeNode(0 /* Err */, this.pos, nextEnd, isNode ? 8 : 4);\n        this.pos = this.reducePos = nextEnd;\n        this.score -= 190 /* Delete */;\n    }\n    /// Check if the given term would be able to be shifted (optionally\n    /// after some reductions) on this stack. This can be useful for\n    /// external tokenizers that want to make sure they only provide a\n    /// given token when it applies.\n    canShift(term) {\n        for (let sim = new SimulatedStack(this);;) {\n            let action = this.p.parser.stateSlot(sim.state, 4 /* DefaultReduce */) || this.p.parser.hasAction(sim.state, term);\n            if (action == 0)\n                return false;\n            if ((action & 65536 /* ReduceFlag */) == 0)\n                return true;\n            sim.reduce(action);\n        }\n    }\n    // Apply up to Recover.MaxNext recovery actions that conceptually\n    // inserts some missing token or rule.\n    /// @internal\n    recoverByInsert(next) {\n        if (this.stack.length >= 300 /* MaxInsertStackDepth */)\n            return [];\n        let nextStates = this.p.parser.nextStates(this.state);\n        if (nextStates.length > 4 /* MaxNext */ << 1 || this.stack.length >= 120 /* DampenInsertStackDepth */) {\n            let best = [];\n            for (let i = 0, s; i < nextStates.length; i += 2) {\n                if ((s = nextStates[i + 1]) != this.state && this.p.parser.hasAction(s, next))\n                    best.push(nextStates[i], s);\n            }\n            if (this.stack.length < 120 /* DampenInsertStackDepth */)\n                for (let i = 0; best.length < 4 /* MaxNext */ << 1 && i < nextStates.length; i += 2) {\n                    let s = nextStates[i + 1];\n                    if (!best.some((v, i) => (i & 1) && v == s))\n                        best.push(nextStates[i], s);\n                }\n            nextStates = best;\n        }\n        let result = [];\n        for (let i = 0; i < nextStates.length && result.length < 4 /* MaxNext */; i += 2) {\n            let s = nextStates[i + 1];\n            if (s == this.state)\n                continue;\n            let stack = this.split();\n            stack.pushState(s, this.pos);\n            stack.storeNode(0 /* Err */, stack.pos, stack.pos, 4, true);\n            stack.shiftContext(nextStates[i], this.pos);\n            stack.score -= 200 /* Insert */;\n            result.push(stack);\n        }\n        return result;\n    }\n    // Force a reduce, if possible. Return false if that can't\n    // be done.\n    /// @internal\n    forceReduce() {\n        let reduce = this.p.parser.stateSlot(this.state, 5 /* ForcedReduce */);\n        if ((reduce & 65536 /* ReduceFlag */) == 0)\n            return false;\n        let { parser } = this.p;\n        if (!parser.validAction(this.state, reduce)) {\n            let depth = reduce >> 19 /* ReduceDepthShift */, term = reduce & 65535 /* ValueMask */;\n            let target = this.stack.length - depth * 3;\n            if (target < 0 || parser.getGoto(this.stack[target], term, false) < 0)\n                return false;\n            this.storeNode(0 /* Err */, this.reducePos, this.reducePos, 4, true);\n            this.score -= 100 /* Reduce */;\n        }\n        this.reducePos = this.pos;\n        this.reduce(reduce);\n        return true;\n    }\n    /// @internal\n    forceAll() {\n        while (!this.p.parser.stateFlag(this.state, 2 /* Accepting */)) {\n            if (!this.forceReduce()) {\n                this.storeNode(0 /* Err */, this.pos, this.pos, 4, true);\n                break;\n            }\n        }\n        return this;\n    }\n    /// Check whether this state has no further actions (assumed to be a direct descendant of the\n    /// top state, since any other states must be able to continue\n    /// somehow). @internal\n    get deadEnd() {\n        if (this.stack.length != 3)\n            return false;\n        let { parser } = this.p;\n        return parser.data[parser.stateSlot(this.state, 1 /* Actions */)] == 65535 /* End */ &&\n            !parser.stateSlot(this.state, 4 /* DefaultReduce */);\n    }\n    /// Restart the stack (put it back in its start state). Only safe\n    /// when this.stack.length == 3 (state is directly below the top\n    /// state). @internal\n    restart() {\n        this.state = this.stack[0];\n        this.stack.length = 0;\n    }\n    /// @internal\n    sameState(other) {\n        if (this.state != other.state || this.stack.length != other.stack.length)\n            return false;\n        for (let i = 0; i < this.stack.length; i += 3)\n            if (this.stack[i] != other.stack[i])\n                return false;\n        return true;\n    }\n    /// Get the parser used by this stack.\n    get parser() { return this.p.parser; }\n    /// Test whether a given dialect (by numeric ID, as exported from\n    /// the terms file) is enabled.\n    dialectEnabled(dialectID) { return this.p.parser.dialect.flags[dialectID]; }\n    shiftContext(term, start) {\n        if (this.curContext)\n            this.updateContext(this.curContext.tracker.shift(this.curContext.context, term, this, this.p.stream.reset(start)));\n    }\n    reduceContext(term, start) {\n        if (this.curContext)\n            this.updateContext(this.curContext.tracker.reduce(this.curContext.context, term, this, this.p.stream.reset(start)));\n    }\n    /// @internal\n    emitContext() {\n        let last = this.buffer.length - 1;\n        if (last < 0 || this.buffer[last] != -3)\n            this.buffer.push(this.curContext.hash, this.reducePos, this.reducePos, -3);\n    }\n    /// @internal\n    emitLookAhead() {\n        let last = this.buffer.length - 1;\n        if (last < 0 || this.buffer[last] != -4)\n            this.buffer.push(this.lookAhead, this.reducePos, this.reducePos, -4);\n    }\n    updateContext(context) {\n        if (context != this.curContext.context) {\n            let newCx = new StackContext(this.curContext.tracker, context);\n            if (newCx.hash != this.curContext.hash)\n                this.emitContext();\n            this.curContext = newCx;\n        }\n    }\n    /// @internal\n    setLookAhead(lookAhead) {\n        if (lookAhead > this.lookAhead) {\n            this.emitLookAhead();\n            this.lookAhead = lookAhead;\n        }\n    }\n    /// @internal\n    close() {\n        if (this.curContext && this.curContext.tracker.strict)\n            this.emitContext();\n        if (this.lookAhead > 0)\n            this.emitLookAhead();\n    }\n}\nclass StackContext {\n    constructor(tracker, context) {\n        this.tracker = tracker;\n        this.context = context;\n        this.hash = tracker.strict ? tracker.hash(context) : 0;\n    }\n}\nvar Recover;\n(function (Recover) {\n    Recover[Recover[\"Insert\"] = 200] = \"Insert\";\n    Recover[Recover[\"Delete\"] = 190] = \"Delete\";\n    Recover[Recover[\"Reduce\"] = 100] = \"Reduce\";\n    Recover[Recover[\"MaxNext\"] = 4] = \"MaxNext\";\n    Recover[Recover[\"MaxInsertStackDepth\"] = 300] = \"MaxInsertStackDepth\";\n    Recover[Recover[\"DampenInsertStackDepth\"] = 120] = \"DampenInsertStackDepth\";\n})(Recover || (Recover = {}));\n// Used to cheaply run some reductions to scan ahead without mutating\n// an entire stack\nclass SimulatedStack {\n    constructor(start) {\n        this.start = start;\n        this.state = start.state;\n        this.stack = start.stack;\n        this.base = this.stack.length;\n    }\n    reduce(action) {\n        let term = action & 65535 /* ValueMask */, depth = action >> 19 /* ReduceDepthShift */;\n        if (depth == 0) {\n            if (this.stack == this.start.stack)\n                this.stack = this.stack.slice();\n            this.stack.push(this.state, 0, 0);\n            this.base += 3;\n        }\n        else {\n            this.base -= (depth - 1) * 3;\n        }\n        let goto = this.start.p.parser.getGoto(this.stack[this.base - 3], term, true);\n        this.state = goto;\n    }\n}\n// This is given to `Tree.build` to build a buffer, and encapsulates\n// the parent-stack-walking necessary to read the nodes.\nclass StackBufferCursor {\n    constructor(stack, pos, index) {\n        this.stack = stack;\n        this.pos = pos;\n        this.index = index;\n        this.buffer = stack.buffer;\n        if (this.index == 0)\n            this.maybeNext();\n    }\n    static create(stack, pos = stack.bufferBase + stack.buffer.length) {\n        return new StackBufferCursor(stack, pos, pos - stack.bufferBase);\n    }\n    maybeNext() {\n        let next = this.stack.parent;\n        if (next != null) {\n            this.index = this.stack.bufferBase - next.bufferBase;\n            this.stack = next;\n            this.buffer = next.buffer;\n        }\n    }\n    get id() { return this.buffer[this.index - 4]; }\n    get start() { return this.buffer[this.index - 3]; }\n    get end() { return this.buffer[this.index - 2]; }\n    get size() { return this.buffer[this.index - 1]; }\n    next() {\n        this.index -= 4;\n        this.pos -= 4;\n        if (this.index == 0)\n            this.maybeNext();\n    }\n    fork() {\n        return new StackBufferCursor(this.stack, this.pos, this.index);\n    }\n}\n\nclass CachedToken {\n    constructor() {\n        this.start = -1;\n        this.value = -1;\n        this.end = -1;\n        this.extended = -1;\n        this.lookAhead = 0;\n        this.mask = 0;\n        this.context = 0;\n    }\n}\nconst nullToken = new CachedToken;\n/// [Tokenizers](#lr.ExternalTokenizer) interact with the input\n/// through this interface. It presents the input as a stream of\n/// characters, tracking lookahead and hiding the complexity of\n/// [ranges](#common.Parser.parse^ranges) from tokenizer code.\nclass InputStream {\n    /// @internal\n    constructor(\n    /// @internal\n    input, \n    /// @internal\n    ranges) {\n        this.input = input;\n        this.ranges = ranges;\n        /// @internal\n        this.chunk = \"\";\n        /// @internal\n        this.chunkOff = 0;\n        /// Backup chunk\n        this.chunk2 = \"\";\n        this.chunk2Pos = 0;\n        /// The character code of the next code unit in the input, or -1\n        /// when the stream is at the end of the input.\n        this.next = -1;\n        /// @internal\n        this.token = nullToken;\n        this.rangeIndex = 0;\n        this.pos = this.chunkPos = ranges[0].from;\n        this.range = ranges[0];\n        this.end = ranges[ranges.length - 1].to;\n        this.readNext();\n    }\n    /// @internal\n    resolveOffset(offset, assoc) {\n        let range = this.range, index = this.rangeIndex;\n        let pos = this.pos + offset;\n        while (pos < range.from) {\n            if (!index)\n                return null;\n            let next = this.ranges[--index];\n            pos -= range.from - next.to;\n            range = next;\n        }\n        while (assoc < 0 ? pos > range.to : pos >= range.to) {\n            if (index == this.ranges.length - 1)\n                return null;\n            let next = this.ranges[++index];\n            pos += next.from - range.to;\n            range = next;\n        }\n        return pos;\n    }\n    /// @internal\n    clipPos(pos) {\n        if (pos >= this.range.from && pos < this.range.to)\n            return pos;\n        for (let range of this.ranges)\n            if (range.to > pos)\n                return Math.max(pos, range.from);\n        return this.end;\n    }\n    /// Look at a code unit near the stream position. `.peek(0)` equals\n    /// `.next`, `.peek(-1)` gives you the previous character, and so\n    /// on.\n    ///\n    /// Note that looking around during tokenizing creates dependencies\n    /// on potentially far-away content, which may reduce the\n    /// effectiveness incremental parsing—when looking forward—or even\n    /// cause invalid reparses when looking backward more than 25 code\n    /// units, since the library does not track lookbehind.\n    peek(offset) {\n        let idx = this.chunkOff + offset, pos, result;\n        if (idx >= 0 && idx < this.chunk.length) {\n            pos = this.pos + offset;\n            result = this.chunk.charCodeAt(idx);\n        }\n        else {\n            let resolved = this.resolveOffset(offset, 1);\n            if (resolved == null)\n                return -1;\n            pos = resolved;\n            if (pos >= this.chunk2Pos && pos < this.chunk2Pos + this.chunk2.length) {\n                result = this.chunk2.charCodeAt(pos - this.chunk2Pos);\n            }\n            else {\n                let i = this.rangeIndex, range = this.range;\n                while (range.to <= pos)\n                    range = this.ranges[++i];\n                this.chunk2 = this.input.chunk(this.chunk2Pos = pos);\n                if (pos + this.chunk2.length > range.to)\n                    this.chunk2 = this.chunk2.slice(0, range.to - pos);\n                result = this.chunk2.charCodeAt(0);\n            }\n        }\n        if (pos >= this.token.lookAhead)\n            this.token.lookAhead = pos + 1;\n        return result;\n    }\n    /// Accept a token. By default, the end of the token is set to the\n    /// current stream position, but you can pass an offset (relative to\n    /// the stream position) to change that.\n    acceptToken(token, endOffset = 0) {\n        let end = endOffset ? this.resolveOffset(endOffset, -1) : this.pos;\n        if (end == null || end < this.token.start)\n            throw new RangeError(\"Token end out of bounds\");\n        this.token.value = token;\n        this.token.end = end;\n    }\n    getChunk() {\n        if (this.pos >= this.chunk2Pos && this.pos < this.chunk2Pos + this.chunk2.length) {\n            let { chunk, chunkPos } = this;\n            this.chunk = this.chunk2;\n            this.chunkPos = this.chunk2Pos;\n            this.chunk2 = chunk;\n            this.chunk2Pos = chunkPos;\n            this.chunkOff = this.pos - this.chunkPos;\n        }\n        else {\n            this.chunk2 = this.chunk;\n            this.chunk2Pos = this.chunkPos;\n            let nextChunk = this.input.chunk(this.pos);\n            let end = this.pos + nextChunk.length;\n            this.chunk = end > this.range.to ? nextChunk.slice(0, this.range.to - this.pos) : nextChunk;\n            this.chunkPos = this.pos;\n            this.chunkOff = 0;\n        }\n    }\n    readNext() {\n        if (this.chunkOff >= this.chunk.length) {\n            this.getChunk();\n            if (this.chunkOff == this.chunk.length)\n                return this.next = -1;\n        }\n        return this.next = this.chunk.charCodeAt(this.chunkOff);\n    }\n    /// Move the stream forward N (defaults to 1) code units. Returns\n    /// the new value of [`next`](#lr.InputStream.next).\n    advance(n = 1) {\n        this.chunkOff += n;\n        while (this.pos + n >= this.range.to) {\n            if (this.rangeIndex == this.ranges.length - 1)\n                return this.setDone();\n            n -= this.range.to - this.pos;\n            this.range = this.ranges[++this.rangeIndex];\n            this.pos = this.range.from;\n        }\n        this.pos += n;\n        if (this.pos >= this.token.lookAhead)\n            this.token.lookAhead = this.pos + 1;\n        return this.readNext();\n    }\n    setDone() {\n        this.pos = this.chunkPos = this.end;\n        this.range = this.ranges[this.rangeIndex = this.ranges.length - 1];\n        this.chunk = \"\";\n        return this.next = -1;\n    }\n    /// @internal\n    reset(pos, token) {\n        if (token) {\n            this.token = token;\n            token.start = pos;\n            token.lookAhead = pos + 1;\n            token.value = token.extended = -1;\n        }\n        else {\n            this.token = nullToken;\n        }\n        if (this.pos != pos) {\n            this.pos = pos;\n            if (pos == this.end) {\n                this.setDone();\n                return this;\n            }\n            while (pos < this.range.from)\n                this.range = this.ranges[--this.rangeIndex];\n            while (pos >= this.range.to)\n                this.range = this.ranges[++this.rangeIndex];\n            if (pos >= this.chunkPos && pos < this.chunkPos + this.chunk.length) {\n                this.chunkOff = pos - this.chunkPos;\n            }\n            else {\n                this.chunk = \"\";\n                this.chunkOff = 0;\n            }\n            this.readNext();\n        }\n        return this;\n    }\n    /// @internal\n    read(from, to) {\n        if (from >= this.chunkPos && to <= this.chunkPos + this.chunk.length)\n            return this.chunk.slice(from - this.chunkPos, to - this.chunkPos);\n        if (from >= this.chunk2Pos && to <= this.chunk2Pos + this.chunk2.length)\n            return this.chunk2.slice(from - this.chunk2Pos, to - this.chunk2Pos);\n        if (from >= this.range.from && to <= this.range.to)\n            return this.input.read(from, to);\n        let result = \"\";\n        for (let r of this.ranges) {\n            if (r.from >= to)\n                break;\n            if (r.to > from)\n                result += this.input.read(Math.max(r.from, from), Math.min(r.to, to));\n        }\n        return result;\n    }\n}\n/// @internal\nclass TokenGroup {\n    constructor(data, id) {\n        this.data = data;\n        this.id = id;\n    }\n    token(input, stack) { readToken(this.data, input, stack, this.id); }\n}\nTokenGroup.prototype.contextual = TokenGroup.prototype.fallback = TokenGroup.prototype.extend = false;\n/// `@external tokens` declarations in the grammar should resolve to\n/// an instance of this class.\nclass ExternalTokenizer {\n    /// Create a tokenizer. The first argument is the function that,\n    /// given an input stream, scans for the types of tokens it\n    /// recognizes at the stream's position, and calls\n    /// [`acceptToken`](#lr.InputStream.acceptToken) when it finds\n    /// one.\n    constructor(\n    /// @internal\n    token, options = {}) {\n        this.token = token;\n        this.contextual = !!options.contextual;\n        this.fallback = !!options.fallback;\n        this.extend = !!options.extend;\n    }\n}\n// Tokenizer data is stored a big uint16 array containing, for each\n// state:\n//\n//  - A group bitmask, indicating what token groups are reachable from\n//    this state, so that paths that can only lead to tokens not in\n//    any of the current groups can be cut off early.\n//\n//  - The position of the end of the state's sequence of accepting\n//    tokens\n//\n//  - The number of outgoing edges for the state\n//\n//  - The accepting tokens, as (token id, group mask) pairs\n//\n//  - The outgoing edges, as (start character, end character, state\n//    index) triples, with end character being exclusive\n//\n// This function interprets that data, running through a stream as\n// long as new states with the a matching group mask can be reached,\n// and updating `input.token` when it matches a token.\nfunction readToken(data, input, stack, group) {\n    let state = 0, groupMask = 1 << group, { parser } = stack.p, { dialect } = parser;\n    scan: for (;;) {\n        if ((groupMask & data[state]) == 0)\n            break;\n        let accEnd = data[state + 1];\n        // Check whether this state can lead to a token in the current group\n        // Accept tokens in this state, possibly overwriting\n        // lower-precedence / shorter tokens\n        for (let i = state + 3; i < accEnd; i += 2)\n            if ((data[i + 1] & groupMask) > 0) {\n                let term = data[i];\n                if (dialect.allows(term) &&\n                    (input.token.value == -1 || input.token.value == term || parser.overrides(term, input.token.value))) {\n                    input.acceptToken(term);\n                    break;\n                }\n            }\n        let next = input.next, low = 0, high = data[state + 2];\n        // Special case for EOF\n        if (input.next < 0 && high > low && data[accEnd + high * 3 - 3] == 65535 /* End */ && data[accEnd + high * 3 - 3] == 65535 /* End */) {\n            state = data[accEnd + high * 3 - 1];\n            continue scan;\n        }\n        // Do a binary search on the state's edges\n        for (; low < high;) {\n            let mid = (low + high) >> 1;\n            let index = accEnd + mid + (mid << 1);\n            let from = data[index], to = data[index + 1] || 0x10000;\n            if (next < from)\n                high = mid;\n            else if (next >= to)\n                low = mid + 1;\n            else {\n                state = data[index + 2];\n                input.advance();\n                continue scan;\n            }\n        }\n        break;\n    }\n}\n\n// See lezer-generator/src/encode.ts for comments about the encoding\n// used here\nfunction decodeArray(input, Type = Uint16Array) {\n    if (typeof input != \"string\")\n        return input;\n    let array = null;\n    for (let pos = 0, out = 0; pos < input.length;) {\n        let value = 0;\n        for (;;) {\n            let next = input.charCodeAt(pos++), stop = false;\n            if (next == 126 /* BigValCode */) {\n                value = 65535 /* BigVal */;\n                break;\n            }\n            if (next >= 92 /* Gap2 */)\n                next--;\n            if (next >= 34 /* Gap1 */)\n                next--;\n            let digit = next - 32 /* Start */;\n            if (digit >= 46 /* Base */) {\n                digit -= 46 /* Base */;\n                stop = true;\n            }\n            value += digit;\n            if (stop)\n                break;\n            value *= 46 /* Base */;\n        }\n        if (array)\n            array[out++] = value;\n        else\n            array = new Type(value);\n    }\n    return array;\n}\n\n// Environment variable used to control console output\nconst verbose = typeof process != \"undefined\" && process.env && /\\bparse\\b/.test(process.env.LOG);\nlet stackIDs = null;\nvar Safety;\n(function (Safety) {\n    Safety[Safety[\"Margin\"] = 25] = \"Margin\";\n})(Safety || (Safety = {}));\nfunction cutAt(tree, pos, side) {\n    let cursor = tree.cursor(IterMode.IncludeAnonymous);\n    cursor.moveTo(pos);\n    for (;;) {\n        if (!(side < 0 ? cursor.childBefore(pos) : cursor.childAfter(pos)))\n            for (;;) {\n                if ((side < 0 ? cursor.to < pos : cursor.from > pos) && !cursor.type.isError)\n                    return side < 0 ? Math.max(0, Math.min(cursor.to - 1, pos - 25 /* Margin */))\n                        : Math.min(tree.length, Math.max(cursor.from + 1, pos + 25 /* Margin */));\n                if (side < 0 ? cursor.prevSibling() : cursor.nextSibling())\n                    break;\n                if (!cursor.parent())\n                    return side < 0 ? 0 : tree.length;\n            }\n    }\n}\nclass FragmentCursor {\n    constructor(fragments, nodeSet) {\n        this.fragments = fragments;\n        this.nodeSet = nodeSet;\n        this.i = 0;\n        this.fragment = null;\n        this.safeFrom = -1;\n        this.safeTo = -1;\n        this.trees = [];\n        this.start = [];\n        this.index = [];\n        this.nextFragment();\n    }\n    nextFragment() {\n        let fr = this.fragment = this.i == this.fragments.length ? null : this.fragments[this.i++];\n        if (fr) {\n            this.safeFrom = fr.openStart ? cutAt(fr.tree, fr.from + fr.offset, 1) - fr.offset : fr.from;\n            this.safeTo = fr.openEnd ? cutAt(fr.tree, fr.to + fr.offset, -1) - fr.offset : fr.to;\n            while (this.trees.length) {\n                this.trees.pop();\n                this.start.pop();\n                this.index.pop();\n            }\n            this.trees.push(fr.tree);\n            this.start.push(-fr.offset);\n            this.index.push(0);\n            this.nextStart = this.safeFrom;\n        }\n        else {\n            this.nextStart = 1e9;\n        }\n    }\n    // `pos` must be >= any previously given `pos` for this cursor\n    nodeAt(pos) {\n        if (pos < this.nextStart)\n            return null;\n        while (this.fragment && this.safeTo <= pos)\n            this.nextFragment();\n        if (!this.fragment)\n            return null;\n        for (;;) {\n            let last = this.trees.length - 1;\n            if (last < 0) { // End of tree\n                this.nextFragment();\n                return null;\n            }\n            let top = this.trees[last], index = this.index[last];\n            if (index == top.children.length) {\n                this.trees.pop();\n                this.start.pop();\n                this.index.pop();\n                continue;\n            }\n            let next = top.children[index];\n            let start = this.start[last] + top.positions[index];\n            if (start > pos) {\n                this.nextStart = start;\n                return null;\n            }\n            if (next instanceof Tree) {\n                if (start == pos) {\n                    if (start < this.safeFrom)\n                        return null;\n                    let end = start + next.length;\n                    if (end <= this.safeTo) {\n                        let lookAhead = next.prop(NodeProp.lookAhead);\n                        if (!lookAhead || end + lookAhead < this.fragment.to)\n                            return next;\n                    }\n                }\n                this.index[last]++;\n                if (start + next.length >= Math.max(this.safeFrom, pos)) { // Enter this node\n                    this.trees.push(next);\n                    this.start.push(start);\n                    this.index.push(0);\n                }\n            }\n            else {\n                this.index[last]++;\n                this.nextStart = start + next.length;\n            }\n        }\n    }\n}\nclass TokenCache {\n    constructor(parser, stream) {\n        this.stream = stream;\n        this.tokens = [];\n        this.mainToken = null;\n        this.actions = [];\n        this.tokens = parser.tokenizers.map(_ => new CachedToken);\n    }\n    getActions(stack) {\n        let actionIndex = 0;\n        let main = null;\n        let { parser } = stack.p, { tokenizers } = parser;\n        let mask = parser.stateSlot(stack.state, 3 /* TokenizerMask */);\n        let context = stack.curContext ? stack.curContext.hash : 0;\n        let lookAhead = 0;\n        for (let i = 0; i < tokenizers.length; i++) {\n            if (((1 << i) & mask) == 0)\n                continue;\n            let tokenizer = tokenizers[i], token = this.tokens[i];\n            if (main && !tokenizer.fallback)\n                continue;\n            if (tokenizer.contextual || token.start != stack.pos || token.mask != mask || token.context != context) {\n                this.updateCachedToken(token, tokenizer, stack);\n                token.mask = mask;\n                token.context = context;\n            }\n            if (token.lookAhead > token.end + 25 /* Margin */)\n                lookAhead = Math.max(token.lookAhead, lookAhead);\n            if (token.value != 0 /* Err */) {\n                let startIndex = actionIndex;\n                if (token.extended > -1)\n                    actionIndex = this.addActions(stack, token.extended, token.end, actionIndex);\n                actionIndex = this.addActions(stack, token.value, token.end, actionIndex);\n                if (!tokenizer.extend) {\n                    main = token;\n                    if (actionIndex > startIndex)\n                        break;\n                }\n            }\n        }\n        while (this.actions.length > actionIndex)\n            this.actions.pop();\n        if (lookAhead)\n            stack.setLookAhead(lookAhead);\n        if (!main && stack.pos == this.stream.end) {\n            main = new CachedToken;\n            main.value = stack.p.parser.eofTerm;\n            main.start = main.end = stack.pos;\n            actionIndex = this.addActions(stack, main.value, main.end, actionIndex);\n        }\n        this.mainToken = main;\n        return this.actions;\n    }\n    getMainToken(stack) {\n        if (this.mainToken)\n            return this.mainToken;\n        let main = new CachedToken, { pos, p } = stack;\n        main.start = pos;\n        main.end = Math.min(pos + 1, p.stream.end);\n        main.value = pos == p.stream.end ? p.parser.eofTerm : 0 /* Err */;\n        return main;\n    }\n    updateCachedToken(token, tokenizer, stack) {\n        let start = this.stream.clipPos(stack.pos);\n        tokenizer.token(this.stream.reset(start, token), stack);\n        if (token.value > -1) {\n            let { parser } = stack.p;\n            for (let i = 0; i < parser.specialized.length; i++)\n                if (parser.specialized[i] == token.value) {\n                    let result = parser.specializers[i](this.stream.read(token.start, token.end), stack);\n                    if (result >= 0 && stack.p.parser.dialect.allows(result >> 1)) {\n                        if ((result & 1) == 0 /* Specialize */)\n                            token.value = result >> 1;\n                        else\n                            token.extended = result >> 1;\n                        break;\n                    }\n                }\n        }\n        else {\n            token.value = 0 /* Err */;\n            token.end = this.stream.clipPos(start + 1);\n        }\n    }\n    putAction(action, token, end, index) {\n        // Don't add duplicate actions\n        for (let i = 0; i < index; i += 3)\n            if (this.actions[i] == action)\n                return index;\n        this.actions[index++] = action;\n        this.actions[index++] = token;\n        this.actions[index++] = end;\n        return index;\n    }\n    addActions(stack, token, end, index) {\n        let { state } = stack, { parser } = stack.p, { data } = parser;\n        for (let set = 0; set < 2; set++) {\n            for (let i = parser.stateSlot(state, set ? 2 /* Skip */ : 1 /* Actions */);; i += 3) {\n                if (data[i] == 65535 /* End */) {\n                    if (data[i + 1] == 1 /* Next */) {\n                        i = pair(data, i + 2);\n                    }\n                    else {\n                        if (index == 0 && data[i + 1] == 2 /* Other */)\n                            index = this.putAction(pair(data, i + 2), token, end, index);\n                        break;\n                    }\n                }\n                if (data[i] == token)\n                    index = this.putAction(pair(data, i + 1), token, end, index);\n            }\n        }\n        return index;\n    }\n}\nvar Rec;\n(function (Rec) {\n    Rec[Rec[\"Distance\"] = 5] = \"Distance\";\n    Rec[Rec[\"MaxRemainingPerStep\"] = 3] = \"MaxRemainingPerStep\";\n    // When two stacks have been running independently long enough to\n    // add this many elements to their buffers, prune one.\n    Rec[Rec[\"MinBufferLengthPrune\"] = 500] = \"MinBufferLengthPrune\";\n    Rec[Rec[\"ForceReduceLimit\"] = 10] = \"ForceReduceLimit\";\n    // Once a stack reaches this depth (in .stack.length) force-reduce\n    // it back to CutTo to avoid creating trees that overflow the stack\n    // on recursive traversal.\n    Rec[Rec[\"CutDepth\"] = 15000] = \"CutDepth\";\n    Rec[Rec[\"CutTo\"] = 9000] = \"CutTo\";\n})(Rec || (Rec = {}));\nclass Parse {\n    constructor(parser, input, fragments, ranges) {\n        this.parser = parser;\n        this.input = input;\n        this.ranges = ranges;\n        this.recovering = 0;\n        this.nextStackID = 0x2654; // ♔, ♕, ♖, ♗, ♘, ♙, ♠, ♡, ♢, ♣, ♤, ♥, ♦, ♧\n        this.minStackPos = 0;\n        this.reused = [];\n        this.stoppedAt = null;\n        this.stream = new InputStream(input, ranges);\n        this.tokens = new TokenCache(parser, this.stream);\n        this.topTerm = parser.top[1];\n        let { from } = ranges[0];\n        this.stacks = [Stack.start(this, parser.top[0], from)];\n        this.fragments = fragments.length && this.stream.end - from > parser.bufferLength * 4\n            ? new FragmentCursor(fragments, parser.nodeSet) : null;\n    }\n    get parsedPos() {\n        return this.minStackPos;\n    }\n    // Move the parser forward. This will process all parse stacks at\n    // `this.pos` and try to advance them to a further position. If no\n    // stack for such a position is found, it'll start error-recovery.\n    //\n    // When the parse is finished, this will return a syntax tree. When\n    // not, it returns `null`.\n    advance() {\n        let stacks = this.stacks, pos = this.minStackPos;\n        // This will hold stacks beyond `pos`.\n        let newStacks = this.stacks = [];\n        let stopped, stoppedTokens;\n        // Keep advancing any stacks at `pos` until they either move\n        // forward or can't be advanced. Gather stacks that can't be\n        // advanced further in `stopped`.\n        for (let i = 0; i < stacks.length; i++) {\n            let stack = stacks[i];\n            for (;;) {\n                this.tokens.mainToken = null;\n                if (stack.pos > pos) {\n                    newStacks.push(stack);\n                }\n                else if (this.advanceStack(stack, newStacks, stacks)) {\n                    continue;\n                }\n                else {\n                    if (!stopped) {\n                        stopped = [];\n                        stoppedTokens = [];\n                    }\n                    stopped.push(stack);\n                    let tok = this.tokens.getMainToken(stack);\n                    stoppedTokens.push(tok.value, tok.end);\n                }\n                break;\n            }\n        }\n        if (!newStacks.length) {\n            let finished = stopped && findFinished(stopped);\n            if (finished)\n                return this.stackToTree(finished);\n            if (this.parser.strict) {\n                if (verbose && stopped)\n                    console.log(\"Stuck with token \" + (this.tokens.mainToken ? this.parser.getName(this.tokens.mainToken.value) : \"none\"));\n                throw new SyntaxError(\"No parse at \" + pos);\n            }\n            if (!this.recovering)\n                this.recovering = 5 /* Distance */;\n        }\n        if (this.recovering && stopped) {\n            let finished = this.stoppedAt != null && stopped[0].pos > this.stoppedAt ? stopped[0]\n                : this.runRecovery(stopped, stoppedTokens, newStacks);\n            if (finished)\n                return this.stackToTree(finished.forceAll());\n        }\n        if (this.recovering) {\n            let maxRemaining = this.recovering == 1 ? 1 : this.recovering * 3 /* MaxRemainingPerStep */;\n            if (newStacks.length > maxRemaining) {\n                newStacks.sort((a, b) => b.score - a.score);\n                while (newStacks.length > maxRemaining)\n                    newStacks.pop();\n            }\n            if (newStacks.some(s => s.reducePos > pos))\n                this.recovering--;\n        }\n        else if (newStacks.length > 1) {\n            // Prune stacks that are in the same state, or that have been\n            // running without splitting for a while, to avoid getting stuck\n            // with multiple successful stacks running endlessly on.\n            outer: for (let i = 0; i < newStacks.length - 1; i++) {\n                let stack = newStacks[i];\n                for (let j = i + 1; j < newStacks.length; j++) {\n                    let other = newStacks[j];\n                    if (stack.sameState(other) ||\n                        stack.buffer.length > 500 /* MinBufferLengthPrune */ && other.buffer.length > 500 /* MinBufferLengthPrune */) {\n                        if (((stack.score - other.score) || (stack.buffer.length - other.buffer.length)) > 0) {\n                            newStacks.splice(j--, 1);\n                        }\n                        else {\n                            newStacks.splice(i--, 1);\n                            continue outer;\n                        }\n                    }\n                }\n            }\n        }\n        this.minStackPos = newStacks[0].pos;\n        for (let i = 1; i < newStacks.length; i++)\n            if (newStacks[i].pos < this.minStackPos)\n                this.minStackPos = newStacks[i].pos;\n        return null;\n    }\n    stopAt(pos) {\n        if (this.stoppedAt != null && this.stoppedAt < pos)\n            throw new RangeError(\"Can't move stoppedAt forward\");\n        this.stoppedAt = pos;\n    }\n    // Returns an updated version of the given stack, or null if the\n    // stack can't advance normally. When `split` and `stacks` are\n    // given, stacks split off by ambiguous operations will be pushed to\n    // `split`, or added to `stacks` if they move `pos` forward.\n    advanceStack(stack, stacks, split) {\n        let start = stack.pos, { parser } = this;\n        let base = verbose ? this.stackID(stack) + \" -> \" : \"\";\n        if (this.stoppedAt != null && start > this.stoppedAt)\n            return stack.forceReduce() ? stack : null;\n        if (this.fragments) {\n            let strictCx = stack.curContext && stack.curContext.tracker.strict, cxHash = strictCx ? stack.curContext.hash : 0;\n            for (let cached = this.fragments.nodeAt(start); cached;) {\n                let match = this.parser.nodeSet.types[cached.type.id] == cached.type ? parser.getGoto(stack.state, cached.type.id) : -1;\n                if (match > -1 && cached.length && (!strictCx || (cached.prop(NodeProp.contextHash) || 0) == cxHash)) {\n                    stack.useNode(cached, match);\n                    if (verbose)\n                        console.log(base + this.stackID(stack) + ` (via reuse of ${parser.getName(cached.type.id)})`);\n                    return true;\n                }\n                if (!(cached instanceof Tree) || cached.children.length == 0 || cached.positions[0] > 0)\n                    break;\n                let inner = cached.children[0];\n                if (inner instanceof Tree && cached.positions[0] == 0)\n                    cached = inner;\n                else\n                    break;\n            }\n        }\n        let defaultReduce = parser.stateSlot(stack.state, 4 /* DefaultReduce */);\n        if (defaultReduce > 0) {\n            stack.reduce(defaultReduce);\n            if (verbose)\n                console.log(base + this.stackID(stack) + ` (via always-reduce ${parser.getName(defaultReduce & 65535 /* ValueMask */)})`);\n            return true;\n        }\n        if (stack.stack.length >= 15000 /* CutDepth */) {\n            while (stack.stack.length > 9000 /* CutTo */ && stack.forceReduce()) { }\n        }\n        let actions = this.tokens.getActions(stack);\n        for (let i = 0; i < actions.length;) {\n            let action = actions[i++], term = actions[i++], end = actions[i++];\n            let last = i == actions.length || !split;\n            let localStack = last ? stack : stack.split();\n            localStack.apply(action, term, end);\n            if (verbose)\n                console.log(base + this.stackID(localStack) + ` (via ${(action & 65536 /* ReduceFlag */) == 0 ? \"shift\"\n                    : `reduce of ${parser.getName(action & 65535 /* ValueMask */)}`} for ${parser.getName(term)} @ ${start}${localStack == stack ? \"\" : \", split\"})`);\n            if (last)\n                return true;\n            else if (localStack.pos > start)\n                stacks.push(localStack);\n            else\n                split.push(localStack);\n        }\n        return false;\n    }\n    // Advance a given stack forward as far as it will go. Returns the\n    // (possibly updated) stack if it got stuck, or null if it moved\n    // forward and was given to `pushStackDedup`.\n    advanceFully(stack, newStacks) {\n        let pos = stack.pos;\n        for (;;) {\n            if (!this.advanceStack(stack, null, null))\n                return false;\n            if (stack.pos > pos) {\n                pushStackDedup(stack, newStacks);\n                return true;\n            }\n        }\n    }\n    runRecovery(stacks, tokens, newStacks) {\n        let finished = null, restarted = false;\n        for (let i = 0; i < stacks.length; i++) {\n            let stack = stacks[i], token = tokens[i << 1], tokenEnd = tokens[(i << 1) + 1];\n            let base = verbose ? this.stackID(stack) + \" -> \" : \"\";\n            if (stack.deadEnd) {\n                if (restarted)\n                    continue;\n                restarted = true;\n                stack.restart();\n                if (verbose)\n                    console.log(base + this.stackID(stack) + \" (restarted)\");\n                let done = this.advanceFully(stack, newStacks);\n                if (done)\n                    continue;\n            }\n            let force = stack.split(), forceBase = base;\n            for (let j = 0; force.forceReduce() && j < 10 /* ForceReduceLimit */; j++) {\n                if (verbose)\n                    console.log(forceBase + this.stackID(force) + \" (via force-reduce)\");\n                let done = this.advanceFully(force, newStacks);\n                if (done)\n                    break;\n                if (verbose)\n                    forceBase = this.stackID(force) + \" -> \";\n            }\n            for (let insert of stack.recoverByInsert(token)) {\n                if (verbose)\n                    console.log(base + this.stackID(insert) + \" (via recover-insert)\");\n                this.advanceFully(insert, newStacks);\n            }\n            if (this.stream.end > stack.pos) {\n                if (tokenEnd == stack.pos) {\n                    tokenEnd++;\n                    token = 0 /* Err */;\n                }\n                stack.recoverByDelete(token, tokenEnd);\n                if (verbose)\n                    console.log(base + this.stackID(stack) + ` (via recover-delete ${this.parser.getName(token)})`);\n                pushStackDedup(stack, newStacks);\n            }\n            else if (!finished || finished.score < stack.score) {\n                finished = stack;\n            }\n        }\n        return finished;\n    }\n    // Convert the stack's buffer to a syntax tree.\n    stackToTree(stack) {\n        stack.close();\n        return Tree.build({ buffer: StackBufferCursor.create(stack),\n            nodeSet: this.parser.nodeSet,\n            topID: this.topTerm,\n            maxBufferLength: this.parser.bufferLength,\n            reused: this.reused,\n            start: this.ranges[0].from,\n            length: stack.pos - this.ranges[0].from,\n            minRepeatType: this.parser.minRepeatTerm });\n    }\n    stackID(stack) {\n        let id = (stackIDs || (stackIDs = new WeakMap)).get(stack);\n        if (!id)\n            stackIDs.set(stack, id = String.fromCodePoint(this.nextStackID++));\n        return id + stack;\n    }\n}\nfunction pushStackDedup(stack, newStacks) {\n    for (let i = 0; i < newStacks.length; i++) {\n        let other = newStacks[i];\n        if (other.pos == stack.pos && other.sameState(stack)) {\n            if (newStacks[i].score < stack.score)\n                newStacks[i] = stack;\n            return;\n        }\n    }\n    newStacks.push(stack);\n}\nclass Dialect {\n    constructor(source, flags, disabled) {\n        this.source = source;\n        this.flags = flags;\n        this.disabled = disabled;\n    }\n    allows(term) { return !this.disabled || this.disabled[term] == 0; }\n}\nconst id = x => x;\n/// Context trackers are used to track stateful context (such as\n/// indentation in the Python grammar, or parent elements in the XML\n/// grammar) needed by external tokenizers. You declare them in a\n/// grammar file as `@context exportName from \"module\"`.\n///\n/// Context values should be immutable, and can be updated (replaced)\n/// on shift or reduce actions.\n///\n/// The export used in a `@context` declaration should be of this\n/// type.\nclass ContextTracker {\n    /// Define a context tracker.\n    constructor(spec) {\n        this.start = spec.start;\n        this.shift = spec.shift || id;\n        this.reduce = spec.reduce || id;\n        this.reuse = spec.reuse || id;\n        this.hash = spec.hash || (() => 0);\n        this.strict = spec.strict !== false;\n    }\n}\n/// Holds the parse tables for a given grammar, as generated by\n/// `lezer-generator`, and provides [methods](#common.Parser) to parse\n/// content with.\nclass LRParser extends Parser {\n    /// @internal\n    constructor(spec) {\n        super();\n        /// @internal\n        this.wrappers = [];\n        if (spec.version != 14 /* Version */)\n            throw new RangeError(`Parser version (${spec.version}) doesn't match runtime version (${14 /* Version */})`);\n        let nodeNames = spec.nodeNames.split(\" \");\n        this.minRepeatTerm = nodeNames.length;\n        for (let i = 0; i < spec.repeatNodeCount; i++)\n            nodeNames.push(\"\");\n        let topTerms = Object.keys(spec.topRules).map(r => spec.topRules[r][1]);\n        let nodeProps = [];\n        for (let i = 0; i < nodeNames.length; i++)\n            nodeProps.push([]);\n        function setProp(nodeID, prop, value) {\n            nodeProps[nodeID].push([prop, prop.deserialize(String(value))]);\n        }\n        if (spec.nodeProps)\n            for (let propSpec of spec.nodeProps) {\n                let prop = propSpec[0];\n                if (typeof prop == \"string\")\n                    prop = NodeProp[prop];\n                for (let i = 1; i < propSpec.length;) {\n                    let next = propSpec[i++];\n                    if (next >= 0) {\n                        setProp(next, prop, propSpec[i++]);\n                    }\n                    else {\n                        let value = propSpec[i + -next];\n                        for (let j = -next; j > 0; j--)\n                            setProp(propSpec[i++], prop, value);\n                        i++;\n                    }\n                }\n            }\n        this.nodeSet = new NodeSet(nodeNames.map((name, i) => NodeType.define({\n            name: i >= this.minRepeatTerm ? undefined : name,\n            id: i,\n            props: nodeProps[i],\n            top: topTerms.indexOf(i) > -1,\n            error: i == 0,\n            skipped: spec.skippedNodes && spec.skippedNodes.indexOf(i) > -1\n        })));\n        if (spec.propSources)\n            this.nodeSet = this.nodeSet.extend(...spec.propSources);\n        this.strict = false;\n        this.bufferLength = DefaultBufferLength;\n        let tokenArray = decodeArray(spec.tokenData);\n        this.context = spec.context;\n        this.specializerSpecs = spec.specialized || [];\n        this.specialized = new Uint16Array(this.specializerSpecs.length);\n        for (let i = 0; i < this.specializerSpecs.length; i++)\n            this.specialized[i] = this.specializerSpecs[i].term;\n        this.specializers = this.specializerSpecs.map(getSpecializer);\n        this.states = decodeArray(spec.states, Uint32Array);\n        this.data = decodeArray(spec.stateData);\n        this.goto = decodeArray(spec.goto);\n        this.maxTerm = spec.maxTerm;\n        this.tokenizers = spec.tokenizers.map(value => typeof value == \"number\" ? new TokenGroup(tokenArray, value) : value);\n        this.topRules = spec.topRules;\n        this.dialects = spec.dialects || {};\n        this.dynamicPrecedences = spec.dynamicPrecedences || null;\n        this.tokenPrecTable = spec.tokenPrec;\n        this.termNames = spec.termNames || null;\n        this.maxNode = this.nodeSet.types.length - 1;\n        this.dialect = this.parseDialect();\n        this.top = this.topRules[Object.keys(this.topRules)[0]];\n    }\n    createParse(input, fragments, ranges) {\n        let parse = new Parse(this, input, fragments, ranges);\n        for (let w of this.wrappers)\n            parse = w(parse, input, fragments, ranges);\n        return parse;\n    }\n    /// Get a goto table entry @internal\n    getGoto(state, term, loose = false) {\n        let table = this.goto;\n        if (term >= table[0])\n            return -1;\n        for (let pos = table[term + 1];;) {\n            let groupTag = table[pos++], last = groupTag & 1;\n            let target = table[pos++];\n            if (last && loose)\n                return target;\n            for (let end = pos + (groupTag >> 1); pos < end; pos++)\n                if (table[pos] == state)\n                    return target;\n            if (last)\n                return -1;\n        }\n    }\n    /// Check if this state has an action for a given terminal @internal\n    hasAction(state, terminal) {\n        let data = this.data;\n        for (let set = 0; set < 2; set++) {\n            for (let i = this.stateSlot(state, set ? 2 /* Skip */ : 1 /* Actions */), next;; i += 3) {\n                if ((next = data[i]) == 65535 /* End */) {\n                    if (data[i + 1] == 1 /* Next */)\n                        next = data[i = pair(data, i + 2)];\n                    else if (data[i + 1] == 2 /* Other */)\n                        return pair(data, i + 2);\n                    else\n                        break;\n                }\n                if (next == terminal || next == 0 /* Err */)\n                    return pair(data, i + 1);\n            }\n        }\n        return 0;\n    }\n    /// @internal\n    stateSlot(state, slot) {\n        return this.states[(state * 6 /* Size */) + slot];\n    }\n    /// @internal\n    stateFlag(state, flag) {\n        return (this.stateSlot(state, 0 /* Flags */) & flag) > 0;\n    }\n    /// @internal\n    validAction(state, action) {\n        if (action == this.stateSlot(state, 4 /* DefaultReduce */))\n            return true;\n        for (let i = this.stateSlot(state, 1 /* Actions */);; i += 3) {\n            if (this.data[i] == 65535 /* End */) {\n                if (this.data[i + 1] == 1 /* Next */)\n                    i = pair(this.data, i + 2);\n                else\n                    return false;\n            }\n            if (action == pair(this.data, i + 1))\n                return true;\n        }\n    }\n    /// Get the states that can follow this one through shift actions or\n    /// goto jumps. @internal\n    nextStates(state) {\n        let result = [];\n        for (let i = this.stateSlot(state, 1 /* Actions */);; i += 3) {\n            if (this.data[i] == 65535 /* End */) {\n                if (this.data[i + 1] == 1 /* Next */)\n                    i = pair(this.data, i + 2);\n                else\n                    break;\n            }\n            if ((this.data[i + 2] & (65536 /* ReduceFlag */ >> 16)) == 0) {\n                let value = this.data[i + 1];\n                if (!result.some((v, i) => (i & 1) && v == value))\n                    result.push(this.data[i], value);\n            }\n        }\n        return result;\n    }\n    /// @internal\n    overrides(token, prev) {\n        let iPrev = findOffset(this.data, this.tokenPrecTable, prev);\n        return iPrev < 0 || findOffset(this.data, this.tokenPrecTable, token) < iPrev;\n    }\n    /// Configure the parser. Returns a new parser instance that has the\n    /// given settings modified. Settings not provided in `config` are\n    /// kept from the original parser.\n    configure(config) {\n        // Hideous reflection-based kludge to make it easy to create a\n        // slightly modified copy of a parser.\n        let copy = Object.assign(Object.create(LRParser.prototype), this);\n        if (config.props)\n            copy.nodeSet = this.nodeSet.extend(...config.props);\n        if (config.top) {\n            let info = this.topRules[config.top];\n            if (!info)\n                throw new RangeError(`Invalid top rule name ${config.top}`);\n            copy.top = info;\n        }\n        if (config.tokenizers)\n            copy.tokenizers = this.tokenizers.map(t => {\n                let found = config.tokenizers.find(r => r.from == t);\n                return found ? found.to : t;\n            });\n        if (config.specializers) {\n            copy.specializers = this.specializers.slice();\n            copy.specializerSpecs = this.specializerSpecs.map((s, i) => {\n                let found = config.specializers.find(r => r.from == s.external);\n                if (!found)\n                    return s;\n                let spec = Object.assign(Object.assign({}, s), { external: found.to });\n                copy.specializers[i] = getSpecializer(spec);\n                return spec;\n            });\n        }\n        if (config.contextTracker)\n            copy.context = config.contextTracker;\n        if (config.dialect)\n            copy.dialect = this.parseDialect(config.dialect);\n        if (config.strict != null)\n            copy.strict = config.strict;\n        if (config.wrap)\n            copy.wrappers = copy.wrappers.concat(config.wrap);\n        if (config.bufferLength != null)\n            copy.bufferLength = config.bufferLength;\n        return copy;\n    }\n    /// Tells you whether any [parse wrappers](#lr.ParserConfig.wrap)\n    /// are registered for this parser.\n    hasWrappers() {\n        return this.wrappers.length > 0;\n    }\n    /// Returns the name associated with a given term. This will only\n    /// work for all terms when the parser was generated with the\n    /// `--names` option. By default, only the names of tagged terms are\n    /// stored.\n    getName(term) {\n        return this.termNames ? this.termNames[term] : String(term <= this.maxNode && this.nodeSet.types[term].name || term);\n    }\n    /// The eof term id is always allocated directly after the node\n    /// types. @internal\n    get eofTerm() { return this.maxNode + 1; }\n    /// The type of top node produced by the parser.\n    get topNode() { return this.nodeSet.types[this.top[1]]; }\n    /// @internal\n    dynamicPrecedence(term) {\n        let prec = this.dynamicPrecedences;\n        return prec == null ? 0 : prec[term] || 0;\n    }\n    /// @internal\n    parseDialect(dialect) {\n        let values = Object.keys(this.dialects), flags = values.map(() => false);\n        if (dialect)\n            for (let part of dialect.split(\" \")) {\n                let id = values.indexOf(part);\n                if (id >= 0)\n                    flags[id] = true;\n            }\n        let disabled = null;\n        for (let i = 0; i < values.length; i++)\n            if (!flags[i]) {\n                for (let j = this.dialects[values[i]], id; (id = this.data[j++]) != 65535 /* End */;)\n                    (disabled || (disabled = new Uint8Array(this.maxTerm + 1)))[id] = 1;\n            }\n        return new Dialect(dialect, flags, disabled);\n    }\n    /// Used by the output of the parser generator. Not available to\n    /// user code.\n    static deserialize(spec) {\n        return new LRParser(spec);\n    }\n}\nfunction pair(data, off) { return data[off] | (data[off + 1] << 16); }\nfunction findOffset(data, start, term) {\n    for (let i = start, next; (next = data[i]) != 65535 /* End */; i++)\n        if (next == term)\n            return i - start;\n    return -1;\n}\nfunction findFinished(stacks) {\n    let best = null;\n    for (let stack of stacks) {\n        let stopped = stack.p.stoppedAt;\n        if ((stack.pos == stack.p.stream.end || stopped != null && stack.pos > stopped) &&\n            stack.p.parser.stateFlag(stack.state, 2 /* Accepting */) &&\n            (!best || best.score < stack.score))\n            best = stack;\n    }\n    return best;\n}\nfunction getSpecializer(spec) {\n    if (spec.external) {\n        let mask = spec.extend ? 1 /* Extend */ : 0 /* Specialize */;\n        return (value, stack) => (spec.external(value, stack) << 1) | mask;\n    }\n    return spec.get;\n}\n\nexport { ContextTracker, ExternalTokenizer, InputStream, LRParser, Stack };\n","\"use strict\";\n(self[\"webpackChunk_N_E\"] = self[\"webpackChunk_N_E\"] || []).push([[105],{\n\n/***/ 53105:\n/***/ (function(__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) {\n\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IK\": function() { return /* binding */ ContextTracker; },\n/* harmony export */   \"Jq\": function() { return /* binding */ ExternalTokenizer; },\n/* harmony export */   \"WQ\": function() { return /* binding */ LRParser; }\n/* harmony export */ });\n/* unused harmony exports InputStream, Stack */\n/* harmony import */ var _lezer_common__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(41113);\n/* provided dependency */ var process = __webpack_require__(83454);\n\n\n/// A parse stack. These are used internally by the parser to track\n/// parsing progress. They also provide some properties and methods\n/// that external code such as a tokenizer can use to get information\n/// about the parse state.\nclass Stack {\n    /// @internal\n    constructor(\n    /// The parse that this stack is part of @internal\n    p, \n    /// Holds state, input pos, buffer index triplets for all but the\n    /// top state @internal\n    stack, \n    /// The current parse state @internal\n    state, \n    // The position at which the next reduce should take place. This\n    // can be less than `this.pos` when skipped expressions have been\n    // added to the stack (which should be moved outside of the next\n    // reduction)\n    /// @internal\n    reducePos, \n    /// The input position up to which this stack has parsed.\n    pos, \n    /// The dynamic score of the stack, including dynamic precedence\n    /// and error-recovery penalties\n    /// @internal\n    score, \n    // The output buffer. Holds (type, start, end, size) quads\n    // representing nodes created by the parser, where `size` is\n    // amount of buffer array entries covered by this node.\n    /// @internal\n    buffer, \n    // The base offset of the buffer. When stacks are split, the split\n    // instance shared the buffer history with its parent up to\n    // `bufferBase`, which is the absolute offset (including the\n    // offset of previous splits) into the buffer at which this stack\n    // starts writing.\n    /// @internal\n    bufferBase, \n    /// @internal\n    curContext, \n    /// @internal\n    lookAhead = 0, \n    // A parent stack from which this was split off, if any. This is\n    // set up so that it always points to a stack that has some\n    // additional buffer content, never to a stack with an equal\n    // `bufferBase`.\n    /// @internal\n    parent) {\n        this.p = p;\n        this.stack = stack;\n        this.state = state;\n        this.reducePos = reducePos;\n        this.pos = pos;\n        this.score = score;\n        this.buffer = buffer;\n        this.bufferBase = bufferBase;\n        this.curContext = curContext;\n        this.lookAhead = lookAhead;\n        this.parent = parent;\n    }\n    /// @internal\n    toString() {\n        return `[${this.stack.filter((_, i) => i % 3 == 0).concat(this.state)}]@${this.pos}${this.score ? \"!\" + this.score : \"\"}`;\n    }\n    // Start an empty stack\n    /// @internal\n    static start(p, state, pos = 0) {\n        let cx = p.parser.context;\n        return new Stack(p, [], state, pos, pos, 0, [], 0, cx ? new StackContext(cx, cx.start) : null, 0, null);\n    }\n    /// The stack's current [context](#lr.ContextTracker) value, if\n    /// any. Its type will depend on the context tracker's type\n    /// parameter, or it will be `null` if there is no context\n    /// tracker.\n    get context() { return this.curContext ? this.curContext.context : null; }\n    // Push a state onto the stack, tracking its start position as well\n    // as the buffer base at that point.\n    /// @internal\n    pushState(state, start) {\n        this.stack.push(this.state, start, this.bufferBase + this.buffer.length);\n        this.state = state;\n    }\n    // Apply a reduce action\n    /// @internal\n    reduce(action) {\n        let depth = action >> 19 /* ReduceDepthShift */, type = action & 65535 /* ValueMask */;\n        let { parser } = this.p;\n        let dPrec = parser.dynamicPrecedence(type);\n        if (dPrec)\n            this.score += dPrec;\n        if (depth == 0) {\n            this.pushState(parser.getGoto(this.state, type, true), this.reducePos);\n            // Zero-depth reductions are a special case—they add stuff to\n            // the stack without popping anything off.\n            if (type < parser.minRepeatTerm)\n                this.storeNode(type, this.reducePos, this.reducePos, 4, true);\n            this.reduceContext(type, this.reducePos);\n            return;\n        }\n        // Find the base index into `this.stack`, content after which will\n        // be dropped. Note that with `StayFlag` reductions we need to\n        // consume two extra frames (the dummy parent node for the skipped\n        // expression and the state that we'll be staying in, which should\n        // be moved to `this.state`).\n        let base = this.stack.length - ((depth - 1) * 3) - (action & 262144 /* StayFlag */ ? 6 : 0);\n        let start = this.stack[base - 2];\n        let bufferBase = this.stack[base - 1], count = this.bufferBase + this.buffer.length - bufferBase;\n        // Store normal terms or `R -> R R` repeat reductions\n        if (type < parser.minRepeatTerm || (action & 131072 /* RepeatFlag */)) {\n            let pos = parser.stateFlag(this.state, 1 /* Skipped */) ? this.pos : this.reducePos;\n            this.storeNode(type, start, pos, count + 4, true);\n        }\n        if (action & 262144 /* StayFlag */) {\n            this.state = this.stack[base];\n        }\n        else {\n            let baseStateID = this.stack[base - 3];\n            this.state = parser.getGoto(baseStateID, type, true);\n        }\n        while (this.stack.length > base)\n            this.stack.pop();\n        this.reduceContext(type, start);\n    }\n    // Shift a value into the buffer\n    /// @internal\n    storeNode(term, start, end, size = 4, isReduce = false) {\n        if (term == 0 /* Err */ &&\n            (!this.stack.length || this.stack[this.stack.length - 1] < this.buffer.length + this.bufferBase)) {\n            // Try to omit/merge adjacent error nodes\n            let cur = this, top = this.buffer.length;\n            if (top == 0 && cur.parent) {\n                top = cur.bufferBase - cur.parent.bufferBase;\n                cur = cur.parent;\n            }\n            if (top > 0 && cur.buffer[top - 4] == 0 /* Err */ && cur.buffer[top - 1] > -1) {\n                if (start == end)\n                    return;\n                if (cur.buffer[top - 2] >= start) {\n                    cur.buffer[top - 2] = end;\n                    return;\n                }\n            }\n        }\n        if (!isReduce || this.pos == end) { // Simple case, just append\n            this.buffer.push(term, start, end, size);\n        }\n        else { // There may be skipped nodes that have to be moved forward\n            let index = this.buffer.length;\n            if (index > 0 && this.buffer[index - 4] != 0 /* Err */)\n                while (index > 0 && this.buffer[index - 2] > end) {\n                    // Move this record forward\n                    this.buffer[index] = this.buffer[index - 4];\n                    this.buffer[index + 1] = this.buffer[index - 3];\n                    this.buffer[index + 2] = this.buffer[index - 2];\n                    this.buffer[index + 3] = this.buffer[index - 1];\n                    index -= 4;\n                    if (size > 4)\n                        size -= 4;\n                }\n            this.buffer[index] = term;\n            this.buffer[index + 1] = start;\n            this.buffer[index + 2] = end;\n            this.buffer[index + 3] = size;\n        }\n    }\n    // Apply a shift action\n    /// @internal\n    shift(action, next, nextEnd) {\n        let start = this.pos;\n        if (action & 131072 /* GotoFlag */) {\n            this.pushState(action & 65535 /* ValueMask */, this.pos);\n        }\n        else if ((action & 262144 /* StayFlag */) == 0) { // Regular shift\n            let nextState = action, { parser } = this.p;\n            if (nextEnd > this.pos || next <= parser.maxNode) {\n                this.pos = nextEnd;\n                if (!parser.stateFlag(nextState, 1 /* Skipped */))\n                    this.reducePos = nextEnd;\n            }\n            this.pushState(nextState, start);\n            this.shiftContext(next, start);\n            if (next <= parser.maxNode)\n                this.buffer.push(next, start, nextEnd, 4);\n        }\n        else { // Shift-and-stay, which means this is a skipped token\n            this.pos = nextEnd;\n            this.shiftContext(next, start);\n            if (next <= this.p.parser.maxNode)\n                this.buffer.push(next, start, nextEnd, 4);\n        }\n    }\n    // Apply an action\n    /// @internal\n    apply(action, next, nextEnd) {\n        if (action & 65536 /* ReduceFlag */)\n            this.reduce(action);\n        else\n            this.shift(action, next, nextEnd);\n    }\n    // Add a prebuilt (reused) node into the buffer.\n    /// @internal\n    useNode(value, next) {\n        let index = this.p.reused.length - 1;\n        if (index < 0 || this.p.reused[index] != value) {\n            this.p.reused.push(value);\n            index++;\n        }\n        let start = this.pos;\n        this.reducePos = this.pos = start + value.length;\n        this.pushState(next, start);\n        this.buffer.push(index, start, this.reducePos, -1 /* size == -1 means this is a reused value */);\n        if (this.curContext)\n            this.updateContext(this.curContext.tracker.reuse(this.curContext.context, value, this, this.p.stream.reset(this.pos - value.length)));\n    }\n    // Split the stack. Due to the buffer sharing and the fact\n    // that `this.stack` tends to stay quite shallow, this isn't very\n    // expensive.\n    /// @internal\n    split() {\n        let parent = this;\n        let off = parent.buffer.length;\n        // Because the top of the buffer (after this.pos) may be mutated\n        // to reorder reductions and skipped tokens, and shared buffers\n        // should be immutable, this copies any outstanding skipped tokens\n        // to the new buffer, and puts the base pointer before them.\n        while (off > 0 && parent.buffer[off - 2] > parent.reducePos)\n            off -= 4;\n        let buffer = parent.buffer.slice(off), base = parent.bufferBase + off;\n        // Make sure parent points to an actual parent with content, if there is such a parent.\n        while (parent && base == parent.bufferBase)\n            parent = parent.parent;\n        return new Stack(this.p, this.stack.slice(), this.state, this.reducePos, this.pos, this.score, buffer, base, this.curContext, this.lookAhead, parent);\n    }\n    // Try to recover from an error by 'deleting' (ignoring) one token.\n    /// @internal\n    recoverByDelete(next, nextEnd) {\n        let isNode = next <= this.p.parser.maxNode;\n        if (isNode)\n            this.storeNode(next, this.pos, nextEnd, 4);\n        this.storeNode(0 /* Err */, this.pos, nextEnd, isNode ? 8 : 4);\n        this.pos = this.reducePos = nextEnd;\n        this.score -= 190 /* Delete */;\n    }\n    /// Check if the given term would be able to be shifted (optionally\n    /// after some reductions) on this stack. This can be useful for\n    /// external tokenizers that want to make sure they only provide a\n    /// given token when it applies.\n    canShift(term) {\n        for (let sim = new SimulatedStack(this);;) {\n            let action = this.p.parser.stateSlot(sim.state, 4 /* DefaultReduce */) || this.p.parser.hasAction(sim.state, term);\n            if (action == 0)\n                return false;\n            if ((action & 65536 /* ReduceFlag */) == 0)\n                return true;\n            sim.reduce(action);\n        }\n    }\n    // Apply up to Recover.MaxNext recovery actions that conceptually\n    // inserts some missing token or rule.\n    /// @internal\n    recoverByInsert(next) {\n        if (this.stack.length >= 300 /* MaxInsertStackDepth */)\n            return [];\n        let nextStates = this.p.parser.nextStates(this.state);\n        if (nextStates.length > 4 /* MaxNext */ << 1 || this.stack.length >= 120 /* DampenInsertStackDepth */) {\n            let best = [];\n            for (let i = 0, s; i < nextStates.length; i += 2) {\n                if ((s = nextStates[i + 1]) != this.state && this.p.parser.hasAction(s, next))\n                    best.push(nextStates[i], s);\n            }\n            if (this.stack.length < 120 /* DampenInsertStackDepth */)\n                for (let i = 0; best.length < 4 /* MaxNext */ << 1 && i < nextStates.length; i += 2) {\n                    let s = nextStates[i + 1];\n                    if (!best.some((v, i) => (i & 1) && v == s))\n                        best.push(nextStates[i], s);\n                }\n            nextStates = best;\n        }\n        let result = [];\n        for (let i = 0; i < nextStates.length && result.length < 4 /* MaxNext */; i += 2) {\n            let s = nextStates[i + 1];\n            if (s == this.state)\n                continue;\n            let stack = this.split();\n            stack.pushState(s, this.pos);\n            stack.storeNode(0 /* Err */, stack.pos, stack.pos, 4, true);\n            stack.shiftContext(nextStates[i], this.pos);\n            stack.score -= 200 /* Insert */;\n            result.push(stack);\n        }\n        return result;\n    }\n    // Force a reduce, if possible. Return false if that can't\n    // be done.\n    /// @internal\n    forceReduce() {\n        let reduce = this.p.parser.stateSlot(this.state, 5 /* ForcedReduce */);\n        if ((reduce & 65536 /* ReduceFlag */) == 0)\n            return false;\n        let { parser } = this.p;\n        if (!parser.validAction(this.state, reduce)) {\n            let depth = reduce >> 19 /* ReduceDepthShift */, term = reduce & 65535 /* ValueMask */;\n            let target = this.stack.length - depth * 3;\n            if (target < 0 || parser.getGoto(this.stack[target], term, false) < 0)\n                return false;\n            this.storeNode(0 /* Err */, this.reducePos, this.reducePos, 4, true);\n            this.score -= 100 /* Reduce */;\n        }\n        this.reducePos = this.pos;\n        this.reduce(reduce);\n        return true;\n    }\n    /// @internal\n    forceAll() {\n        while (!this.p.parser.stateFlag(this.state, 2 /* Accepting */)) {\n            if (!this.forceReduce()) {\n                this.storeNode(0 /* Err */, this.pos, this.pos, 4, true);\n                break;\n            }\n        }\n        return this;\n    }\n    /// Check whether this state has no further actions (assumed to be a direct descendant of the\n    /// top state, since any other states must be able to continue\n    /// somehow). @internal\n    get deadEnd() {\n        if (this.stack.length != 3)\n            return false;\n        let { parser } = this.p;\n        return parser.data[parser.stateSlot(this.state, 1 /* Actions */)] == 65535 /* End */ &&\n            !parser.stateSlot(this.state, 4 /* DefaultReduce */);\n    }\n    /// Restart the stack (put it back in its start state). Only safe\n    /// when this.stack.length == 3 (state is directly below the top\n    /// state). @internal\n    restart() {\n        this.state = this.stack[0];\n        this.stack.length = 0;\n    }\n    /// @internal\n    sameState(other) {\n        if (this.state != other.state || this.stack.length != other.stack.length)\n            return false;\n        for (let i = 0; i < this.stack.length; i += 3)\n            if (this.stack[i] != other.stack[i])\n                return false;\n        return true;\n    }\n    /// Get the parser used by this stack.\n    get parser() { return this.p.parser; }\n    /// Test whether a given dialect (by numeric ID, as exported from\n    /// the terms file) is enabled.\n    dialectEnabled(dialectID) { return this.p.parser.dialect.flags[dialectID]; }\n    shiftContext(term, start) {\n        if (this.curContext)\n            this.updateContext(this.curContext.tracker.shift(this.curContext.context, term, this, this.p.stream.reset(start)));\n    }\n    reduceContext(term, start) {\n        if (this.curContext)\n            this.updateContext(this.curContext.tracker.reduce(this.curContext.context, term, this, this.p.stream.reset(start)));\n    }\n    /// @internal\n    emitContext() {\n        let last = this.buffer.length - 1;\n        if (last < 0 || this.buffer[last] != -3)\n            this.buffer.push(this.curContext.hash, this.reducePos, this.reducePos, -3);\n    }\n    /// @internal\n    emitLookAhead() {\n        let last = this.buffer.length - 1;\n        if (last < 0 || this.buffer[last] != -4)\n            this.buffer.push(this.lookAhead, this.reducePos, this.reducePos, -4);\n    }\n    updateContext(context) {\n        if (context != this.curContext.context) {\n            let newCx = new StackContext(this.curContext.tracker, context);\n            if (newCx.hash != this.curContext.hash)\n                this.emitContext();\n            this.curContext = newCx;\n        }\n    }\n    /// @internal\n    setLookAhead(lookAhead) {\n        if (lookAhead > this.lookAhead) {\n            this.emitLookAhead();\n            this.lookAhead = lookAhead;\n        }\n    }\n    /// @internal\n    close() {\n        if (this.curContext && this.curContext.tracker.strict)\n            this.emitContext();\n        if (this.lookAhead > 0)\n            this.emitLookAhead();\n    }\n}\nclass StackContext {\n    constructor(tracker, context) {\n        this.tracker = tracker;\n        this.context = context;\n        this.hash = tracker.strict ? tracker.hash(context) : 0;\n    }\n}\nvar Recover;\n(function (Recover) {\n    Recover[Recover[\"Insert\"] = 200] = \"Insert\";\n    Recover[Recover[\"Delete\"] = 190] = \"Delete\";\n    Recover[Recover[\"Reduce\"] = 100] = \"Reduce\";\n    Recover[Recover[\"MaxNext\"] = 4] = \"MaxNext\";\n    Recover[Recover[\"MaxInsertStackDepth\"] = 300] = \"MaxInsertStackDepth\";\n    Recover[Recover[\"DampenInsertStackDepth\"] = 120] = \"DampenInsertStackDepth\";\n})(Recover || (Recover = {}));\n// Used to cheaply run some reductions to scan ahead without mutating\n// an entire stack\nclass SimulatedStack {\n    constructor(start) {\n        this.start = start;\n        this.state = start.state;\n        this.stack = start.stack;\n        this.base = this.stack.length;\n    }\n    reduce(action) {\n        let term = action & 65535 /* ValueMask */, depth = action >> 19 /* ReduceDepthShift */;\n        if (depth == 0) {\n            if (this.stack == this.start.stack)\n                this.stack = this.stack.slice();\n            this.stack.push(this.state, 0, 0);\n            this.base += 3;\n        }\n        else {\n            this.base -= (depth - 1) * 3;\n        }\n        let goto = this.start.p.parser.getGoto(this.stack[this.base - 3], term, true);\n        this.state = goto;\n    }\n}\n// This is given to `Tree.build` to build a buffer, and encapsulates\n// the parent-stack-walking necessary to read the nodes.\nclass StackBufferCursor {\n    constructor(stack, pos, index) {\n        this.stack = stack;\n        this.pos = pos;\n        this.index = index;\n        this.buffer = stack.buffer;\n        if (this.index == 0)\n            this.maybeNext();\n    }\n    static create(stack, pos = stack.bufferBase + stack.buffer.length) {\n        return new StackBufferCursor(stack, pos, pos - stack.bufferBase);\n    }\n    maybeNext() {\n        let next = this.stack.parent;\n        if (next != null) {\n            this.index = this.stack.bufferBase - next.bufferBase;\n            this.stack = next;\n            this.buffer = next.buffer;\n        }\n    }\n    get id() { return this.buffer[this.index - 4]; }\n    get start() { return this.buffer[this.index - 3]; }\n    get end() { return this.buffer[this.index - 2]; }\n    get size() { return this.buffer[this.index - 1]; }\n    next() {\n        this.index -= 4;\n        this.pos -= 4;\n        if (this.index == 0)\n            this.maybeNext();\n    }\n    fork() {\n        return new StackBufferCursor(this.stack, this.pos, this.index);\n    }\n}\n\nclass CachedToken {\n    constructor() {\n        this.start = -1;\n        this.value = -1;\n        this.end = -1;\n        this.extended = -1;\n        this.lookAhead = 0;\n        this.mask = 0;\n        this.context = 0;\n    }\n}\nconst nullToken = new CachedToken;\n/// [Tokenizers](#lr.ExternalTokenizer) interact with the input\n/// through this interface. It presents the input as a stream of\n/// characters, tracking lookahead and hiding the complexity of\n/// [ranges](#common.Parser.parse^ranges) from tokenizer code.\nclass InputStream {\n    /// @internal\n    constructor(\n    /// @internal\n    input, \n    /// @internal\n    ranges) {\n        this.input = input;\n        this.ranges = ranges;\n        /// @internal\n        this.chunk = \"\";\n        /// @internal\n        this.chunkOff = 0;\n        /// Backup chunk\n        this.chunk2 = \"\";\n        this.chunk2Pos = 0;\n        /// The character code of the next code unit in the input, or -1\n        /// when the stream is at the end of the input.\n        this.next = -1;\n        /// @internal\n        this.token = nullToken;\n        this.rangeIndex = 0;\n        this.pos = this.chunkPos = ranges[0].from;\n        this.range = ranges[0];\n        this.end = ranges[ranges.length - 1].to;\n        this.readNext();\n    }\n    /// @internal\n    resolveOffset(offset, assoc) {\n        let range = this.range, index = this.rangeIndex;\n        let pos = this.pos + offset;\n        while (pos < range.from) {\n            if (!index)\n                return null;\n            let next = this.ranges[--index];\n            pos -= range.from - next.to;\n            range = next;\n        }\n        while (assoc < 0 ? pos > range.to : pos >= range.to) {\n            if (index == this.ranges.length - 1)\n                return null;\n            let next = this.ranges[++index];\n            pos += next.from - range.to;\n            range = next;\n        }\n        return pos;\n    }\n    /// @internal\n    clipPos(pos) {\n        if (pos >= this.range.from && pos < this.range.to)\n            return pos;\n        for (let range of this.ranges)\n            if (range.to > pos)\n                return Math.max(pos, range.from);\n        return this.end;\n    }\n    /// Look at a code unit near the stream position. `.peek(0)` equals\n    /// `.next`, `.peek(-1)` gives you the previous character, and so\n    /// on.\n    ///\n    /// Note that looking around during tokenizing creates dependencies\n    /// on potentially far-away content, which may reduce the\n    /// effectiveness incremental parsing—when looking forward—or even\n    /// cause invalid reparses when looking backward more than 25 code\n    /// units, since the library does not track lookbehind.\n    peek(offset) {\n        let idx = this.chunkOff + offset, pos, result;\n        if (idx >= 0 && idx < this.chunk.length) {\n            pos = this.pos + offset;\n            result = this.chunk.charCodeAt(idx);\n        }\n        else {\n            let resolved = this.resolveOffset(offset, 1);\n            if (resolved == null)\n                return -1;\n            pos = resolved;\n            if (pos >= this.chunk2Pos && pos < this.chunk2Pos + this.chunk2.length) {\n                result = this.chunk2.charCodeAt(pos - this.chunk2Pos);\n            }\n            else {\n                let i = this.rangeIndex, range = this.range;\n                while (range.to <= pos)\n                    range = this.ranges[++i];\n                this.chunk2 = this.input.chunk(this.chunk2Pos = pos);\n                if (pos + this.chunk2.length > range.to)\n                    this.chunk2 = this.chunk2.slice(0, range.to - pos);\n                result = this.chunk2.charCodeAt(0);\n            }\n        }\n        if (pos >= this.token.lookAhead)\n            this.token.lookAhead = pos + 1;\n        return result;\n    }\n    /// Accept a token. By default, the end of the token is set to the\n    /// current stream position, but you can pass an offset (relative to\n    /// the stream position) to change that.\n    acceptToken(token, endOffset = 0) {\n        let end = endOffset ? this.resolveOffset(endOffset, -1) : this.pos;\n        if (end == null || end < this.token.start)\n            throw new RangeError(\"Token end out of bounds\");\n        this.token.value = token;\n        this.token.end = end;\n    }\n    getChunk() {\n        if (this.pos >= this.chunk2Pos && this.pos < this.chunk2Pos + this.chunk2.length) {\n            let { chunk, chunkPos } = this;\n            this.chunk = this.chunk2;\n            this.chunkPos = this.chunk2Pos;\n            this.chunk2 = chunk;\n            this.chunk2Pos = chunkPos;\n            this.chunkOff = this.pos - this.chunkPos;\n        }\n        else {\n            this.chunk2 = this.chunk;\n            this.chunk2Pos = this.chunkPos;\n            let nextChunk = this.input.chunk(this.pos);\n            let end = this.pos + nextChunk.length;\n            this.chunk = end > this.range.to ? nextChunk.slice(0, this.range.to - this.pos) : nextChunk;\n            this.chunkPos = this.pos;\n            this.chunkOff = 0;\n        }\n    }\n    readNext() {\n        if (this.chunkOff >= this.chunk.length) {\n            this.getChunk();\n            if (this.chunkOff == this.chunk.length)\n                return this.next = -1;\n        }\n        return this.next = this.chunk.charCodeAt(this.chunkOff);\n    }\n    /// Move the stream forward N (defaults to 1) code units. Returns\n    /// the new value of [`next`](#lr.InputStream.next).\n    advance(n = 1) {\n        this.chunkOff += n;\n        while (this.pos + n >= this.range.to) {\n            if (this.rangeIndex == this.ranges.length - 1)\n                return this.setDone();\n            n -= this.range.to - this.pos;\n            this.range = this.ranges[++this.rangeIndex];\n            this.pos = this.range.from;\n        }\n        this.pos += n;\n        if (this.pos >= this.token.lookAhead)\n            this.token.lookAhead = this.pos + 1;\n        return this.readNext();\n    }\n    setDone() {\n        this.pos = this.chunkPos = this.end;\n        this.range = this.ranges[this.rangeIndex = this.ranges.length - 1];\n        this.chunk = \"\";\n        return this.next = -1;\n    }\n    /// @internal\n    reset(pos, token) {\n        if (token) {\n            this.token = token;\n            token.start = pos;\n            token.lookAhead = pos + 1;\n            token.value = token.extended = -1;\n        }\n        else {\n            this.token = nullToken;\n        }\n        if (this.pos != pos) {\n            this.pos = pos;\n            if (pos == this.end) {\n                this.setDone();\n                return this;\n            }\n            while (pos < this.range.from)\n                this.range = this.ranges[--this.rangeIndex];\n            while (pos >= this.range.to)\n                this.range = this.ranges[++this.rangeIndex];\n            if (pos >= this.chunkPos && pos < this.chunkPos + this.chunk.length) {\n                this.chunkOff = pos - this.chunkPos;\n            }\n            else {\n                this.chunk = \"\";\n                this.chunkOff = 0;\n            }\n            this.readNext();\n        }\n        return this;\n    }\n    /// @internal\n    read(from, to) {\n        if (from >= this.chunkPos && to <= this.chunkPos + this.chunk.length)\n            return this.chunk.slice(from - this.chunkPos, to - this.chunkPos);\n        if (from >= this.chunk2Pos && to <= this.chunk2Pos + this.chunk2.length)\n            return this.chunk2.slice(from - this.chunk2Pos, to - this.chunk2Pos);\n        if (from >= this.range.from && to <= this.range.to)\n            return this.input.read(from, to);\n        let result = \"\";\n        for (let r of this.ranges) {\n            if (r.from >= to)\n                break;\n            if (r.to > from)\n                result += this.input.read(Math.max(r.from, from), Math.min(r.to, to));\n        }\n        return result;\n    }\n}\n/// @internal\nclass TokenGroup {\n    constructor(data, id) {\n        this.data = data;\n        this.id = id;\n    }\n    token(input, stack) { readToken(this.data, input, stack, this.id); }\n}\nTokenGroup.prototype.contextual = TokenGroup.prototype.fallback = TokenGroup.prototype.extend = false;\n/// `@external tokens` declarations in the grammar should resolve to\n/// an instance of this class.\nclass ExternalTokenizer {\n    /// Create a tokenizer. The first argument is the function that,\n    /// given an input stream, scans for the types of tokens it\n    /// recognizes at the stream's position, and calls\n    /// [`acceptToken`](#lr.InputStream.acceptToken) when it finds\n    /// one.\n    constructor(\n    /// @internal\n    token, options = {}) {\n        this.token = token;\n        this.contextual = !!options.contextual;\n        this.fallback = !!options.fallback;\n        this.extend = !!options.extend;\n    }\n}\n// Tokenizer data is stored a big uint16 array containing, for each\n// state:\n//\n//  - A group bitmask, indicating what token groups are reachable from\n//    this state, so that paths that can only lead to tokens not in\n//    any of the current groups can be cut off early.\n//\n//  - The position of the end of the state's sequence of accepting\n//    tokens\n//\n//  - The number of outgoing edges for the state\n//\n//  - The accepting tokens, as (token id, group mask) pairs\n//\n//  - The outgoing edges, as (start character, end character, state\n//    index) triples, with end character being exclusive\n//\n// This function interprets that data, running through a stream as\n// long as new states with the a matching group mask can be reached,\n// and updating `input.token` when it matches a token.\nfunction readToken(data, input, stack, group) {\n    let state = 0, groupMask = 1 << group, { parser } = stack.p, { dialect } = parser;\n    scan: for (;;) {\n        if ((groupMask & data[state]) == 0)\n            break;\n        let accEnd = data[state + 1];\n        // Check whether this state can lead to a token in the current group\n        // Accept tokens in this state, possibly overwriting\n        // lower-precedence / shorter tokens\n        for (let i = state + 3; i < accEnd; i += 2)\n            if ((data[i + 1] & groupMask) > 0) {\n                let term = data[i];\n                if (dialect.allows(term) &&\n                    (input.token.value == -1 || input.token.value == term || parser.overrides(term, input.token.value))) {\n                    input.acceptToken(term);\n                    break;\n                }\n            }\n        let next = input.next, low = 0, high = data[state + 2];\n        // Special case for EOF\n        if (input.next < 0 && high > low && data[accEnd + high * 3 - 3] == 65535 /* End */ && data[accEnd + high * 3 - 3] == 65535 /* End */) {\n            state = data[accEnd + high * 3 - 1];\n            continue scan;\n        }\n        // Do a binary search on the state's edges\n        for (; low < high;) {\n            let mid = (low + high) >> 1;\n            let index = accEnd + mid + (mid << 1);\n            let from = data[index], to = data[index + 1] || 0x10000;\n            if (next < from)\n                high = mid;\n            else if (next >= to)\n                low = mid + 1;\n            else {\n                state = data[index + 2];\n                input.advance();\n                continue scan;\n            }\n        }\n        break;\n    }\n}\n\n// See lezer-generator/src/encode.ts for comments about the encoding\n// used here\nfunction decodeArray(input, Type = Uint16Array) {\n    if (typeof input != \"string\")\n        return input;\n    let array = null;\n    for (let pos = 0, out = 0; pos < input.length;) {\n        let value = 0;\n        for (;;) {\n            let next = input.charCodeAt(pos++), stop = false;\n            if (next == 126 /* BigValCode */) {\n                value = 65535 /* BigVal */;\n                break;\n            }\n            if (next >= 92 /* Gap2 */)\n                next--;\n            if (next >= 34 /* Gap1 */)\n                next--;\n            let digit = next - 32 /* Start */;\n            if (digit >= 46 /* Base */) {\n                digit -= 46 /* Base */;\n                stop = true;\n            }\n            value += digit;\n            if (stop)\n                break;\n            value *= 46 /* Base */;\n        }\n        if (array)\n            array[out++] = value;\n        else\n            array = new Type(value);\n    }\n    return array;\n}\n\n// Environment variable used to control console output\nconst verbose = typeof process != \"undefined\" && process.env && /\\bparse\\b/.test(process.env.LOG);\nlet stackIDs = null;\nvar Safety;\n(function (Safety) {\n    Safety[Safety[\"Margin\"] = 25] = \"Margin\";\n})(Safety || (Safety = {}));\nfunction cutAt(tree, pos, side) {\n    let cursor = tree.cursor(_lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .IterMode.IncludeAnonymous */ .vj.IncludeAnonymous);\n    cursor.moveTo(pos);\n    for (;;) {\n        if (!(side < 0 ? cursor.childBefore(pos) : cursor.childAfter(pos)))\n            for (;;) {\n                if ((side < 0 ? cursor.to < pos : cursor.from > pos) && !cursor.type.isError)\n                    return side < 0 ? Math.max(0, Math.min(cursor.to - 1, pos - 25 /* Margin */))\n                        : Math.min(tree.length, Math.max(cursor.from + 1, pos + 25 /* Margin */));\n                if (side < 0 ? cursor.prevSibling() : cursor.nextSibling())\n                    break;\n                if (!cursor.parent())\n                    return side < 0 ? 0 : tree.length;\n            }\n    }\n}\nclass FragmentCursor {\n    constructor(fragments, nodeSet) {\n        this.fragments = fragments;\n        this.nodeSet = nodeSet;\n        this.i = 0;\n        this.fragment = null;\n        this.safeFrom = -1;\n        this.safeTo = -1;\n        this.trees = [];\n        this.start = [];\n        this.index = [];\n        this.nextFragment();\n    }\n    nextFragment() {\n        let fr = this.fragment = this.i == this.fragments.length ? null : this.fragments[this.i++];\n        if (fr) {\n            this.safeFrom = fr.openStart ? cutAt(fr.tree, fr.from + fr.offset, 1) - fr.offset : fr.from;\n            this.safeTo = fr.openEnd ? cutAt(fr.tree, fr.to + fr.offset, -1) - fr.offset : fr.to;\n            while (this.trees.length) {\n                this.trees.pop();\n                this.start.pop();\n                this.index.pop();\n            }\n            this.trees.push(fr.tree);\n            this.start.push(-fr.offset);\n            this.index.push(0);\n            this.nextStart = this.safeFrom;\n        }\n        else {\n            this.nextStart = 1e9;\n        }\n    }\n    // `pos` must be >= any previously given `pos` for this cursor\n    nodeAt(pos) {\n        if (pos < this.nextStart)\n            return null;\n        while (this.fragment && this.safeTo <= pos)\n            this.nextFragment();\n        if (!this.fragment)\n            return null;\n        for (;;) {\n            let last = this.trees.length - 1;\n            if (last < 0) { // End of tree\n                this.nextFragment();\n                return null;\n            }\n            let top = this.trees[last], index = this.index[last];\n            if (index == top.children.length) {\n                this.trees.pop();\n                this.start.pop();\n                this.index.pop();\n                continue;\n            }\n            let next = top.children[index];\n            let start = this.start[last] + top.positions[index];\n            if (start > pos) {\n                this.nextStart = start;\n                return null;\n            }\n            if (next instanceof _lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .Tree */ .mp) {\n                if (start == pos) {\n                    if (start < this.safeFrom)\n                        return null;\n                    let end = start + next.length;\n                    if (end <= this.safeTo) {\n                        let lookAhead = next.prop(_lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .NodeProp.lookAhead */ .md.lookAhead);\n                        if (!lookAhead || end + lookAhead < this.fragment.to)\n                            return next;\n                    }\n                }\n                this.index[last]++;\n                if (start + next.length >= Math.max(this.safeFrom, pos)) { // Enter this node\n                    this.trees.push(next);\n                    this.start.push(start);\n                    this.index.push(0);\n                }\n            }\n            else {\n                this.index[last]++;\n                this.nextStart = start + next.length;\n            }\n        }\n    }\n}\nclass TokenCache {\n    constructor(parser, stream) {\n        this.stream = stream;\n        this.tokens = [];\n        this.mainToken = null;\n        this.actions = [];\n        this.tokens = parser.tokenizers.map(_ => new CachedToken);\n    }\n    getActions(stack) {\n        let actionIndex = 0;\n        let main = null;\n        let { parser } = stack.p, { tokenizers } = parser;\n        let mask = parser.stateSlot(stack.state, 3 /* TokenizerMask */);\n        let context = stack.curContext ? stack.curContext.hash : 0;\n        let lookAhead = 0;\n        for (let i = 0; i < tokenizers.length; i++) {\n            if (((1 << i) & mask) == 0)\n                continue;\n            let tokenizer = tokenizers[i], token = this.tokens[i];\n            if (main && !tokenizer.fallback)\n                continue;\n            if (tokenizer.contextual || token.start != stack.pos || token.mask != mask || token.context != context) {\n                this.updateCachedToken(token, tokenizer, stack);\n                token.mask = mask;\n                token.context = context;\n            }\n            if (token.lookAhead > token.end + 25 /* Margin */)\n                lookAhead = Math.max(token.lookAhead, lookAhead);\n            if (token.value != 0 /* Err */) {\n                let startIndex = actionIndex;\n                if (token.extended > -1)\n                    actionIndex = this.addActions(stack, token.extended, token.end, actionIndex);\n                actionIndex = this.addActions(stack, token.value, token.end, actionIndex);\n                if (!tokenizer.extend) {\n                    main = token;\n                    if (actionIndex > startIndex)\n                        break;\n                }\n            }\n        }\n        while (this.actions.length > actionIndex)\n            this.actions.pop();\n        if (lookAhead)\n            stack.setLookAhead(lookAhead);\n        if (!main && stack.pos == this.stream.end) {\n            main = new CachedToken;\n            main.value = stack.p.parser.eofTerm;\n            main.start = main.end = stack.pos;\n            actionIndex = this.addActions(stack, main.value, main.end, actionIndex);\n        }\n        this.mainToken = main;\n        return this.actions;\n    }\n    getMainToken(stack) {\n        if (this.mainToken)\n            return this.mainToken;\n        let main = new CachedToken, { pos, p } = stack;\n        main.start = pos;\n        main.end = Math.min(pos + 1, p.stream.end);\n        main.value = pos == p.stream.end ? p.parser.eofTerm : 0 /* Err */;\n        return main;\n    }\n    updateCachedToken(token, tokenizer, stack) {\n        let start = this.stream.clipPos(stack.pos);\n        tokenizer.token(this.stream.reset(start, token), stack);\n        if (token.value > -1) {\n            let { parser } = stack.p;\n            for (let i = 0; i < parser.specialized.length; i++)\n                if (parser.specialized[i] == token.value) {\n                    let result = parser.specializers[i](this.stream.read(token.start, token.end), stack);\n                    if (result >= 0 && stack.p.parser.dialect.allows(result >> 1)) {\n                        if ((result & 1) == 0 /* Specialize */)\n                            token.value = result >> 1;\n                        else\n                            token.extended = result >> 1;\n                        break;\n                    }\n                }\n        }\n        else {\n            token.value = 0 /* Err */;\n            token.end = this.stream.clipPos(start + 1);\n        }\n    }\n    putAction(action, token, end, index) {\n        // Don't add duplicate actions\n        for (let i = 0; i < index; i += 3)\n            if (this.actions[i] == action)\n                return index;\n        this.actions[index++] = action;\n        this.actions[index++] = token;\n        this.actions[index++] = end;\n        return index;\n    }\n    addActions(stack, token, end, index) {\n        let { state } = stack, { parser } = stack.p, { data } = parser;\n        for (let set = 0; set < 2; set++) {\n            for (let i = parser.stateSlot(state, set ? 2 /* Skip */ : 1 /* Actions */);; i += 3) {\n                if (data[i] == 65535 /* End */) {\n                    if (data[i + 1] == 1 /* Next */) {\n                        i = pair(data, i + 2);\n                    }\n                    else {\n                        if (index == 0 && data[i + 1] == 2 /* Other */)\n                            index = this.putAction(pair(data, i + 2), token, end, index);\n                        break;\n                    }\n                }\n                if (data[i] == token)\n                    index = this.putAction(pair(data, i + 1), token, end, index);\n            }\n        }\n        return index;\n    }\n}\nvar Rec;\n(function (Rec) {\n    Rec[Rec[\"Distance\"] = 5] = \"Distance\";\n    Rec[Rec[\"MaxRemainingPerStep\"] = 3] = \"MaxRemainingPerStep\";\n    // When two stacks have been running independently long enough to\n    // add this many elements to their buffers, prune one.\n    Rec[Rec[\"MinBufferLengthPrune\"] = 500] = \"MinBufferLengthPrune\";\n    Rec[Rec[\"ForceReduceLimit\"] = 10] = \"ForceReduceLimit\";\n    // Once a stack reaches this depth (in .stack.length) force-reduce\n    // it back to CutTo to avoid creating trees that overflow the stack\n    // on recursive traversal.\n    Rec[Rec[\"CutDepth\"] = 15000] = \"CutDepth\";\n    Rec[Rec[\"CutTo\"] = 9000] = \"CutTo\";\n})(Rec || (Rec = {}));\nclass Parse {\n    constructor(parser, input, fragments, ranges) {\n        this.parser = parser;\n        this.input = input;\n        this.ranges = ranges;\n        this.recovering = 0;\n        this.nextStackID = 0x2654; // ♔, ♕, ♖, ♗, ♘, ♙, ♠, ♡, ♢, ♣, ♤, ♥, ♦, ♧\n        this.minStackPos = 0;\n        this.reused = [];\n        this.stoppedAt = null;\n        this.stream = new InputStream(input, ranges);\n        this.tokens = new TokenCache(parser, this.stream);\n        this.topTerm = parser.top[1];\n        let { from } = ranges[0];\n        this.stacks = [Stack.start(this, parser.top[0], from)];\n        this.fragments = fragments.length && this.stream.end - from > parser.bufferLength * 4\n            ? new FragmentCursor(fragments, parser.nodeSet) : null;\n    }\n    get parsedPos() {\n        return this.minStackPos;\n    }\n    // Move the parser forward. This will process all parse stacks at\n    // `this.pos` and try to advance them to a further position. If no\n    // stack for such a position is found, it'll start error-recovery.\n    //\n    // When the parse is finished, this will return a syntax tree. When\n    // not, it returns `null`.\n    advance() {\n        let stacks = this.stacks, pos = this.minStackPos;\n        // This will hold stacks beyond `pos`.\n        let newStacks = this.stacks = [];\n        let stopped, stoppedTokens;\n        // Keep advancing any stacks at `pos` until they either move\n        // forward or can't be advanced. Gather stacks that can't be\n        // advanced further in `stopped`.\n        for (let i = 0; i < stacks.length; i++) {\n            let stack = stacks[i];\n            for (;;) {\n                this.tokens.mainToken = null;\n                if (stack.pos > pos) {\n                    newStacks.push(stack);\n                }\n                else if (this.advanceStack(stack, newStacks, stacks)) {\n                    continue;\n                }\n                else {\n                    if (!stopped) {\n                        stopped = [];\n                        stoppedTokens = [];\n                    }\n                    stopped.push(stack);\n                    let tok = this.tokens.getMainToken(stack);\n                    stoppedTokens.push(tok.value, tok.end);\n                }\n                break;\n            }\n        }\n        if (!newStacks.length) {\n            let finished = stopped && findFinished(stopped);\n            if (finished)\n                return this.stackToTree(finished);\n            if (this.parser.strict) {\n                if (verbose && stopped)\n                    console.log(\"Stuck with token \" + (this.tokens.mainToken ? this.parser.getName(this.tokens.mainToken.value) : \"none\"));\n                throw new SyntaxError(\"No parse at \" + pos);\n            }\n            if (!this.recovering)\n                this.recovering = 5 /* Distance */;\n        }\n        if (this.recovering && stopped) {\n            let finished = this.stoppedAt != null && stopped[0].pos > this.stoppedAt ? stopped[0]\n                : this.runRecovery(stopped, stoppedTokens, newStacks);\n            if (finished)\n                return this.stackToTree(finished.forceAll());\n        }\n        if (this.recovering) {\n            let maxRemaining = this.recovering == 1 ? 1 : this.recovering * 3 /* MaxRemainingPerStep */;\n            if (newStacks.length > maxRemaining) {\n                newStacks.sort((a, b) => b.score - a.score);\n                while (newStacks.length > maxRemaining)\n                    newStacks.pop();\n            }\n            if (newStacks.some(s => s.reducePos > pos))\n                this.recovering--;\n        }\n        else if (newStacks.length > 1) {\n            // Prune stacks that are in the same state, or that have been\n            // running without splitting for a while, to avoid getting stuck\n            // with multiple successful stacks running endlessly on.\n            outer: for (let i = 0; i < newStacks.length - 1; i++) {\n                let stack = newStacks[i];\n                for (let j = i + 1; j < newStacks.length; j++) {\n                    let other = newStacks[j];\n                    if (stack.sameState(other) ||\n                        stack.buffer.length > 500 /* MinBufferLengthPrune */ && other.buffer.length > 500 /* MinBufferLengthPrune */) {\n                        if (((stack.score - other.score) || (stack.buffer.length - other.buffer.length)) > 0) {\n                            newStacks.splice(j--, 1);\n                        }\n                        else {\n                            newStacks.splice(i--, 1);\n                            continue outer;\n                        }\n                    }\n                }\n            }\n        }\n        this.minStackPos = newStacks[0].pos;\n        for (let i = 1; i < newStacks.length; i++)\n            if (newStacks[i].pos < this.minStackPos)\n                this.minStackPos = newStacks[i].pos;\n        return null;\n    }\n    stopAt(pos) {\n        if (this.stoppedAt != null && this.stoppedAt < pos)\n            throw new RangeError(\"Can't move stoppedAt forward\");\n        this.stoppedAt = pos;\n    }\n    // Returns an updated version of the given stack, or null if the\n    // stack can't advance normally. When `split` and `stacks` are\n    // given, stacks split off by ambiguous operations will be pushed to\n    // `split`, or added to `stacks` if they move `pos` forward.\n    advanceStack(stack, stacks, split) {\n        let start = stack.pos, { parser } = this;\n        let base = verbose ? this.stackID(stack) + \" -> \" : \"\";\n        if (this.stoppedAt != null && start > this.stoppedAt)\n            return stack.forceReduce() ? stack : null;\n        if (this.fragments) {\n            let strictCx = stack.curContext && stack.curContext.tracker.strict, cxHash = strictCx ? stack.curContext.hash : 0;\n            for (let cached = this.fragments.nodeAt(start); cached;) {\n                let match = this.parser.nodeSet.types[cached.type.id] == cached.type ? parser.getGoto(stack.state, cached.type.id) : -1;\n                if (match > -1 && cached.length && (!strictCx || (cached.prop(_lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .NodeProp.contextHash */ .md.contextHash) || 0) == cxHash)) {\n                    stack.useNode(cached, match);\n                    if (verbose)\n                        console.log(base + this.stackID(stack) + ` (via reuse of ${parser.getName(cached.type.id)})`);\n                    return true;\n                }\n                if (!(cached instanceof _lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .Tree */ .mp) || cached.children.length == 0 || cached.positions[0] > 0)\n                    break;\n                let inner = cached.children[0];\n                if (inner instanceof _lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .Tree */ .mp && cached.positions[0] == 0)\n                    cached = inner;\n                else\n                    break;\n            }\n        }\n        let defaultReduce = parser.stateSlot(stack.state, 4 /* DefaultReduce */);\n        if (defaultReduce > 0) {\n            stack.reduce(defaultReduce);\n            if (verbose)\n                console.log(base + this.stackID(stack) + ` (via always-reduce ${parser.getName(defaultReduce & 65535 /* ValueMask */)})`);\n            return true;\n        }\n        if (stack.stack.length >= 15000 /* CutDepth */) {\n            while (stack.stack.length > 9000 /* CutTo */ && stack.forceReduce()) { }\n        }\n        let actions = this.tokens.getActions(stack);\n        for (let i = 0; i < actions.length;) {\n            let action = actions[i++], term = actions[i++], end = actions[i++];\n            let last = i == actions.length || !split;\n            let localStack = last ? stack : stack.split();\n            localStack.apply(action, term, end);\n            if (verbose)\n                console.log(base + this.stackID(localStack) + ` (via ${(action & 65536 /* ReduceFlag */) == 0 ? \"shift\"\n                    : `reduce of ${parser.getName(action & 65535 /* ValueMask */)}`} for ${parser.getName(term)} @ ${start}${localStack == stack ? \"\" : \", split\"})`);\n            if (last)\n                return true;\n            else if (localStack.pos > start)\n                stacks.push(localStack);\n            else\n                split.push(localStack);\n        }\n        return false;\n    }\n    // Advance a given stack forward as far as it will go. Returns the\n    // (possibly updated) stack if it got stuck, or null if it moved\n    // forward and was given to `pushStackDedup`.\n    advanceFully(stack, newStacks) {\n        let pos = stack.pos;\n        for (;;) {\n            if (!this.advanceStack(stack, null, null))\n                return false;\n            if (stack.pos > pos) {\n                pushStackDedup(stack, newStacks);\n                return true;\n            }\n        }\n    }\n    runRecovery(stacks, tokens, newStacks) {\n        let finished = null, restarted = false;\n        for (let i = 0; i < stacks.length; i++) {\n            let stack = stacks[i], token = tokens[i << 1], tokenEnd = tokens[(i << 1) + 1];\n            let base = verbose ? this.stackID(stack) + \" -> \" : \"\";\n            if (stack.deadEnd) {\n                if (restarted)\n                    continue;\n                restarted = true;\n                stack.restart();\n                if (verbose)\n                    console.log(base + this.stackID(stack) + \" (restarted)\");\n                let done = this.advanceFully(stack, newStacks);\n                if (done)\n                    continue;\n            }\n            let force = stack.split(), forceBase = base;\n            for (let j = 0; force.forceReduce() && j < 10 /* ForceReduceLimit */; j++) {\n                if (verbose)\n                    console.log(forceBase + this.stackID(force) + \" (via force-reduce)\");\n                let done = this.advanceFully(force, newStacks);\n                if (done)\n                    break;\n                if (verbose)\n                    forceBase = this.stackID(force) + \" -> \";\n            }\n            for (let insert of stack.recoverByInsert(token)) {\n                if (verbose)\n                    console.log(base + this.stackID(insert) + \" (via recover-insert)\");\n                this.advanceFully(insert, newStacks);\n            }\n            if (this.stream.end > stack.pos) {\n                if (tokenEnd == stack.pos) {\n                    tokenEnd++;\n                    token = 0 /* Err */;\n                }\n                stack.recoverByDelete(token, tokenEnd);\n                if (verbose)\n                    console.log(base + this.stackID(stack) + ` (via recover-delete ${this.parser.getName(token)})`);\n                pushStackDedup(stack, newStacks);\n            }\n            else if (!finished || finished.score < stack.score) {\n                finished = stack;\n            }\n        }\n        return finished;\n    }\n    // Convert the stack's buffer to a syntax tree.\n    stackToTree(stack) {\n        stack.close();\n        return _lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .Tree.build */ .mp.build({ buffer: StackBufferCursor.create(stack),\n            nodeSet: this.parser.nodeSet,\n            topID: this.topTerm,\n            maxBufferLength: this.parser.bufferLength,\n            reused: this.reused,\n            start: this.ranges[0].from,\n            length: stack.pos - this.ranges[0].from,\n            minRepeatType: this.parser.minRepeatTerm });\n    }\n    stackID(stack) {\n        let id = (stackIDs || (stackIDs = new WeakMap)).get(stack);\n        if (!id)\n            stackIDs.set(stack, id = String.fromCodePoint(this.nextStackID++));\n        return id + stack;\n    }\n}\nfunction pushStackDedup(stack, newStacks) {\n    for (let i = 0; i < newStacks.length; i++) {\n        let other = newStacks[i];\n        if (other.pos == stack.pos && other.sameState(stack)) {\n            if (newStacks[i].score < stack.score)\n                newStacks[i] = stack;\n            return;\n        }\n    }\n    newStacks.push(stack);\n}\nclass Dialect {\n    constructor(source, flags, disabled) {\n        this.source = source;\n        this.flags = flags;\n        this.disabled = disabled;\n    }\n    allows(term) { return !this.disabled || this.disabled[term] == 0; }\n}\nconst id = x => x;\n/// Context trackers are used to track stateful context (such as\n/// indentation in the Python grammar, or parent elements in the XML\n/// grammar) needed by external tokenizers. You declare them in a\n/// grammar file as `@context exportName from \"module\"`.\n///\n/// Context values should be immutable, and can be updated (replaced)\n/// on shift or reduce actions.\n///\n/// The export used in a `@context` declaration should be of this\n/// type.\nclass ContextTracker {\n    /// Define a context tracker.\n    constructor(spec) {\n        this.start = spec.start;\n        this.shift = spec.shift || id;\n        this.reduce = spec.reduce || id;\n        this.reuse = spec.reuse || id;\n        this.hash = spec.hash || (() => 0);\n        this.strict = spec.strict !== false;\n    }\n}\n/// Holds the parse tables for a given grammar, as generated by\n/// `lezer-generator`, and provides [methods](#common.Parser) to parse\n/// content with.\nclass LRParser extends _lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .Parser */ ._b {\n    /// @internal\n    constructor(spec) {\n        super();\n        /// @internal\n        this.wrappers = [];\n        if (spec.version != 14 /* Version */)\n            throw new RangeError(`Parser version (${spec.version}) doesn't match runtime version (${14 /* Version */})`);\n        let nodeNames = spec.nodeNames.split(\" \");\n        this.minRepeatTerm = nodeNames.length;\n        for (let i = 0; i < spec.repeatNodeCount; i++)\n            nodeNames.push(\"\");\n        let topTerms = Object.keys(spec.topRules).map(r => spec.topRules[r][1]);\n        let nodeProps = [];\n        for (let i = 0; i < nodeNames.length; i++)\n            nodeProps.push([]);\n        function setProp(nodeID, prop, value) {\n            nodeProps[nodeID].push([prop, prop.deserialize(String(value))]);\n        }\n        if (spec.nodeProps)\n            for (let propSpec of spec.nodeProps) {\n                let prop = propSpec[0];\n                if (typeof prop == \"string\")\n                    prop = _lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .NodeProp */ .md[prop];\n                for (let i = 1; i < propSpec.length;) {\n                    let next = propSpec[i++];\n                    if (next >= 0) {\n                        setProp(next, prop, propSpec[i++]);\n                    }\n                    else {\n                        let value = propSpec[i + -next];\n                        for (let j = -next; j > 0; j--)\n                            setProp(propSpec[i++], prop, value);\n                        i++;\n                    }\n                }\n            }\n        this.nodeSet = new _lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .NodeSet */ .Lj(nodeNames.map((name, i) => _lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .NodeType.define */ .Jq.define({\n            name: i >= this.minRepeatTerm ? undefined : name,\n            id: i,\n            props: nodeProps[i],\n            top: topTerms.indexOf(i) > -1,\n            error: i == 0,\n            skipped: spec.skippedNodes && spec.skippedNodes.indexOf(i) > -1\n        })));\n        if (spec.propSources)\n            this.nodeSet = this.nodeSet.extend(...spec.propSources);\n        this.strict = false;\n        this.bufferLength = _lezer_common__WEBPACK_IMPORTED_MODULE_0__/* .DefaultBufferLength */ .L3;\n        let tokenArray = decodeArray(spec.tokenData);\n        this.context = spec.context;\n        this.specializerSpecs = spec.specialized || [];\n        this.specialized = new Uint16Array(this.specializerSpecs.length);\n        for (let i = 0; i < this.specializerSpecs.length; i++)\n            this.specialized[i] = this.specializerSpecs[i].term;\n        this.specializers = this.specializerSpecs.map(getSpecializer);\n        this.states = decodeArray(spec.states, Uint32Array);\n        this.data = decodeArray(spec.stateData);\n        this.goto = decodeArray(spec.goto);\n        this.maxTerm = spec.maxTerm;\n        this.tokenizers = spec.tokenizers.map(value => typeof value == \"number\" ? new TokenGroup(tokenArray, value) : value);\n        this.topRules = spec.topRules;\n        this.dialects = spec.dialects || {};\n        this.dynamicPrecedences = spec.dynamicPrecedences || null;\n        this.tokenPrecTable = spec.tokenPrec;\n        this.termNames = spec.termNames || null;\n        this.maxNode = this.nodeSet.types.length - 1;\n        this.dialect = this.parseDialect();\n        this.top = this.topRules[Object.keys(this.topRules)[0]];\n    }\n    createParse(input, fragments, ranges) {\n        let parse = new Parse(this, input, fragments, ranges);\n        for (let w of this.wrappers)\n            parse = w(parse, input, fragments, ranges);\n        return parse;\n    }\n    /// Get a goto table entry @internal\n    getGoto(state, term, loose = false) {\n        let table = this.goto;\n        if (term >= table[0])\n            return -1;\n        for (let pos = table[term + 1];;) {\n            let groupTag = table[pos++], last = groupTag & 1;\n            let target = table[pos++];\n            if (last && loose)\n                return target;\n            for (let end = pos + (groupTag >> 1); pos < end; pos++)\n                if (table[pos] == state)\n                    return target;\n            if (last)\n                return -1;\n        }\n    }\n    /// Check if this state has an action for a given terminal @internal\n    hasAction(state, terminal) {\n        let data = this.data;\n        for (let set = 0; set < 2; set++) {\n            for (let i = this.stateSlot(state, set ? 2 /* Skip */ : 1 /* Actions */), next;; i += 3) {\n                if ((next = data[i]) == 65535 /* End */) {\n                    if (data[i + 1] == 1 /* Next */)\n                        next = data[i = pair(data, i + 2)];\n                    else if (data[i + 1] == 2 /* Other */)\n                        return pair(data, i + 2);\n                    else\n                        break;\n                }\n                if (next == terminal || next == 0 /* Err */)\n                    return pair(data, i + 1);\n            }\n        }\n        return 0;\n    }\n    /// @internal\n    stateSlot(state, slot) {\n        return this.states[(state * 6 /* Size */) + slot];\n    }\n    /// @internal\n    stateFlag(state, flag) {\n        return (this.stateSlot(state, 0 /* Flags */) & flag) > 0;\n    }\n    /// @internal\n    validAction(state, action) {\n        if (action == this.stateSlot(state, 4 /* DefaultReduce */))\n            return true;\n        for (let i = this.stateSlot(state, 1 /* Actions */);; i += 3) {\n            if (this.data[i] == 65535 /* End */) {\n                if (this.data[i + 1] == 1 /* Next */)\n                    i = pair(this.data, i + 2);\n                else\n                    return false;\n            }\n            if (action == pair(this.data, i + 1))\n                return true;\n        }\n    }\n    /// Get the states that can follow this one through shift actions or\n    /// goto jumps. @internal\n    nextStates(state) {\n        let result = [];\n        for (let i = this.stateSlot(state, 1 /* Actions */);; i += 3) {\n            if (this.data[i] == 65535 /* End */) {\n                if (this.data[i + 1] == 1 /* Next */)\n                    i = pair(this.data, i + 2);\n                else\n                    break;\n            }\n            if ((this.data[i + 2] & (65536 /* ReduceFlag */ >> 16)) == 0) {\n                let value = this.data[i + 1];\n                if (!result.some((v, i) => (i & 1) && v == value))\n                    result.push(this.data[i], value);\n            }\n        }\n        return result;\n    }\n    /// @internal\n    overrides(token, prev) {\n        let iPrev = findOffset(this.data, this.tokenPrecTable, prev);\n        return iPrev < 0 || findOffset(this.data, this.tokenPrecTable, token) < iPrev;\n    }\n    /// Configure the parser. Returns a new parser instance that has the\n    /// given settings modified. Settings not provided in `config` are\n    /// kept from the original parser.\n    configure(config) {\n        // Hideous reflection-based kludge to make it easy to create a\n        // slightly modified copy of a parser.\n        let copy = Object.assign(Object.create(LRParser.prototype), this);\n        if (config.props)\n            copy.nodeSet = this.nodeSet.extend(...config.props);\n        if (config.top) {\n            let info = this.topRules[config.top];\n            if (!info)\n                throw new RangeError(`Invalid top rule name ${config.top}`);\n            copy.top = info;\n        }\n        if (config.tokenizers)\n            copy.tokenizers = this.tokenizers.map(t => {\n                let found = config.tokenizers.find(r => r.from == t);\n                return found ? found.to : t;\n            });\n        if (config.specializers) {\n            copy.specializers = this.specializers.slice();\n            copy.specializerSpecs = this.specializerSpecs.map((s, i) => {\n                let found = config.specializers.find(r => r.from == s.external);\n                if (!found)\n                    return s;\n                let spec = Object.assign(Object.assign({}, s), { external: found.to });\n                copy.specializers[i] = getSpecializer(spec);\n                return spec;\n            });\n        }\n        if (config.contextTracker)\n            copy.context = config.contextTracker;\n        if (config.dialect)\n            copy.dialect = this.parseDialect(config.dialect);\n        if (config.strict != null)\n            copy.strict = config.strict;\n        if (config.wrap)\n            copy.wrappers = copy.wrappers.concat(config.wrap);\n        if (config.bufferLength != null)\n            copy.bufferLength = config.bufferLength;\n        return copy;\n    }\n    /// Tells you whether any [parse wrappers](#lr.ParserConfig.wrap)\n    /// are registered for this parser.\n    hasWrappers() {\n        return this.wrappers.length > 0;\n    }\n    /// Returns the name associated with a given term. This will only\n    /// work for all terms when the parser was generated with the\n    /// `--names` option. By default, only the names of tagged terms are\n    /// stored.\n    getName(term) {\n        return this.termNames ? this.termNames[term] : String(term <= this.maxNode && this.nodeSet.types[term].name || term);\n    }\n    /// The eof term id is always allocated directly after the node\n    /// types. @internal\n    get eofTerm() { return this.maxNode + 1; }\n    /// The type of top node produced by the parser.\n    get topNode() { return this.nodeSet.types[this.top[1]]; }\n    /// @internal\n    dynamicPrecedence(term) {\n        let prec = this.dynamicPrecedences;\n        return prec == null ? 0 : prec[term] || 0;\n    }\n    /// @internal\n    parseDialect(dialect) {\n        let values = Object.keys(this.dialects), flags = values.map(() => false);\n        if (dialect)\n            for (let part of dialect.split(\" \")) {\n                let id = values.indexOf(part);\n                if (id >= 0)\n                    flags[id] = true;\n            }\n        let disabled = null;\n        for (let i = 0; i < values.length; i++)\n            if (!flags[i]) {\n                for (let j = this.dialects[values[i]], id; (id = this.data[j++]) != 65535 /* End */;)\n                    (disabled || (disabled = new Uint8Array(this.maxTerm + 1)))[id] = 1;\n            }\n        return new Dialect(dialect, flags, disabled);\n    }\n    /// Used by the output of the parser generator. Not available to\n    /// user code.\n    static deserialize(spec) {\n        return new LRParser(spec);\n    }\n}\nfunction pair(data, off) { return data[off] | (data[off + 1] << 16); }\nfunction findOffset(data, start, term) {\n    for (let i = start, next; (next = data[i]) != 65535 /* End */; i++)\n        if (next == term)\n            return i - start;\n    return -1;\n}\nfunction findFinished(stacks) {\n    let best = null;\n    for (let stack of stacks) {\n        let stopped = stack.p.stoppedAt;\n        if ((stack.pos == stack.p.stream.end || stopped != null && stack.pos > stopped) &&\n            stack.p.parser.stateFlag(stack.state, 2 /* Accepting */) &&\n            (!best || best.score < stack.score))\n            best = stack;\n    }\n    return best;\n}\nfunction getSpecializer(spec) {\n    if (spec.external) {\n        let mask = spec.extend ? 1 /* Extend */ : 0 /* Specialize */;\n        return (value, stack) => (spec.external(value, stack) << 1) | mask;\n    }\n    return spec.get;\n}\n\n\n\n\n/***/ })\n\n}]);"],"names":["self","push","__unused_webpack___webpack_module__","__webpack_exports__","__webpack_require__","d","ContextTracker","ExternalTokenizer","LRParser","Recover","Safety","Rec","_lezer_common__WEBPACK_IMPORTED_MODULE_0__","process","Stack","constructor","p","stack","state","reducePos","pos","score","buffer","bufferBase","curContext","lookAhead","parent","toString","filter","_","i","concat","start","cx","parser","context","StackContext","pushState","length","reduce","action","depth","type","dPrec","dynamicPrecedence","getGoto","minRepeatTerm","storeNode","reduceContext","base","count","stateFlag","baseStateID","pop","term","end","size","isReduce","cur","top","index","shift","next","nextEnd","maxNode","shiftContext","apply","useNode","value","reused","updateContext","tracker","reuse","stream","reset","split","off","slice","recoverByDelete","isNode","canShift","sim","SimulatedStack","stateSlot","hasAction","recoverByInsert","nextStates","best","s","some","v","result","forceReduce","validAction","target","forceAll","deadEnd","data","restart","sameState","other","dialectEnabled","dialectID","dialect","flags","emitContext","last","hash","emitLookAhead","newCx","setLookAhead","close","strict","goto","StackBufferCursor","maybeNext","create","id","fork","CachedToken","extended","mask","nullToken","InputStream","input","ranges","chunk","chunkOff","chunk2","chunk2Pos","token","rangeIndex","chunkPos","from","range","to","readNext","resolveOffset","offset","assoc","clipPos","Math","max","peek","idx","charCodeAt","resolved","acceptToken","endOffset","getChunk","nextChunk","advance","n","setDone","read","r","min","TokenGroup","readToken","group","groupMask","scan","accEnd","allows","overrides","low","high","mid","prototype","contextual","fallback","extend","options","decodeArray","Type","Uint16Array","array","out","stop","digit","verbose","env","test","LOG","stackIDs","cutAt","tree","side","cursor","vj","IncludeAnonymous","moveTo","childBefore","childAfter","isError","prevSibling","nextSibling","FragmentCursor","fragments","nodeSet","fragment","safeFrom","safeTo","trees","nextFragment","fr","openStart","openEnd","nextStart","nodeAt","children","positions","mp","prop","md","TokenCache","tokens","mainToken","actions","tokenizers","map","getActions","actionIndex","main","tokenizer","updateCachedToken","startIndex","addActions","eofTerm","getMainToken","specialized","specializers","putAction","set","pair","Parse","recovering","nextStackID","minStackPos","stoppedAt","topTerm","stacks","bufferLength","parsedPos","stopped","stoppedTokens","newStacks","advanceStack","tok","finished","findFinished","stackToTree","console","log","getName","runRecovery","maxRemaining","sort","a","b","outer","j","splice","stopAt","stackID","strictCx","cxHash","cached","match","types","contextHash","inner","defaultReduce","localStack","advanceFully","pushStackDedup","restarted","tokenEnd","force","forceBase","insert","build","topID","maxBufferLength","minRepeatType","WeakMap","get","String","fromCodePoint","Dialect","source","disabled","x","spec","_b","wrappers","version","nodeNames","repeatNodeCount","topTerms","Object","keys","topRules","nodeProps","setProp","nodeID","deserialize","propSpec","Lj","name","Jq","define","undefined","props","indexOf","error","skipped","skippedNodes","propSources","L3","tokenArray","tokenData","specializerSpecs","getSpecializer","states","Uint32Array","stateData","maxTerm","dialects","dynamicPrecedences","tokenPrecTable","tokenPrec","termNames","parseDialect","createParse","parse","w","loose","table","groupTag","terminal","slot","flag","prev","iPrev","findOffset","configure","config","copy","assign","info","t","found","find","external","contextTracker","wrap","hasWrappers","topNode","prec","values","part","Uint8Array"],"sourceRoot":""}